[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Auswertung quantitativer Daten",
    "section": "",
    "text": "Herzlich willkommen!\nDieses Dokument wird Sie durch die Veranstaltung ‚ÄúAuswertung quantitativer Daten‚Äù begleiten. Es ist zum und im Wintersemeter 2024/25 an der Universit√§t Erfurt entstanden.",
    "crumbs": [
      "Herzlich willkommen!"
    ]
  },
  {
    "objectID": "Einleitung.html",
    "href": "Einleitung.html",
    "title": "1¬† Willkommen zum Kurs",
    "section": "",
    "text": "1.1 Lernziele\nKommunikationswissenschaft ist nur mit einem bodenst√§ndigen Verst√§ndnis von Daten und Statistik m√∂glich. Das gilt einerseits f√ºr die Forschung, die selbst quantitativ sein kann, mindestens aber voraussetzt, quantitative Studien lesen und verstehen zu k√∂nnen. Es gilt andererseits aber auch f√ºr die Berufspraxis: Viele Berufe erfordern heute ein gutes Verst√§ndnis von Daten oder sogar einen sicheren Umgang damit.\nVor diesem Hintergrund verfolgt diese Veranstaltung zwei zentrale Ziele:",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#lernziele",
    "href": "Einleitung.html#lernziele",
    "title": "1¬† Willkommen zum Kurs",
    "section": "",
    "text": "Wir wollen Ihnen die statistischen Grundlagen vermitteln, die Sie im weiteren Verlauf Ihres Studiums ben√∂tigen werden, zum Beispiel in der Veranstaltung ‚ÄûErhebung quantitativer Daten‚Äú, m√∂glicherweise aber auch in der PSP oder einem anschlie√üenden Masterstudium.\nWir wollen Ihnen die Werkzeuge an die Hand geben, die Sie ben√∂tigen, um vielf√§ltige Arbeiten mit Daten auszu√ºben. Konkret bedeutet das, dass Sie lernen, Daten computergest√ºtzt aufzubereiten (also in ein verwertbares Format bringen), zu beschreiben und zu visualisieren. Dazu werden wir R benutzen.\n\n\n\n\n\n\n\nWas ist R?\n\n\n\nR ist ein Open-Source-Programm, das hei√üt, Sie k√∂nnen es kostenfrei nutzen. R zeichnet sich durch eine sehr aktive Community aus, diezahlreiche, ebenfalls kostenfreie, Erweiterungen entwickelt haben. In R nennen wir diese Erweiterungen Pakete. Einige davon werden wir im Lauf der Veranstaltung kennenlernen. R ist aber auch eine Programmiersprache mit einem Schwerpunkt auf statistisches Programmieren. Aber keine Sorge: Sie ben√∂tigen f√ºr diesen Kurs weder Vorkenntnisse in Statistik noch Informatik. Die wichtigsten Grundlagen bringen wir Ihnen bei. Weniger bedrohlich k√∂nnte man auch sagen, dass R einfach ein sehr guter und umfangreicher Taschenrechner ist.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#ablauf-und-aufbau-des-kurses",
    "href": "Einleitung.html#ablauf-und-aufbau-des-kurses",
    "title": "1¬† Willkommen zum Kurs",
    "section": "1.2 Ablauf und Aufbau des Kurses",
    "text": "1.2 Ablauf und Aufbau des Kurses\nDer Kurs ist so konzipiert, dass Sie die Inhalte zwischen den Pr√§senzsitzungen selbstst√§ndig erarbeiten. Die Sitzungen werden wir dann nutzen, um das Erlernte zu √ºben. Sie sollten also gut vorbereitet kommen! Als Grundlage dazu dient dieses Dokument. Jedes Kapitel erl√§utert die Inhalte einer Woche.\nIn den ersten Sitzungen werden wir uns Zeit f√ºr die Grundlagen nehmen, die Sie im Lauf des Semester immer wieder ben√∂tigen werden. Dazu z√§hlen auch einige Grundlagen der Statistik. In den sp√§teren Sitzungen werden wir uns dann mit konkreten statistischen Verfahren besch√§ftigen. Auch hier werden wir uns sowohl mit der Statistik an sich besch√§ftigen, als auch mit der Umsetzung in R.\nNachfolgenden finden Sie einen tabellarischen Ablauf der Sitzung\n\n\n\n\n\n\n\n\nDatum\nInhalt\nVorbereitung\n\n\n\n\n15.10.\n\nLernziele\nAblauf und Aufbau des Kurses\nR und RStudio installieren\nProjekt anlegen\nSkript anlegen und speichern\n\n-\n\n\n22.10.\n\nObjekte (Objekte deklarieren, Objekte benennen, Objekttypen)\nDatens√§tze (Daten erstellen, Objekte in Datens√§tzen ansprechen, Daten einlesen)\nFunktionen (Argumente und R√ºckgabe von Funktionen, Funktionen ausf√ºhren, Funktionen verschachteln)\n\nKapitel 2\n\n\n29.10.\n\nPakete installieren und Pakete laden\nDatentransformation\n\nKapitel 3\n\n\n05.11.\n\nSkalenniveaus und zenrtale Lagema√üe\ndeskriptive Datenanylse\n\nKapitel 4\n\n\n12.11.\n\nHypothesen (Alternativ- und Nullhypothese, Arten von Hypothesen)\nTesttheorie (p-Werte, statistische Signifikanz, statistische Power)\n\nKapitel 5\n\n\n19.11.\n\nZusammenh√§nge zwischen zwei nominalen Variablen testen (Kreuztabellen)\nZusammenh√§nge zwischen metrischen oder ordinalen Daten testen (Korrelationen)\n\nKapitel 6\n\n\n26.11.\ntba\n\n\n\n03.12.\ntba\n\n\n\n10.12.\ntba\n\n\n\n17.12.\ntba\n\n\n\n24.12.\nvorlesungsfrei üéÖ\n\n\n\n31.12.\nvorlesungsfrei üéÜ ü•≥\n\n\n\n07.01.\ntba\n\n\n\n14.01.\ntba\n\n\n\n21.01.\ntba\n\n\n\n28.01.\ntba\n\n\n\n04.02.\ntba",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#r-herunterladen",
    "href": "Einleitung.html#r-herunterladen",
    "title": "1¬† Willkommen zum Kurs",
    "section": "1.3 R herunterladen",
    "text": "1.3 R herunterladen\nBevor es losgehen kann, m√ºssen Sie R auf Ihrem Laptop installieren. Die beste Anlaufstelle daf√ºr ist CRAN (The Comprehensive R Archive Network): https://cran.r-project.org/\nOben mittig auf der Seite k√∂nnen Sie Ihr Betriebssystem ausw√§hlen.\n\nWenn Sie Windows nutzen, klicken Sie auf ‚Äúbase‚Äù und starten dann auf der n√§chsten Seite den Download.\nWenn Sie MacOS nutzen, m√ºssen Sie darauf achten, die f√ºr Ihr System korrekte R-Version herunterzuladen.\n\nNachdem Sie R heruntergeladen und installiert haben, k√∂nnten Sie im Prinzip loslegen. Allerdings ist die Nutzeroberfl√§che von R nicht gerade leicht verst√§ndlich. Darum arbeiten wir in diesem Kurs mit RStudio. Hierbei handelt es sich um eine sogenannte integrierte Entwicklungsumgebung, die das Arbeiten mit R deutlich leichter macht. Sie k√∂nnen es auf https://posit.co/download/rstudio-desktop/ herunterladen. W√§hlen Sie auch hier die f√ºr Ihr Betriebssystem ausgegebene Version herunter und installieren diese.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#in-rstudio-arbeiten",
    "href": "Einleitung.html#in-rstudio-arbeiten",
    "title": "1¬† Willkommen zum Kurs",
    "section": "1.4 In RStudio arbeiten",
    "text": "1.4 In RStudio arbeiten\n\n1.4.1 Die Nutzeroberfl√§che von RStudio\nWenn Sie auch RStudio installiert haben, kann es endlich losgehen. Wenn Sie das Programm das erste Mal √∂ffnen, werden Sie gefragt, welche R-Version genutzt werden soll. Hier k√∂nnen Sie angeben, dass die System-Standardversion genutzt werden soll. Das bedeutet auch: Immer, wenn Sie RStudio √∂ffnen, wird R im Hintergrund ebenfalls gestartet. Sie m√ºssen also nicht beide Programme √∂ffnen!\nAnschlie√üend sollte Ihr Programm in etwa so aussehen, wie auf dem Screenshot unten.\n\n\n\nScreenshot RStudio\n\n\nLinks sehen Sie die Konsole. Hier zeigt R Ihnen, welche Befehle ausgef√ºhrt wurden und was das Ergebnis ist. Sie k√∂nnen auch direkt Befehle eingeben, aber dazu unten mehr. Oben rechts sehen Sie das sogenannte Environment. Hier finden Sie Objekte, die Sie angelegt haben. Ein Objekt kann erstmal alles m√∂gliche sein, z.B. ein Datensatz, eine Variable oder eine Funktion. Im Lauf des Kurses werden wir darauf noch genauer eingehen. Das Feld unten rechts erf√ºllt mehrere Funktionen. Die zwei wichtigsten verbergen sich hinter den Reitern Plots und Help. Die Namen sind relativ selbsterkl√§rend: Unter Plots werden uns Grafiken gezeigt, die wir in R erstellen und unter Help finden wir Hilfe. Beides ist im Moment noch nicht relevant f√ºr uns, aber wir werden sp√§ter darauf zur√ºckkommen.\n\n\n1.4.2 Die Konsole\nZun√§chst schauen wir uns die Konsole etwas genauer an. Hier k√∂nnen Sie direkt mit R interagieren. Durch das Gr√∂√üer-als-Zeichen (&gt;) am Anfang der untersten Zeile signalisiert R Ihnen, dass Sie Befehle ausf√ºhren k√∂nnen. Wenn Sie z.B. einfache Rechnungen in der Konsole eingeben und mit Enter best√§tigen, wird R Ihnen das Ergebnis ausgeben. Die [1] k√∂nnen Sie zun√§chst ignorieren. Dazu kommen wir sp√§ter noch. Daneben sollte nun das Ergebnis der Rechnung stehen, so wie in den folgenden Zeilen:\n\n3+2 \n\n[1] 5\n\n\nEs kann vorkommen, dass Sie in der untersten Zeile der Konsole nicht das Gr√∂√üer-als-Zeichen sehen, sondern ein Plus. Das passiert immer dann, wenn Sie einen unvollst√§ndigen Befehl ausf√ºhren wollen. Geben Sie z.B. nur 17- ein und versuchen, den Befehl auszuf√ºhren, wird R Ihnen ein ‚Äú+‚Äù anzeigen, da es nicht wei√ü, was von 17 abgezogen werden soll. Sobald Sie eine zweite Zahl eingeben und mit Enter best√§tigen, wird Ihnen das Ergebnis angezeigt. Wenn Sie das ‚Äú+‚Äù einmal sehen, aber nicht wissen, woher es kommt bzw. welcher Befehl unvollst√§dnig war, k√∂nnen Sie einfach irgendetwas in die Konsole eingeben, mit Enter best√§tigen und sich dann auf die Suche nach dem Fehler machen.\nMit diesem Wissen k√∂nnten wir so ziemlich alle Funktionalit√§ten von R nutzen, es w√§re aber ziemlich unpraktisch. Zwar speichert R den Verlauf unserer Sitzung (verborgen hinter dem Reiter History, oben rechts neben Environmen‚Äù), das Format ist aber nicht sonderlicht gut dazu geeignet, unsere Berechnungen und Analysen wiederverwertbar festzuhalten.\n\n\n1.4.3 Arbeit in Projekten\nEine gute M√∂glichkeit, Ihre Arbeit in R festzuhalten, sind Projekte.Diese haben den Vorteil, dass alle relevanten Dateien an einem Ort geb√ºndelt und durch eine spezielle R-Datei verbunden werden. Das macht zum Beispiel das Laden von Datens√§tzen deutlich einfacher. Als erstes sollten Sie daher ein Projekt f√ºr diesen Kurs anlegen.\nDazu klicken Sie zun√§chst rechts oben auf ‚ÄúProjekte‚Äù und dann ‚ÄúNeues Projekt‚Äù\n\nAls n√§chstes werden Sie gefragt, ob Sie einen einen neuen Ordner anlegen oder vorhandenen Ordner verwenden m√∂chten. Falls Sie noch keinen Ordner f√ºr diesen Kurs angelegt haben, w√§hlen Sie die erste Option, anderfalls die zweite.\n\nSofern Sie einen neuen Ordner angelegt haben, klicken Sie nun auf ‚ÄúNeues Projekt‚Äù.\n\nZuletzt m√ºssen Sie dem Ordner noch einen Namen geben und angeben, wo er angelegt werden soll und abschlie√üend das Projekt anlegen.\n\n\n\n1.4.4 Skripte\nSkripte sind Datein, in dene Sie R-Code schreiben und speichern k√∂nnen. Der gro√üe Vorteil daran ist, dass Sie Ihre Arbeit so dokumentieren und jederzeit wiederholen oder ver√§ndern k√∂nnen, ohne alles von vorne in der Konsole eingeben zu m√ºssen. Um ein Skript anzulegen, klicken Sie oben links auf File ‚Äì&gt; New File ‚Äì&gt; R Script. Nun √∂ffnet sich √ºber der Konsole das (noch leere) Skript. Speicher Sie es am besten direkt ab, entweder √ºber die Men√ºleiste (File ‚Äì&gt; Save) oder wie in anderen Programmen per Tastatur:  + SS. Praktischerweise schl√§gt R direkt den Ordner vor, in dem wir gerade arbeiten, sprich den vorhin angelegten Projektordner.\nIm Skript k√∂nnen Sie nun R-Code schreiben. Um eine Code-Zeile auszuf√ºhren k√∂nnen Sie entweder gleichzeitig  + EnterEnter dr√ºcken, oder oben rechts direkt √ºber dem Skript auf ‚ÄúRun‚Äù klicken. R f√ºhrt den Befehl in der aktuellen Zeile aus und springt zum n√§chsten Befehl. Manchmal erstrecken sich Befehle √ºber mehrere Zeilen, aber das ist kein Problem. R ist ziemlich gut darin, zu erkennen, wann ein Befehl aufh√∂rt und wo der n√§chste beginnt. Zumindest solange Sie keinen Fehler in Ihrem Code haben.\nDas Ergebnis wird Ihnen in der Konsole angezeigt. Probieren Sie es doch mal mit der Addition von oben aus: 3+2\nDamit Sie zuk√ºnftig in Ihren Skripten nicht den √úberblick verlieren, sollten Sie sich angew√∂hnen, Kommentare zu schreiben. Dazu k√∂nnen Sie das Hashtag- bzw. Doppelkreuzzeichen `#` verwenden. Alles was in einer Zeile hinter diesem Zeichen steht, wir von R nicht interpretiert, sondern dient lediglich Ihnen und allen anderen, die den Code lesen, als Erkl√∂rung oder Erinnerungsst√ºtze. Jetzt am Anfang mag das noch etwas albern wirken, aber untersch√§tzen Sie nicht, wie wertvoll es sein kann, nach einer l√§ngeren Pause an einem Skript eine gute Dokumentation vorzufinden!\nAb der kommenden Woche werden wir intensiv(er) in Skripten arbeiten. Die ersten Kapitel k√∂nnen Sie noch gut in einem Skript bearbeiten. F√ºr die sp√§teren Kapitel empfiehlt es sich, jeweils ein neues Skirpt anzulegen, damit Sie den √úberblick nicht verlieren.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#ressourcen",
    "href": "Einleitung.html#ressourcen",
    "title": "1¬† Willkommen zum Kurs",
    "section": "1.5 Ressourcen",
    "text": "1.5 Ressourcen\nR ist sehr komplex und kann nicht innerhalb eines Semesters gemeistert werden. Wie oben erw√§hnt, lernen Sie in dieser Veranstaltung einige wichtige Grundlagen. Die ersten davon haben Sie heute schon gelernt. Dennoch werden Sie in den n√§chsten Wochen und Monaten einiges an Informationen verarbeiten m√ºssen. Ihre erste Anlaufstelle daf√ºr ist dieses Dokument und die Pr√§senz√ºbungen. Aber niemand nimmt es Ihnen √ºbel, wenn Sie dar√ºber hinaus weitere Hilfe ben√∂tigen oder in Anspruch nehmen!\nDie meisten Probleme, die Sie haben werden, hatten vor Ihnen schon unz√§hlige andere R-Lerner:innen und gl√ºcklicherweise hat R eine sehr aktive und hilfsbereite Community, die Ihnen jederzeit weiterhelfen kann. Beispielsweise finden sich in einigen sozialen Netzwerken wie X/Twitter (#rstats) und Reddit (/r/rstats) informelle R-Gruppen, die einander Fragen beantworten. Wenn Sie ein Problem oder eine Fehlermeldung googeln, werden Sie f√ºher oder sp√§ter auch Ergebnisse von StackOverflow finden, einem Forum f√ºr Programmierer:innen. Und keine Sorgen: Niemand erwartet von Ihnen, dass Sie sich aktiv in die Community einbringen!\nDar√ºber hinaus gibt es zahlreiche Lehrb√ºcher und Online-Kurse √ºber R. Untenstehend finden Sie einige davon:\n\nR f√ºr Einsteiger von Maike Luhmann (Zugriff √ºber das Uninetz)\nLearning Statistics with R von Danielle Navarro\nEine Sammlung H√§ufig verwendeter Datenvisualisierungen\n√Ñhnliche R-Kurse aus Bremen und Hamburg\n\nFalls Sie in diesen Quellen nicht f√ºndig werden, spricht prinzipiell auch nichts gegen den Einsatz von KI, also zum Beispiel gro√üe Sprachmodelle wie ChatGPT. Hiermit erhalten Sie ganz offiziell die Erlaubnis, davon im Rahmen dieses Kurses gebrauch zu machen! Seien Sie bitte trotzdem vorsichtig: Nicht jeder von ChatGPT und √§hnlichen Anwendungen erstellte R-Code tut das was Sie wollen oder sich vorgestellt haben. Pr√ºfen Sie die Code daher stets auf Herz und Nieren, bevor Sie ihn als richtig akzeptieren.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html",
    "href": "Objekte, Daten, Funktionen.html",
    "title": "2¬† Objekte, Daten, Funktionen",
    "section": "",
    "text": "2.1 Objekte\nIm letzten Kapitel haben Sie bereits zwei wichtige Dinge √ºber Objekte erfahren:\nIn diesem Kapitel lernen Sie, wie Sie Objekte deklarieren, wie Objekte benannt sein sollten und welche Objekttypen es gibt.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#objekte",
    "href": "Objekte, Daten, Funktionen.html#objekte",
    "title": "2¬† Objekte, Daten, Funktionen",
    "section": "",
    "text": "Objekte k√∂nnen erst einmal alles m√∂gliche sein, z.B. einzelne Variablen oder ganze Datens√§tze.\nObjekte werden im Environment angezeigt.\n\n\n\n2.1.1 Objekte deklarieren\nSie k√∂nnen Objekte erstellen und ihnen einen Wert zuzuweisen, indem Sie einen Namen f√ºr das Objekt in ihr Skript schreiben, daneben einen Pfeil (&lt;-) und danach den Wert des Objektes deklarieren.1\nSo wie hier:\n\n# Erstellt die Objekte x und y mit den Werten 3 und 6\n\nx &lt;- 3\ny &lt;- 6\n\nMit diesem Code haben wir zwei Objekte erstellt: Das Objekt x mit dem Wert 3 und das Objekt y mit dem Wert 6. Mit diesen Objekten k√∂nnen wir jetzt weiterarbeiten, z.B. indem wir sie addieren. Indem wir z noch mal einzeln in eine Zeile schreiben, k√∂nnen wir uns den Wert direkt in der Konsole anzeigen lassen.\n\n# Berechnet das Objekt z aus den Objekten x und y\nz &lt;- x+y\n\n# Zeigt den Wert von z in der Konsole an\nz\n\n[1] 9\n\n\nWenn wir jetzt den Wert von x oder y √§ndern, √§ndert sich durch erneutes Ausf√ºhren des Befehls auch der Wert von z.\n\n# Der Wert von x wird ge√§ndert\nx &lt;- 7\n\n# z wird neu berechnet\nz &lt;- x+y\nz\n\n[1] 13\n\n\nDie Objekte x, y und z sind bisher jeweils nat√ºrliche (also ganze) Zahlen. Sie k√∂nnen aber auch andere Zahlen erstellen, z.B. negative Zahlen oder Zahlen mit Dezimalstellen:\n\n# x und y werden neue Werte zugewiesen, die keine ganze Zahlen sind. \nx &lt;- -7\ny &lt;- 6.5\n\n\n# z wird neu berechnet\nz &lt;- x+y\nz\n\n[1] -0.5\n\n\nJetzt haben wir x den Wert -7 und y den Wert 6,5 zugewiesen. Beachten Sie, dass wir einen Punkt als Dezimalzeichen genutzt haben! Entsprechend dieser Zuweisungen ist z nun -0,5.\nObjekte k√∂nnen auch andere Werte als Zahlen enthalten, z.B. Zeichenketten, sogenannte strings.\n\n# Ein String der \"name\" hei√üt wird erstellt und mit dem Wert \"Hans\" versehen\n\nname &lt;- \"Hans\"\n\n\n\n\n\n\n\nTipp\n\n\n\nWenn Sie in RStudio Anf√ºhrungszeichen setzen wollen, geht das um einiges einfacher als z.B. in Word. Wenn Sie in einem Skript z.B. ShiftShift + 22dr√ºcken, werden gleich Anf√ºhrungszeichen f√ºr den Anfang und das Ende des strings gesetzt, sodass Sie daziwschen Ihren Text platzieren k√∂nnen. Sie k√∂nnen aber auch jeden vorhandenen Text markieren und dann ShiftShift + 22 dr√ºcken und es werden Anf√ºhrungszeichen um den Text herum gesetzt.\n\n\nOhne weitere Funktionen haben wir allerdings deutlich weniger M√∂glichkeiten, mit strings zu arbeiten. Wir k√∂nnen Sie z.B. nicht ohne Weiteres kombinieren.\n\n\n2.1.2 Objektnamen\nBisher haben wir unseren Objekten sehr einfache Namen gegeben, die nicht sonderlich hilfreich sind und w√ºrden wir nur bei einfachen Buchstaben bleiben, gingen uns bald die Namens aus. Darum empfiehlt es sich, andere Namen zu verwenden. Welche das konkret sind, ist Ihnen √ºberlassen. R gibt allerdings einige Regel vor:\n\nGrunds√§tzlich sind Zahlen, Punkte, Binde- und Unterstriche und Buchstaben erlaubt.\nUmlaute, Sonderzeichen (exkl. Punkte, Binde- und Unterstriche) und Leerzeichen sind nicht erlaubt.\nObjektnamen m√ºssen mit einem Buchstaben beginnen.\nObjektnamen beachten Gro√ü- und Kleinschreibung.\nObjektnamen sind einzigartig. Das hei√üt, wenn Sie zwei Objekten nacheinander gleich benennen, wird das Zweite das Erste √ºberschreiben.\nTRUE und FALSE sind als Namen verboten, da es sich hierbei um sogenannte boolesche Operatoren handelt. Da Sie mit T und F abgek√ºrzt werden k√∂nnen, sollten auch diese Namen vermieden werden. Was genau es damit auf sich hat, werden wir im Lauf der Veranstaltung lernen.\n\nDar√ºber hinaus gibt es einige sinnvolle Konventionen, an die Sie sich halten sollten:\n\nAnschlie√üend an den Ausschluss von TRUE und FALSE bzw. T und F, sollten Namen vermieden werden, die schon anderweitig vergeben sind, z.B. durch Funktionen.\nObjektnamen sollten so gew√§hlt sein, dass sie auch nach einer l√§ngeren Pause noch wissen, was sich hinter einem Objekt verbirgt. In einigen F√§llen ist das relativ einfach. Wenn Sie zum Beispiel im Rahmen einer Befragung das Alter der Befragten erhoben haben, k√∂nnen Sie die entsprechende Variable einfach Alter nennen. Manchmal wird es aber auch schwieriger. Wenn Sie zum Beispiel die Einstellung der Befragten zur Statistik √ºber mehrere Fragen erhoben haben, empfielt es sich, einen gemeinsamen Pr√§fix zu verwenden, z.B. einstellungStatistik und dann eine Zahl. So wissen Sie zwar nicht mehr unbedingt, was der genaue Wortlaut der Frage war, aber Sie sollten die Variable schnell wiedererkennen k√∂nnen.\nEs gibt verschiedene Konventionen zu l√§ngeren Objektnamen. Im vorherigen Punkt wurde z.B. der Konvention gefolgt, das erste Wort klein und das darauffolgende (bzw. alle weiteren Worte) gro√ü zu schreiben. Genauso gut k√∂nnten Sie die Worte anders kenntlich machen, z.B. so: einstellung_statistik. Manchmal sieht man auch Dinge wie einstellung.statistik, EINSTELLUNG_STATISTIK, einstellung-statistik oder EinstellungStatistik. Wie sie es machen, ist Ihnen √ºberlassen, aber versuchen Sie sich an eine dieser Konventionen zu halten.\n\n\n\n2.1.3 Objekttypen\nBisher haben wir unseren Objekten nur einfache Zahlenwerte bzw. einen string zugewiesen. Man kann diese Objekte auch einfach Variablen nennen. Aber Vorsicht: Der Begriff ist gewisserma√üen zwedeutig: In der Programmierlogik von R nennen bezeichnen wir Objekte als Variable, wenn wir dort etwas Speichern, das wir irgendwie variieren k√∂nnen. In der Statistik meint der Begriff dagegen in der Regel eine Sache, √ºber die wir Daten gesammelt haben. Also zum Beispiel eine Frage im Fragebogen oder eine Kategorie in der Inhaltsanalyse.\nDie sehr einfachen Variablen, die wir oben angelegt haben, kommen in der Praxis relativ selten vor. Stattdessen haben wir es h√§ufig mit einer ganzen Abfolge von Zahlen (oder strings) zu tun, z.B. wenn wir Daten einer Stichprobe erhoben haben.\nGl√ºcklicherweise m√ºssen wir nicht f√ºr jede Antwort jeder Person ein eigenes Objekt erstellen, sondern k√∂nnen sogenannte Vektoren verwenden. Hierbei handelt es sich um Objekte, die aus verschiedenen Elementen zusammengesetzt sind. Vektoren sind so etwas wie das R√ºckgrat von R, da viele Dinge intern als Vektoren behandelt werden, z.B. einzelne Zeilen oder Spalten in einer Tabelle. Entsprechend sind auch viele Funktionen in R darauf ausgelegt, auf Vektoren angewendet zu werden. Wir werden sie uns daher etwas genauer ansehen.\nVektoren k√∂nnen zum Beispiel mit der Funktion (dazu unten mehr) c() erstellt werden. Das c steht dabei f√ºr ‚Äúcombine‚Äù. Die einzeknen Elemente werden mit einem Komma getrennt.\n\n# Erstellt den Vektor \"Zahlen\", der die Zahlen von 1 bis 10 enth√§lt\n\nzahlen &lt;- c(1,2,3,4,5,6,7,8,9,10)\n\nIn diesem Beispiel haben wir einen Vektor namens zahlen erstellt, der die Zahlen von 1 bis 10 enth√§lt. In solch einfachen F√§llen gibt es √ºbrigens einen kleinen Trick und zwar den Doppelpunkt:\n\n# Erstellt den Vektor \"zahlenAnders\", der ebenfalls die Zahlen von 1 bis 10 enth√§lt\n\nzahlenAnders &lt;- 1:10\n\nMit diesem Befehl sagen wir R, dass alle Zahlen von 1 bis einschlie√ülich 10 in einem Vektor kombiniert werden sollen, ohne jede Zahl einzeln aufschreiben zu m√ºssen.\nVielleicht ist Ihnen aufgefallen das die beiden Vektoren zahlen und zahlenAnders im Environment leicht unterschiedlich dargestellt werden. F√ºr den Moment k√∂nnen wir das jedoch ignorieren.\n\nDie einzelnen Zahlen in den oben angelegten Vektoren, werden als Elemente bezeichnet. Sie k√∂nnen einzeln angew√§hlt und ggf. manipuliert werden. Daf√ºr nutzen wir sogenannte Indizes. Hier kommt die [1] ins Spiel, die wir im letzten Kapitel ignoriert haben. Damit hat uns R signalisiert, dass das Ergebnis hinter dieser [1] das erste Element eines Vektors war. Da es nur ein Element gab, wirkt das zun√§chst etwas √ºberfl√ºssig. In machen Situationen kann es aber vorkommen, dass das Ergebnis eines Befehls mehrere Elemente enth√§lt. Und in wieder anderen Situationen kann es sinnvoll sein, einzelne Elemente eines Vektors direkt anzusprechen. Das geht ebenfalls mit eckigen Klammern. Beispielsweise lassen wir hier das dritte Element des Vektors zahlen anzeigen.\n\n# Das dritte Element von \"zahlen\" wird ausgegeben\n\nzahlen[3]\n\n[1] 3\n\n\nWir k√∂nnen das Element auch √§ndern:\n\n# Das dritte Element von \"zahlen\" wird ge√§ndert und dann ausgegeben\n\nzahlen[3] &lt;- 9\nzahlen[3]\n\n[1] 9\n\n\nUnd genauso, wie wir oben die Zahlen von 1 bis 10 in einen Vektor geschrieben haben, k√∂nnen wir uns auch mehrere Elemente eines Vektors anzeigen lassen, z.B. die ersten drei Elemente:\n\n# Zeigt die ersten drei Elemente von \"zahlen\" an\n\nzahlen[1:3]\n\n[1] 1 2 9\n\n\nOder das erste, zweite und f√ºnfte Element, indem wir die c()-Funktion von oben verwenden:\n\n# Zeigt die ersten beiden und das f√ºnfte Element von \"zahlen\" an\n\nzahlen[c(1:2, 5)]\n\n[1] 1 2 5\n\n\nWir k√∂nnen auch mehrere Elemente auf einmal √§ndern. Dabei m√ºssen wir aber allerdings ein paar Dinge beachten:\n\nWir k√∂nnen entweder alle Elemente durch einen Wert ersetzen:\n\n\n# √Ñndert alle Werte in \"zahlen\" zu 1\n\nzahlen[1:10] &lt;- 1\nzahlen\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\n\n\nOder so viele Werte, dass die Anzahl der alten Werte ein vielfaches der Anzahl der neuen Werte sind (z.B. 5 neue auf die 10 alten Werte). Die neuen Werte werden dann so lange wiederholt, bis der Vektror wieder dieselbe L√§nge hat:\n\n\n# Die Werte in \"zahlen\" werden durch die Werte von 1 bis 5 ersetzt und dann angezeigt\n\nzahlen[1:10] &lt;- 1:5\nzahlen[1:10]\n\n [1] 1 2 3 4 5 1 2 3 4 5\n\n# Die Werte in \"zahlen\" werden durch die Werte von 1 und 2 ersetzt und dann angezeigt\n\nzahlen[1:10] &lt;- 1:2\nzahlen[1:10]\n\n [1] 1 2 1 2 1 2 1 2 1 2\n\n\n\nOder genauso viele Werte angeben, wie wir ersetzen wollen:\n\n\n# Die Werte in \"zahlen\" werden durch die Werte von 10 bis 1 ersetzt und dann angezeigt\n\nzahlen[1:10] &lt;- c(10,9,8,7,6,5,4,3,2,1)\nzahlen[1:10]\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nNach denselben Regeln k√∂nnen wir auch mit den Vektoren rechnen. Wenn Sie in Ihrem Skript die obigen Befehle der Reihe nach ausgef√ºllt haben, sollten Ihre beiden Vektoren nun die Werte von 10 bis 1 (zahlen) bzw. 1 bis 10 (zahlenAnders) haben:\n\n# Zeigt die Vektoren \"zahlen\" und \"zahlenAnders\" an\n\nzahlen\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\nzahlenAnders\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWir k√∂nnen nun entweder eine einzelne Zahl nehmen und sie zu einem Vektor addieren, davon subtrahieren, dadurch Teilen oder die beiden multiplizieren:\n\n# Addiert y (6,5) zu den Elementen von \"zahlen\"\nzahlen+y\n\n [1] 16.5 15.5 14.5 13.5 12.5 11.5 10.5  9.5  8.5  7.5\n\n# Subtrahiert y von den Elementen von \"zahlen\"\nzahlen-y\n\n [1]  3.5  2.5  1.5  0.5 -0.5 -1.5 -2.5 -3.5 -4.5 -5.5\n\n# Multipliziert y mit den Elementen von \"zahlen\"\nzahlen*y\n\n [1] 65.0 58.5 52.0 45.5 39.0 32.5 26.0 19.5 13.0  6.5\n\n# Dividiert die Elementen von \"zahlen\" durch y \nzahlen/y\n\n [1] 1.5384615 1.3846154 1.2307692 1.0769231 0.9230769 0.7692308 0.6153846\n [8] 0.4615385 0.3076923 0.1538462\n\n\nOder eine Anzahl, die so gro√ü ist, dass die Anzahl der Elemente des Vektors ein Vielfaches davon ist:\n\n# Subtrahiert 1 bsi 5 von den Elementen von \"zahlen\"\n\nzahlen - 1:5\n\n [1]  9  7  5  3  1  4  2  0 -2 -4\n\n\nOder wir nutzen einen Vektor der genauso lang ist:\n\n# Addiert \"zahlen\" und \"zahlenAnders\"\n\nzahlen + zahlenAnders\n\n [1] 11 11 11 11 11 11 11 11 11 11\n\n\nWie oben bereits erw√§hnt, kommt man in R schon ziemlich weit, wenn man ein gutes Verst√§ndnis von Vektoren mitbringt. In diesem Abschnitt haben Sie einige Basics gelernt, die Ihnen bei der Arbeit mit R immer wieder begegnen werden.\nNeben Vektoren gibt es noch zwei weitere Objekttypen, die Ihnen in Ihrer Arbeit mit R begegnen werden. Der erste ist die Liste. Der Name ist relativ selbsterkl√§rend: Es handelt sich dabei um eine Liste von Elementen. Der Unterschied zum Vektor ist, dass Listenelemente alles Denkbare sein k√∂nnen. Also z.B. einzelne Werte wie x, y, z und name von oben, aber auch Vektoren wie zahlen und zahlenAnders. Sogar ganze Datens√§tze k√∂nnen Teil einer Liste sein! Am h√§ufgisten werden Ihnen Listen als Ergebnis von statistischen Berechnungen begnen, aber Sie k√∂nnen mit der list()-Funktion auch selber welche anlegen. Hier in Beispiel:\n\n# Erstellt eine Liste aller bisher erstellten Elemente\n\nwasBisherGeschah &lt;- list(x, y, z, name, zahlen, zahlenAnders)\n\nIn dieser Liste haben wir alle bisher erstellten Objekte zusammengefasst. √Ñhnlich wie bei den Vektoren, k√∂nnen wir auch Listenelemente direkt √ºber einen Index anprechen. Diesmal nutzen wir aber doppelte Klammren: [[]]. Zum Beispiel k√∂nnen wir so das vierte Element ausgeben lassen:\n\n# Zeigt das vierte Element der Liste an\n\nwasBisherGeschah[[4]]\n\n[1] \"Hans\"\n\n\nWir k√∂nnen auch erst ein bestimmtes Listenelement ansprechen und dann ein darin enthaltenes Element:\n\n# Zeigt das vierte Element des f√ºnften Elements der Liste an\n\nwasBisherGeschah[[5]][4]\n\n[1] 7\n\n\nEin Vorteil von Listen ist, dass die Elemente darin benannt sein k√∂nnen. Und tats√§chlich werden wir benannte Listen in der Realit√§t deutlich h√§ufiger antreffen. Wenn Sie selber eine benannte Liste erstellen wollen, gehen Sie √§hnlich vor wie beim Deklarieren von Objekten. Allerdings nutzen Sie dabei nicht den Pfeil, sondern ein Gleichheitszeichen. In diesem Beispiel behalten wir die Namen von oben bei:\n\n# Erstellt eine Liste mit Namen\n\nwasBisherWirklichGeschah &lt;- list(x = x, y = y, z = z,\n                                 name = name, zahlen = zahlen,\n                                 zahlenAnders = zahlenAnders)\n\nNamen f√ºr Listenelemente haben den gro√üen Vorteil, dass wir uns nicht merken m√ºssen, an welcher Stelle ein bestimmtes Element auftaucht. Stattdessen k√∂nnen wir es ganz einfach √ºber das Dollarzeichen ($) ansprechen. Dazu schreiben Sie erst den Namen der Liste, dann ein $ und dann den Namen des Elements. Auch hier k√∂nnen Sie wieder einen Index nutzen, um nur bestimmte Elemente anzusprechen:\n\n# zeigt das Element \"zahlenAnders\" der Liste \"wasBisherWirklichGeschah\" an\n\nwasBisherWirklichGeschah$zahlenAnders\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# zeigt das f√ºnfte Element des Element \"zahlenAnders\" der Liste \"wasBisherWirklichGeschah\" an\n\nwasBisherWirklichGeschah$zahlenAnders[5]\n\n[1] 5\n\n\n\n\n\n\n\n\nObjekte inspizieren\n\n\n\nSie haben verschiedene M√∂glichkeiten, mehr √ºber Objekte im Environment zu erfahren. Insbesondere im Kontext von Listen kann das manchmal sehr n√ºtzlich sein. Die beiden soeben erstellten Listen haben im Environment einen kleinen blauen Pfeil neben ihrem Namen. Dort k√∂nnen Sie draufklicken, um die Elemente der Liste zu sehen:\n\nSie k√∂nnen aber auch auf den Namen klicken. Dann √∂ffnet sich oben im Editor (da wo Sie Ihr Skript schreiben) ein neues Tab, in dem Sie sich das Objekt genauer ansehen k√∂nnen.\n\n\nDer letzte Objektyp ist der, wegen dem wir eigentlich hier sind: Datens√§tze. Wir werden Sie uns nun etwas genauer ansehen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#datens√§tze",
    "href": "Objekte, Daten, Funktionen.html#datens√§tze",
    "title": "2¬† Objekte, Daten, Funktionen",
    "section": "2.2 Daten(s√§tze)",
    "text": "2.2 Daten(s√§tze)\nIn der Wissenschaft haben wir es in der Regel mit Daten zu tun. Soweit so gut. Aber was sind Daten eigentlich genau? Die Frage mag auf den ersten Blick trivial erscheinen, ist aber erstaunlich komplex. Beispielsweise k√∂nnten Sie im Rahmen einer qualitativen Studie Interviews mit Menschen f√ºhren, diese transkribieren und h√§tten dann Daten in Textform vorliegen. Aber w√§re das Ihr erster Gedanke, wenn Sie danach gefragt werden, was Daten eigentlich genau sind? Tats√§chlich haben diese Art von Daten, also qualitative Daten, relativ wenig mit dem zu tun, was wir in diesem Kurs machen. Wir besch√§ftigen uns mit quantitativen Daten. Weil dieser Ausdruck auf Dauer etwas sperrig ist, k√ºrzen wir ihn hier aber etwas ab und sprechen nur von Daten.\n\n2.2.1 Struktur von Datens√§tzen\nWas also sind denn jetzt Daten im Sinne dieses Kurses? In erster Linie meinen wir mit Daten Informationen, die in Zahlenform vorliegen oder zumindest so repr√§sentiert werden k√∂nnen. Das erlaubt uns, damit zu rechnen. In R werden diese Zahlen meistens als eine Art Tabelle gespeichert. Die meisten von ihnen folgen einem einfachen Muster: Jede Zeile ist ein Fall, jede Spalte eine Variable. Ein Fall ist z.B. ein ausgef√ºllter Fragebogen, ein codierter Medieninhalt oder ein Versuchsdurchlauf eines Experiments. Eine Variable ist z.B. eine Frage aus einem Fragebogen, eine Kategorie aus einem Codebuch oder ein im Experiment gemessener Wert.\n\n\n2.2.2 Datens√§tze erstellen\nWir schauen uns so eine Tabelle mal an einem einfachen Beispiel an, indem wir die data.frame()-Funktion nutzen. √Ñhnlich wie die list()-Funktion, k√∂nnen wir data.frame() nutzen, um ein Objekt aus mehreren vorhandenen Objekten zu erstellen. Auch hier k√∂nnen wir einzelnen Elementen einen Namen geben. Wir nennen diesen Datensatz df (Abk√ºrzung von data frame), ein generischer Name, dem Sie in Beispielen immer mal wieder begenen werden. Andere gel√§ufige Namen sind dat oder data.\n\n# Erstellt den Datensatz df, der 3 Variablen enth√§lt\n\ndf &lt;- data.frame(var1 = zahlen, var2 = zahlenAnders, var3 = zahlenAnders/zahlen)\n\nWenn wir nun den Namen unseres Datensatzes eingeben und die entsprechende Zeile im Skript ausf√ºhren, wird uns die Tabelle angezeigt:\n\n# zeigt df an\n\ndf\n\n   var1 var2       var3\n1    10    1  0.1000000\n2     9    2  0.2222222\n3     8    3  0.3750000\n4     7    4  0.5714286\n5     6    5  0.8333333\n6     5    6  1.2000000\n7     4    7  1.7500000\n8     3    8  2.6666667\n9     2    9  4.5000000\n10    1   10 10.0000000\n\n\n\n\n2.2.3 Elemente von Datens√§tzen\nDadurch, dass Datens√§tze Zeilen und Spalten haben, sind sie zweidimensional. Die Spalten k√∂nnen Sie so ansprechen, wie wir es schon mit der benannten Liste oben gemacht haben (wasBisherWirklichGeschah), sprich mit einem $-Zeichen gefolgt vom Namen:\n\n# zeigt die erste Variable in df an\n\ndf$var1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nAb und zu kann es auch vorkommen, dass Sie eine bestimmte Zeile ansprechen wollen. Dazu k√∂nnen wir wieder Indizes benutzen, allerdings etwas anders als zuvor. Zum Beispiel liefert der Befehl df[1] dasselbe Ergebnis wie df$var1, nur etwas anders dargestellt.\n\n# zeigt jeweils die erste Variable in df an\n\ndf[1]\n\n   var1\n1    10\n2     9\n3     8\n4     7\n5     6\n6     5\n7     4\n8     3\n9     2\n10    1\n\ndf$var1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nEinzelne Zeilen k√∂nnen wir ansprechen, indem wir hinter die Zahl im Index ein Komma schreiben. df[1,] Wir sagen R damit, dass wir am ersten Element der ersten Dimension interessiert sind, die immer links vom Komma steht.\n\n# zeigt die erste Zeile in df an\n\ndf[1,]\n\n  var1 var2 var3\n1   10    1  0.1\n\n\nWir k√∂nnen auch rechts vom Komma eine Zahl erg√§nzen, z.B. wenn wir nur den dritten Wert aus der zehnten Zeile sehen wollen:\n\n# zeigt den Wert aus Zeile 10, Spalte 3 in df an\n\ndf[10,3]\n\n[1] 10\n\n\n\n\n2.2.4 Datens√§tze laden\nAufbauend auf diesen Grundlagen k√∂nnten Sie sich schon einen ganz guten √úberblick √ºber einen Datensatz machen. Aber: Woher bekommen Sie eigentlich Daten und wie werden Daten in R eingelesen? Im weiteren Verlauf dieses Kurses werden mit Daten arbeiten, die hier am Seminar f√ºr Medien- und Kommunikationswissenschaften entstanden sind. Im sp√§teren Verlauf Ihres Studiums werden Sie dann mit Ihren eigenen Daten arbeiten. Das Einlesen in R ist relativ einfach. Sie brauchen dazu nur einen Datensatz und m√ºssen wissen, wo auf Ihrem System er gespeichert ist. Am einfachsten ist es, wenn Sie die Daten im selben Ordner ablegen, wie Ihr R-Projekt. Damit Sie nicht den √úberblick verlieren, ist es sinnvoll, zun√§chst einen Unterordner anzulegen, in dem Sie die Daten ablegen k√∂nnen.\nHier laden wir mit der read.csv()-Funktion einen Datensatz, der von Prof.¬†Dogruel erhoben wurde. Es handelt sich dabei um eine Befragung zur Nutzung von Lokalmedien von Menschen aus Th√ºringen und Rheinland-Pfalz. Sie finden den Datensatz sowie ein zugeh√∂riges Codebook bei Moodle. Letzteres enth√§lt Informationen √ºber die einzelnen Spalten im Datensatz.\n\n# L√§dt den Datensatz \"lokalkommunikation\" und speichert ihn als Objekt namens \"df_lokal\"\n\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\nMit diesem Datensatz werden wir vorerst weiterarbeiten. Im weiteren Verlauf des Kurses werden aber noch weitere Daten dazukommen. Zun√§chst ben√∂tigen wir aber noch ein paar Basics zur Arbeit in R: Grundwissen √ºber sogenannte Funktionen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#funktionen",
    "href": "Objekte, Daten, Funktionen.html#funktionen",
    "title": "2¬† Objekte, Daten, Funktionen",
    "section": "2.3 Funktionen",
    "text": "2.3 Funktionen\nFast alle Aufgaben in R lassen sich mit Hilfe von Funktionen l√∂sen. Einige haben Sie in den vorherigen Abschnitten bereits kennengelernt, z.B. c() und list(). In diesem Abschnitt werden Sie einige weitere kennenlernen, Sie sollen aber vor allem lernen, wie Funktionen eigentlich funktionieren.\n\n2.3.1 Argumente\nDas wichtigste Konzept, das Sie dazu verstehen m√ºssen, sind die sogenannten Argumente. Damit sind Informationen gemeint, die wir einer Funktion √ºbergeben und mit denen sie arbeitet. Argumente werden in Klammern hinter dem Namen der Funktion aufgef√ºhrt. Als wir oben die c()-Funktion genutzt haben, waren dementsprechend die Zahlen, die wir in die Klammern geschrieben haben die Argumente. Und als Sie die Liste erstellt haben, haben Sie die vorher angelegten Objekte als Argumente √ºbergeben.\nBeides waren relativ simple F√§lle, die Ihnen im R-Alltag aber immer wieder begenen werden, denn die allermeisten Funktionen ben√∂tigen ein Objekt, mit dem sie arbeiten k√∂nnen. Durch andere Argumente k√∂nnen wir bestimmen, wie die Funktion genau arbeiten soll. Im weiteren Verlauf dieses Kapitels und in den kommenden Wochen werden wir einige solcher Argumente kennenlernen. Zun√§chst gen√ºgt es, festzuhalten, dass Funktionen mit Argumenten dar√ºber informiert werden, an welchem Objekt sie ihre Aufgabe aus√ºben sollen und ggf., was sie dabei zu beachten haben.\n\n\n2.3.2 R√ºckgabe\nEin weiteres wichtigtes Konzept ist die R√ºckgabe von Funktionen. Oder anders gesagt: ihr Ergebnis. In der Regel empfielt es sich, Funktionen nicht einfach nur auszuf√ºhren, sondern das Ergebnis in einem neuen Objekt zu speichern. Der Vorteil davon ist, dass Sie dann mit dem Objekt weiterarbeiten k√∂nnen, ohne jedesmal wieder die Funktion aufrufen zu m√ºssen. Das wird besonders an der read.csv()-Funktion deutlich, die wir oben genutzt haben, um den Datensatz zu laden. Nur so k√∂nnen wir √ºberhaupt sinnvoll damit weiterarbeiten.\n\n\n\n\n\n\nHilfe f√ºr Funktionen\n\n\n\nWenn Sie einmal nicht wissen, wie eine Funktion funktioniert oder Sie z.B. wissen wollen, welche Argumente eine Funktion ben√∂tigt oder was sie zur√ºckgibt, k√∂nnen Sie ganz einfach Hilfe erhalten. Dazu geben Sie einfach ein ? gefolgt vom Namen der Funktion ein, z.B. ?read.csv(). Im Bereich unten rechts zeigt R Ihnen dann die Dokumentation der Funktion an.\n\n\n\n\n2.3.3 Beispiel - Erstellen einer H√§ufigkeitstabelle\nDie oben genannten Konzepte schauen wir uns nun anhand der table()-Funktion an. Damit k√∂nnen wir - wie der Name vermuten l√§sst - eine Tabelle erstellen. Der Datensatz df_lokal enth√§lt eine Spalte, die das Geschlecht der Befragten angibt (A602). Der Wert 1 steht f√ºr ‚Äúm√§nnlich‚Äù, 2 f√ºr ‚Äúweiblich‚Äù, 3 f√ºr ‚Äúdivers/non-bin√§r‚Äù und 4 f√ºr ‚Äúkeine Angabe‚Äù, eine sogenannte Ausweichkategorie. Wenn wir diese Spalte an die table()-Funktion √ºbergeben, zeigt R uns in der Konsole eine H√§ufigkeitstabelle an. Wir erfahren also, wie h√§ufig jede Antwort im Datensatz vorkommt.\n\n# Erstellt eine H√§ufigkeitstabelle der Geschlechtsabfrage\n\ntable(df_lokal$A602)\n\n\n  1   2   3   4 \n813 996   7  18 \n\n\nEs ist etwas m√ºhselig, die Werte gedanklich immer wieder neu zuordnen. Um dies zu vermeiden, k√∂nnen wir die factor()-Funktion benutzen. Diese wandelt einen Vektor (die Spalte A602) in einen Faktor mit beschrifteten Werten um. Faktor bedeutet in diesem Kontext, dass wir wenige distinkte Werte haben. Es handelt sich um eine sogenannte kategorische Variable. Keine Sorge, dar√ºber werden wir in den kommenden Wochen noch mehr reden.\nF√ºr die factor()-Funktion m√ºssen wir neben der Spalte auch das labels-Argument nuzten, also die Beschriftung festlegen. Die R√ºckgabe der Funktion ist ein Vektor, der genauso lang ist, wie unser Ausgangsvektor (die Spalte A602), aber beschriftete Werte hat. Das k√∂nnen wir nutzen, um uns Arbeit zu sparen. Statt die R√ºckgabe der Funktion erst in einem neuen Objekt zu speichern, k√∂nnen wir factor() direkt in der table()-Funktion aufrufen.\n\n# Erstellt eine H√§ufigkeitstabelle der Geschlechtsabfrage, die vorher in einen beschrifteten Faktor umgewandelt wird\n\ntable(factor(df_lokal$A602, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\")))\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n         813          996            7           18 \n\n\nTats√§chlich gibt es kein Limit, wie viele Funktionen wir innerhalb von Funktionen aufrufen k√∂nnen. Beispielsweise k√∂nnen wir die prop.table()-Funktion nutzen, um den Anteil der jeweiligen Geschlechter in der Stichprobe auszurechnen.\n\n# Erstellt eine Tabelle der relativen H√§ufigkeiten der Geschlechtsabfrage, die vorher in einen beschrifteten Faktor umgewandelt wird\n\nprop.table(table(factor(df_lokal$A602, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n 0.443293348  0.543075245  0.003816794  0.009814613 \n\n\nUm das Ergebnis als Prozentwert zu lesen, k√∂nnen wir es mit 100 multiplizieren.\n\n# Multipliziert die relativen H√§ufigkeiten mit 100, um Prozentwerte zu erhalten\n\nprop.table(table(factor(df_lokal$A602, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))*100\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n  44.3293348   54.3075245    0.3816794    0.9814613 \n\n\nUnd um das Ergebnis noch besser lesbar zu machen, k√∂nnen wir die round()-Funktion nutzen, um das Ergebnis zu runden. Das digits-Argument gibt dabei die Anzahl der Nachkommastellen an.\n\n# Rundet die Prozentwerte auf 2 Nachkommastellen\n\nround(prop.table(table(factor(df_lokal$A602, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))*100, digits = 2)\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n       44.33        54.31         0.38         0.98 \n\n\n\n\n\n\n\n\nTip\n\n\n\n√úbrigens: Funktionen erwarten Argumente in einer festen Reihenfolge, die Sie mit der Hilfsfunktion (? gefolgt vom Namen der Funktion) erfahren k√∂nnen. Solange wir die Argumente in dieser Reihenfolge nuzten, m√ºssen wir sie nicht benennen. Im vorherigen Befehl k√∂nnen wir z.B. das digits = einfach weglassen und erhalten dasselbe Ergebnis.\n\n# Rundet die Prozentwerte auf 2 Nachkommastellen, l√§sst aber den Namen des digits-Arguments weg.\n\nround(prop.table(table(factor(df_lokal$A602, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))*100, 2)\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n       44.33        54.31         0.38         0.98 \n\n\n\n\n\n\n2.3.4 Pipes\nDas Verschachteln von Funktionen im Beispiel oben funktioniert zwar gut, wird aber schnell schwer nachvollziehbar. Man sagt auch, dass der Code nicht sonderlich lesbar ist. Um diesem Problem zu begegnen, k√∂nnen wir sogenannte Pipes (im Sinne von Pipeline) verwenden. Dazu nutzen wir den |&gt; Operator. Die Funktionsweise ist zugegebenerma√üen etwas gew√∂hnungsbed√ºrftig, mit etwas √úbung erleichtert er unser Leben aber sehr. Pipes nehmen ein Objekt, das links von ihnen steht und √ºbergeben es als erstes Argument in eine Funktion, die rechts davon bzw. in der Regel in einer neuen Zeile darunter steht. Wenn wir einen Ausdruck wie im Beispiel mit der Tabelle mit Pipes replizieren wollen, gehen wir von innen nach au√üen vor. Schauen wir uns das mal an, indem wir zun√§chst die Spalte A602 in einen Faktor umwandeln. Dazu √ºbergeben wir die Spalte mit dem |&gt; Operator an die factor()-Funktion. R erkennt automatisch, dass das Objekt (also die Spalte) als erstes Argument genutzt werden muss. Wir m√ºssen also nur das labels-Argument erg√§nzen. Vorsicht, da wir das Ergebnis nicht in einem neuen Objekt speichern, wird es in der Konsole angezeigt und ist sehr lang!\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\")) \n\n   [1] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n   [6] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n  [11] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n  [16] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n  [21] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n  [26] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n  [31] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n  [36] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n  [41] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n  [46] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n  [51] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n  [56] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n  [61] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n  [66] weiblich     weiblich     divers       weiblich     weiblich    \n  [71] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n  [76] weiblich     weiblich     weiblich     weiblich     weiblich    \n  [81] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n  [86] weiblich     m√§nnlich     divers       m√§nnlich     weiblich    \n  [91] weiblich     weiblich     weiblich     weiblich     weiblich    \n  [96] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [101] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n [106] weiblich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [111] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [116] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [121] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n [126] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [131] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [136] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [141] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n [146] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n [151] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [156] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n [161] weiblich     m√§nnlich     weiblich     weiblich     &lt;NA&gt;        \n [166] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [171] divers       m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n [176] weiblich     weiblich     weiblich     weiblich     weiblich    \n [181] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [186] m√§nnlich     divers       m√§nnlich     weiblich     weiblich    \n [191] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [196] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n [201] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [206] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [211] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [216] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n [221] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [226] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [231] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [236] weiblich     weiblich     weiblich     weiblich     weiblich    \n [241] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [246] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n [251] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n [256] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [261] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n [266] weiblich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n [271] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [276] weiblich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n [281] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n [286] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [291] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [296] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [301] m√§nnlich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [306] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n [311] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [316] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [321] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [326] weiblich     weiblich     weiblich     weiblich     weiblich    \n [331] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [336] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [341] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n [346] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n [351] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [356] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n [361] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [366] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [371] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n [376] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [381] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [386] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n [391] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n [396] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [401] weiblich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n [406] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n [411] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [416] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [421] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n [426] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [431] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n [436] m√§nnlich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [441] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n [446] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [451] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [456] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [461] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [466] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n [471] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [476] weiblich     weiblich     weiblich     weiblich     weiblich    \n [481] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n [486] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [491] weiblich     weiblich     m√§nnlich     weiblich     divers      \n [496] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [501] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [506] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n [511] weiblich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n [516] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [521] weiblich     weiblich     weiblich     weiblich     weiblich    \n [526] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n [531] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n [536] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [541] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [546] weiblich     m√§nnlich     m√§nnlich     &lt;NA&gt;         keine Angabe\n [551] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [556] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [561] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [566] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [571] weiblich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n [576] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n [581] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [586] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [591] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [596] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [601] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [606] weiblich     weiblich     weiblich     weiblich     weiblich    \n [611] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [616] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [621] weiblich     m√§nnlich     keine Angabe weiblich     m√§nnlich    \n [626] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n [631] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [636] weiblich     weiblich     weiblich     weiblich     weiblich    \n [641] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n [646] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [651] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [656] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [661] weiblich     weiblich     weiblich     weiblich     weiblich    \n [666] m√§nnlich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [671] weiblich     weiblich     weiblich     weiblich     weiblich    \n [676] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [681] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n [686] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [691] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [696] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [701] weiblich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [706] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n [711] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n [716] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n [721] weiblich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [726] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [731] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [736] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [741] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n [746] weiblich     m√§nnlich     &lt;NA&gt;         m√§nnlich     weiblich    \n [751] weiblich     weiblich     weiblich     weiblich     weiblich    \n [756] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n [761] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n [766] weiblich     weiblich     weiblich     weiblich     weiblich    \n [771] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [776] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [781] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [786] weiblich     divers       weiblich     weiblich     weiblich    \n [791] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [796] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [801] m√§nnlich     m√§nnlich     m√§nnlich     &lt;NA&gt;         weiblich    \n [806] keine Angabe m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n [811] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [816] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n [821] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n [826] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [831] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [836] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n [841] weiblich     weiblich     weiblich     weiblich     keine Angabe\n [846] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [851] weiblich     weiblich     weiblich     m√§nnlich     keine Angabe\n [856] keine Angabe weiblich     m√§nnlich     weiblich     m√§nnlich    \n [861] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n [866] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [871] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [876] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n [881] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [886] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n [891] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n [896] weiblich     weiblich     weiblich     weiblich     weiblich    \n [901] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [906] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [911] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n [916] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [921] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n [926] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [931] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n [936] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n [941] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [946] m√§nnlich     keine Angabe weiblich     m√§nnlich     m√§nnlich    \n [951] weiblich     m√§nnlich     weiblich     weiblich     &lt;NA&gt;        \n [956] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n [961] m√§nnlich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n [966] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [971] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n [976] weiblich     weiblich     weiblich     weiblich     weiblich    \n [981] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n [986] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n [991] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n [996] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n[1001] &lt;NA&gt;         weiblich     weiblich     weiblich     weiblich    \n[1006] weiblich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1011] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n[1016] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1021] m√§nnlich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1026] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1031] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1036] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n[1041] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1046] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n[1051] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1056] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n[1061] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1066] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n[1071] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n[1076] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n[1081] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1086] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1091] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1096] &lt;NA&gt;         weiblich     weiblich     weiblich     weiblich    \n[1101] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1106] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1111] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n[1116] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1121] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1126] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1131] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1136] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1141] weiblich     m√§nnlich     m√§nnlich     weiblich     keine Angabe\n[1146] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1151] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n[1156] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n[1161] weiblich     m√§nnlich     m√§nnlich     keine Angabe m√§nnlich    \n[1166] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1171] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1176] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n[1181] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n[1186] weiblich     weiblich     keine Angabe weiblich     m√§nnlich    \n[1191] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1196] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1201] weiblich     m√§nnlich     weiblich     m√§nnlich     keine Angabe\n[1206] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n[1211] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1216] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1221] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n[1226] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1231] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n[1236] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1241] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1246] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1251] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1256] weiblich     weiblich     weiblich     &lt;NA&gt;         weiblich    \n[1261] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1266] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n[1271] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n[1276] keine Angabe m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1281] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1286] m√§nnlich     weiblich     m√§nnlich     &lt;NA&gt;         weiblich    \n[1291] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n[1296] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1301] m√§nnlich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1306] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n[1311] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1316] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n[1321] weiblich     weiblich     m√§nnlich     weiblich     weiblich    \n[1326] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n[1331] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1336] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n[1341] weiblich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1346] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n[1351] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1356] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n[1361] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n[1366] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1371] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n[1376] weiblich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n[1381] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1386] m√§nnlich     m√§nnlich     keine Angabe weiblich     m√§nnlich    \n[1391] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1396] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n[1401] m√§nnlich     &lt;NA&gt;         m√§nnlich     m√§nnlich     m√§nnlich    \n[1406] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n[1411] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1416] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1421] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1426] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1431] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1436] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n[1441] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1446] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1451] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1456] m√§nnlich     m√§nnlich     &lt;NA&gt;         weiblich     m√§nnlich    \n[1461] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1466] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1471] weiblich     keine Angabe m√§nnlich     weiblich     weiblich    \n[1476] weiblich     keine Angabe weiblich     weiblich     m√§nnlich    \n[1481] weiblich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1486] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1491] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n[1496] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1501] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1506] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1511] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n[1516] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1521] weiblich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1526] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1531] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n[1536] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1541] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1546] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1551] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n[1556] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n[1561] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n[1566] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n[1571] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n[1576] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n[1581] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1586] weiblich     &lt;NA&gt;         m√§nnlich     weiblich     weiblich    \n[1591] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1596] weiblich     m√§nnlich     weiblich     m√§nnlich     divers      \n[1601] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1606] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n[1611] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n[1616] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n[1621] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1626] weiblich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1631] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n[1636] weiblich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1641] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n[1646] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1651] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n[1656] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1661] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1666] weiblich     weiblich     weiblich     m√§nnlich     weiblich    \n[1671] m√§nnlich     weiblich     m√§nnlich     weiblich     weiblich    \n[1676] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1681] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n[1686] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1691] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1696] m√§nnlich     weiblich     weiblich     m√§nnlich     m√§nnlich    \n[1701] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n[1706] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1711] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n[1716] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1721] keine Angabe m√§nnlich     m√§nnlich     weiblich     m√§nnlich    \n[1726] m√§nnlich     m√§nnlich     weiblich     keine Angabe m√§nnlich    \n[1731] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1736] m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich     weiblich    \n[1741] weiblich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n[1746] weiblich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1751] m√§nnlich     weiblich     weiblich     weiblich     weiblich    \n[1756] m√§nnlich     m√§nnlich     m√§nnlich     weiblich     weiblich    \n[1761] m√§nnlich     weiblich     weiblich     weiblich     m√§nnlich    \n[1766] m√§nnlich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1771] m√§nnlich     weiblich     weiblich     m√§nnlich     weiblich    \n[1776] weiblich     m√§nnlich     weiblich     m√§nnlich     weiblich    \n[1781] weiblich     weiblich     keine Angabe weiblich     m√§nnlich    \n[1786] weiblich     m√§nnlich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1791] m√§nnlich     m√§nnlich     weiblich     weiblich     weiblich    \n[1796] m√§nnlich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n[1801] weiblich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1806] weiblich     m√§nnlich     weiblich     weiblich     weiblich    \n[1811] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     weiblich    \n[1816] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1821] weiblich     m√§nnlich     weiblich     weiblich     m√§nnlich    \n[1826] weiblich     m√§nnlich     weiblich     m√§nnlich     m√§nnlich    \n[1831] weiblich     weiblich     weiblich     weiblich     m√§nnlich    \n[1836] m√§nnlich     weiblich     m√§nnlich     m√§nnlich     m√§nnlich    \n[1841] m√§nnlich     weiblich     m√§nnlich     weiblich     m√§nnlich    \n[1846] m√§nnlich    \nLevels: m√§nnlich weiblich divers keine Angabe\n\n\nIm n√§chsten Schritt √ºbergeben wir diesen neuen Faktor mit |&gt; an die table()-Funktion, die keine weiteren Argumente ben√∂tigt.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und √ºbergibt diesen an die table()-Funktion.\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table()\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n         813          996            7           18 \n\n\nDiese H√§ufigkeitstabelle k√∂nnen wir nun an die prop.table()-Funktion √ºbergeben, um eine Tabelle mit relativen H√§ufigkeiten zu bekommen.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und √ºbergibt diesen an die table()-Funktion und erstellt dann eine Tabelle mit relativen H√§ufigkeiten\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table() |&gt;\n  prop.table()\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n 0.443293348  0.543075245  0.003816794  0.009814613 \n\n\nAls letztes haben wir oben die Werte dieser Tabelle mit 100 multipliziert und das Ergebnis auf zwei Nachkommastellen gerundet. Wenn wir versuchen, diesen Schritt umzusetzen, sehen wir zwar, dass die Prozentwerte richtig angegeben werden, allerdings funktioniert das Runden nicht. Kurz gesagt liegt das daran, dass R es nicht schafft den Ausdruck prop.table()*100 weiterzuleiten.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und √ºbergibt diesen an die table()-Funktion und erstellt dann eine Tabelle mit relativen H√§ufigkeiten, die in Prozentwerte umgerechnet werden; das Runden funktioniert nicht\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table() |&gt;\n  prop.table()*100 |&gt;\n  round(2)\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n  44.3293348   54.3075245    0.3816794    0.9814613 \n\n\nWir k√∂nnen Abhilfe schaffen, indem wir das Ergebnis der prop.table()-Funktion direkt an die round()-Funktion weitergeben und erst deren Ergebnis runden. Wichtig ist dabei, dass wir erst auf 4 Nachkommastellen runden und diese dann mit 100 multiplizieren, sodass wir am Ende eine Zahl mit 4 Stellen (2 vor und 2 nach dem Komma) bekommen.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und √ºbergibt diesen an die table()-Funktion und erstellt dann eine Tabelle mit relativen H√§ufigkeiten, die in Prozentwerte umgerechnet werden; das Ergebnis wird gerundet\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table() |&gt;\n  prop.table() |&gt;\n  round(4)*100\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n       44.33        54.31         0.38         0.98",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#footnotes",
    "href": "Objekte, Daten, Funktionen.html#footnotes",
    "title": "2¬† Objekte, Daten, Funktionen",
    "section": "",
    "text": "In machen Quellen werden Sie statt des Pfeils ein Gleichheitszeichen sehen. Im Prinzip sind die beiden √§quivalent. Wir nutzen hier den Pfeil, werden aber sp√§ter, wenn wir uns mit Funktionen befassen, auch das Gleicheitszeichen verwenden.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Pakete und Datentransformationen.html",
    "href": "Pakete und Datentransformationen.html",
    "title": "3¬† Pakete und Datentransformationen",
    "section": "",
    "text": "3.1 Pakete\nZwar kann R direkt nach der Installation schon relativ viel, aber gleichzeitig gibt es viele Aufgaben, die wir nur l√∂sen k√∂nnen, indem wir R erweitern. Dazu nutzen wir sogenannte Pakete. Vereinfacht gesagt handelt es sich dabei um Sammlungen von Funktionen. Im Lauf des Kurses werden wir einige Pakete ben√∂tigen, die wir entsprechend nach und nach kennenlernen werden. Zun√§chst schauen wir uns an, wie wir Pakete installieren und laden k√∂nnen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Pakete und Datentransformationen</span>"
    ]
  },
  {
    "objectID": "Pakete und Datentransformationen.html#pakete",
    "href": "Pakete und Datentransformationen.html#pakete",
    "title": "3¬† Pakete und Datentransformationen",
    "section": "",
    "text": "3.1.1 Pakete installieren\nUm ein Paket zu installieren, m√ºssen Sie zun√§chst dessen Namen kennen. Dann haben Sie zwei M√∂glichkeiten:\n\nSie k√∂nnen die Funktion install.packages() nutzen. Als Argument nimmt die Funktion den Namen mindestens eines Pakets in Anf√ºhrungszeichen, oder mehrere Pakete durch Kommata getrennt. F√ºr den weiteren Verlauf des Kapitels werden wir das Paket tidyverse nutzen. Damit wir das Paket nicht jedes Mal aufs Neue installieren, wenn wir ein Skript ausf√ºhren, k√∂nnen wir die Funktion mit dem folgenden Befehl aufrufen.\n\n# Pr√ºft, ob das Paket \"tidyverse\" installiert ist. Falls nicht, wird es installiert\nif(!require(tidyverse)){\n  install.packages(\"tidyverse\")\n} \n\nLade n√∂tiges Paket: tidyverse\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nDie Funktionsweise ist f√ºr Sie nicht entscheidend, aber f√ºr den Fall, dass es Sie interessiert, wird sie hier noch kurz erkl√§rt: Wir starten mit einem sogenannten if-Befehl, deren Aufbau immer gleich ist. In der Klammer steht eine Bedingung, die gepr√ºft wird. Sofern sie zutrifft, wird der Teil in der in den geschwungenen Klammern ({}) ausgeff√ºhrt. Die Bedingung in einem if-Befehl muss immer wahr oder falsch sein, bzw. TRUE oder FALSE zur√ºckgeben. Wird TRUE zur√ºckgegeben, gilt die Bedingung als erf√ºllt, andernfalls nicht. In diesem Fall wird die Bedingung !require(tidyverse) gepr√ºft. require() ist eine Funktion, die versucht ein Paket zu laden. Falls es aber nicht installiert ist, gibt sie FALSE zur√ºck. Durch das Ausrufezeichen, wird dieser Ausdruck negiert. Etwas das nicht FALSE ist, ist in der R-Logik TRUE. In der Summe bedeutet das also, dass wir erst pr√ºfen, ob das Paket vorhanden ist und falls nicht, wird es installiert.\nAlternativ k√∂nnen Sie im Bereich unten rechts auf den Reiter Packages und dort auf Install klicken.\n\n\n\n\n\n\nAnschlie√üend √∂ffnet sich ein Fenster, in dem Sie den oder die Namen der gew√ºnschten Pakete eintragen k√∂nnen.\n\n\n\n\n\n\n\n3.1.2 Pakete laden\nAuch zum Laden von Paketen haben Sie mehrere M√∂glichkeiten:\n\nSie k√∂nnen den Befehl von oben nutzen, da die require()-Funktion versucht, das angegebene Paket zu laden. Sofern das Paket bereits installiert ist, wird es einfach nur geladen.\nSie k√∂nnen auch die library()-Funktion verwenden. Auch hier m√ºssen Sie nur den Namen des Pakets als Argument √ºbergeben. Diesmal allerdings ohne Anf√ºhrungszeichen. Der Unterschied zu require() ist, dass die Funktion eine Fehlermeldung zur√ºckgibt, falls das Paket nicht vorhanden ist.\n\n# L√§dt das Paket \"tidyverse\"\nlibrary(tidyverse)\n\nAlterantiv k√∂nnen Sie wieder auf den Reiter Packages unten rechts navigieren, den Namen des Pakets im Suchfeld eingeben und anschlie√üend einen Haken im entsprechenden Feld setzen.\n\n\n\n\n\n\n\n\n3.1.3 Das tidyverse\nIn den beiden vorherigen Abschnitten haben wir das tidyverse-Paket installiert und geladen. Strenggenommen handelt es sich dabei nicht um ein einzelnes Paket, sondern gleich eine ganze Sammlung. Das sehen Sie auch, nachdem Sie das Paket geladen haben. In der Konsole wird uns gleich eine ganze Reihe an Paketen angezeigt, die geladen wurden:\n\n\n\n\n\nSchauen wir uns einmal kurz an, worum es sich bei diesen Paketen handelt:\n\ndplyr ist gewisserma√üen das Herzst√ºck des tidyverse. Das Pekt enth√§lt zahlreiche Funktionen, die wir f√ºr die Datentransformation ben√∂tigen. Sie k√∂nnen damit z.B. neue Variablen berechnen, Datens√§tze filtern, einzelne Spalten selektieren und vieles mehr. Wir werden das Paket haupts√§chlich nutzen, um Daten in ein Format zu bringen, mit dem wir weiterarbeiten k√∂nnen und, um Datens√§tze deskriptiv auszuwerten.\nforcats erleichtert die Arbeit mit kategorischen Variablen, also z.B. dem Geschlecht der Befragten aus dem letzten Kapitel.\nggplot2 ist ein Paket zum Erstellen von Grafiken. Wir werden es in den kommenden Wochen n√§her kennenlernen.\nlubridate enth√§lt Funktionen, die das Arbeiten mit Zeit- und Datumsvariablen erleichtern. In diesem Kurs werden wir solchen Daten allerdings nicht begegnen.\npurrr ist eher etwas f√ºr fortgeschrittene Programmierer:innen. Es enth√§lt Funktionen, die das Arbeiten anderen R Funktionen optimieren k√∂nnen. Keine Sorge: Wir bleiben in diesem Kurs bei den Basics und werden uns nicht damit befassen.\nreadr ist ein Paket zum Laden von Daten, zum Beispiel enth√§lt es die read_csv()-Funktion als Alternative zur read.csv()-Funktion aus dem letzten Kapitel. Das mag redundant wirken, aber zeigt in erster Linie, dass es in R in der Regel viele verschiedene M√∂glichkeiten gibt, ein gegebenes Problem zu l√∂sen. Der Grund, warum readr entwickelt wurde ist, dass die enthaltenen Funktionen oftmals schneller sind, als ihre in R enthaltenen Pendants. Allerdings zeigt sich dieser Geschwindigkeitsvorteil haupts√§chlich bei sehr gro√üen Datens√§tzen.\nstringr ist ein Paket, um strings zu manipulieren. Man kann damit z.B. pr√ºfen, ob eine Zeichenfolge bestimmte Zeichen enth√§lt, die wiederum entfernt oder ge√§ndert werden k√∂nnen.\ntibble nicht nur der Name des Pakets, sondern auch der Name des Objekttyps, den das Paket erzeugt. Im Prinzip ist die Kernfunktion tibble() eine moderne Version der data.frame()-Funktion aus dem letzten Kapitel.\ntidyr enth√§lt Funktionen, mit denen wir Datens√§tze bzw. tibbles in ein bestimmtes Format bringen k√∂nnen, das schlicht tidy genannt wird. Dieses Format haben Sie im letzten Kapitel bereits kennengelernt, wenn auch nicht unter diesem Namen. Es bedeutet nicht mehr als die Idee, dass in einem gut strukturierten Datensatz jede Zeile einem Fall und jede Spalte einer Variable entspricht.\n\nDer Vorteil des tidyverse ist, dass Sie immer nur ein Paket laden m√ºssen, um einen umfangreichen Wekrzeugkasten nutzen zu k√∂nnen. Gleichwohl kann das Paket am Anfang aufgrund seines Umfangs etwas abschreckend und unzug√§nglich wirken. Hier k√∂nnen sogenannte Cheatsheets, also Spickzettel, Abhilfe schaffen. Darauf werden die wichtigsten Funktionen der einzelnen Pakete vorgestellt und erkl√§rt. F√ºr die meisten tidyverse-Pakete finden Sie solche Cheatsheets auf der Webseite von posit, dem Unternehmen, das auch RStudio entwickelt: https://posit.co/resources/cheatsheets/",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Pakete und Datentransformationen</span>"
    ]
  },
  {
    "objectID": "Pakete und Datentransformationen.html#datentransformationen",
    "href": "Pakete und Datentransformationen.html#datentransformationen",
    "title": "3¬† Pakete und Datentransformationen",
    "section": "3.2 Datentransformationen",
    "text": "3.2 Datentransformationen\nMit Hilfe des tidyverse und insbesondere den in dplyr enthaltenen Funktionen k√∂nnen wir Datens√§tze transformieren. Das ist etwas vereinfacht ausgedr√ºckt, denn eigentlich verbirgt sich hinter der Transformation von Daten und Datens√§tzen eine Vielzahl von Dingen. Einige davon werden wir uns nun angucken. Ganz konkret das Umbenennen von Spalten, das Hinzuf√ºgen von neuen Spalten, das Selektieren von bestimmten Spalten und das Filtern von F√§llen, also Zeilen.\n\n3.2.1 Spalten umbenennen\nUm eine oder mehrere Spalten umzubenennen, k√∂nnen wir die rename()-Funktion nutzen. Das Schema ist dabei relativ einfach: neuerName = alterName. In der Praxis sieht das so aus:\nZuerst lesen wir die Daten ein. Falls Sie das Skript aus dem letzten Kapitel nutzen, sollten Sie diesen Befehl schon im Skript haben und k√∂nnen ihn entsprechend ausf√ºhren.\n\n# Einlesen der Daten \n\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\nDamit der neue Name im Datensatz gespeichert wird, m√ºssen wir das Ergebnis der rename()-Funktion in einem Objekt speichern. In solchen F√§llen ist es h√§ufig sinnvoll, das vorhadene Datensatzobjekt zu √ºberschreiben. Mit der Pipe (|&gt;) √ºbergeben wir den Datensatz an die rename()-Funktion.\n\n# Benennt die Spalte A101_01 in Themeninteresse_lokal um\n\ndf_lokal &lt;- df_lokal |&gt;\n  rename(Themeninteresse_lokal = A101_01)\n\n\n\n3.2.2 Neue Spalten hinzuf√ºgen\nEs gibt zwei Situationen, in denen es sinnvoll ist, einem Datensatz eine neue Spalte hinzuzuf√ºgen:\n\nWenn Sie eine neue Variable berechnen wollen oder\nwenn Sie eine bestehende Variable ver√§ndern wollen.\n\nDazu k√∂nnen wir die dplyr-Funktion mutate() nutzen. Als Argument √ºbergeben wir der Funktion den Namen der neuen Spalte und deren Inhalt. Das Schema sieht so aus: mutate(nameDerNeuenSpalte = fester Wert, Berechnung oder Ver√§nderung einer bestehenden Spalte). Schauen wir uns die Funktion einmal am Beispiel aus dem letzten Kapitel an. Dort haben wir die Spalte A602 in einen Faktor umgewandelt und eine H√§ufigkeitstabelle ausgegeben. Das geht auch mit der mutate()-Funktion Dieser sagen wir, dass wir eine neue Spalte namens geschlecht erstellen wollen. Diese ist gleich einem Faktor aus der Spalte A602, mit den entsprechenden Wertbeschriftungen.\n\n# Erstellt einen Faktor aus der Spalte A602 und speichert diesen in der neuen Spalte Geschlecht\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlecht = factor(A602, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\", \"keine Angabe\")))\n\n# H√§ufigkeitstabelle der neuen Spalte\n\ntable(df_lokal$geschlecht)\n\n\n    m√§nnlich     weiblich       divers keine Angabe \n         813          996            7           18 \n\n\nOben haben Sie erfahren, dass man mit mutate() neue Spalten hinzuf√ºgen kann. Sie k√∂nnen aber auch bestehende Spalten ver√§ndern. Das sollten Sie allerdings nur in absoluten Ausnahmen machen! Eine davon ist, wenn Sie zum erstellen neuer Spalten mehrere Schritte ben√∂tigen. Zum Beispiel k√∂nnen wir mit der Antwort \"keine Angabe\" auf die Geschlechtsabfrage wenig anfangen. F√ºr viele Analysen w√§re es daher sinnvoll, wenn diese Werte als fehlende Werte codiert w√§ren. In R nennen wir solche Werte NAs (f√ºr not available). Um diese Werte entsprechend als fehlend zu codieren, k√∂nnen wir in zwei Schritten vorgehen. Erst codieren wir den Wert 4 aus der Ausgangsspalte A602 als fehlend. Das geht mit der na_if()-Funktion aus dem dyplr-Paket. Dieser Funktion √ºbergeben wir ein Objekt und den Wert, der in NA umgewandelt werden soll. Im zweiten Schritt k√∂nnen wir dann einen Faktor mit den drei Kategorien \"m√§nnlich\", \"weiblich\" und \"divers\" erstellen.\n\n# Erstellt eine Spalte aus der Geschlechtsabfrage. Erst wird der Wert \"keine Angabe\" als fehlend deklariertm dann wird ein Faktor mit den √ºbrigen drei Kategorien erstellt\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlechtMitNAs = na_if(A602, 4)) |&gt;\n  mutate(geschlechtMitNAs = factor(geschlechtMitNAs, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\")))\n\n# H√§ufigkeitstabelle der neuen Spalte\n\ntable(df_lokal$geschlechtMitNAs)\n\n\nm√§nnlich weiblich   divers \n     813      996        7 \n\n\nSchauen wir uns noch ein weiteres Beispiel an. In der Spalte A601_01 ist das Geburtsjahr der Befragten angegeben, das in ein offenes Textfeld eingetragen werden sollte. Mit der unique()-Funktion k√∂nnen wir uns alle Werte anzeigen lassen, die mindestens einmal in der Spalte vorkommen. Anders als die table()-Funktion erhalten wir aber keine H√§ufigkeiten. unique() ist also praktisch, wenn wir nur wissen wollen, was f√ºr Werte eine Spalte eigentlich enth√§lt.\n\n# Zeigt alle Werte on A601_01, die mindestens einmal vorkommen\n\nunique(df_lokal$A601_01)\n\n [1] \"1981\"         \"1957\"         \"1962\"         \"1997\"         \"1967\"        \n [6] \"1984\"         \"1961\"         \"1989\"         \"1978\"         \"1964\"        \n[11] \"1971\"         \"1993\"         \"1973\"         \"1991\"         \"Deutschland \"\n[16] \"2005\"         \"1972\"         \"1988\"         \"1965\"         \"1966\"        \n[21] \"1982\"         \"1958\"         \"1985\"         \"1953\"         \"1974\"        \n[26] \"1979\"         \"1963\"         \"1970\"         \"1959\"         \"1954\"        \n[31] \"1990\"         \"1975\"         \"1976\"         \"1960\"         \"1956\"        \n[36] \"1999\"         \"1968\"         \"1969\"         \"1987\"         \"2004\"        \n[41] \"1983\"         \"1980\"         \"2002\"         \"1977\"         \"1952\"        \n[46] \"1950\"         \"1995\"         \"01.11.1967\"   \"1996\"         \"1944\"        \n[51] \"1994\"         \"1986\"         \"1955\"         \"1948\"         \"1951\"        \n[56] \"2001\"         \"1942\"         \"1949\"         \"2000\"         \"1947\"        \n[61] \"1942 \"        \"1941\"         \"1939\"         \"w000\"         \"2003\"        \n[66] \"1998\"         \"1992\"         \"1946\"         \"1975 \"        NA            \n[71] \"1945\"         \"Deutschland\"  \"Keine Angabe\" \"1964 \"        \"1943\"        \n[76] \"1936\"         \"1938\"         \"2007\"         \"1957 \"        \"1935\"        \n[81] \"1972 \"        \"1940\"         \"1965 \"        \"1934\"         \"16.02.1957\"  \n[86] \"Datenschutz \" \"&lt;60\"          \"1933\"         \"24.10.1945\"   \"I 966\"       \n[91] \"1937\"         \"1961 \"       \n\n\nWie es aussieht, haben einige Befragte die Frage nicht ganz verstanden und unsinnige Werte (z.B. Deutschland) oder ihren genauen Geburtstag angegeben. Wieder andere haben ein Leerzeichen am Ende der Jahresangabe angeh√§ngt. All das f√ºhrt dazu, dass die Spalte nicht als Zahl, sondern als string gespeichert ist. Das ist ziemlich unpraktisch!\nUm diese Spalte etwas aufzur√§umen, m√ºssen wir in mehreren Schritten vorgehen. Das Ziel ist, pro Person entweder eine Zahl mit vier Ziffern oder ein NA zu erhalten.\nWir fangen mit den Leerzeichen an. Diese k√∂nnen wir mit der str_trim()-Funktion aus dem stringr-Paket entfernen. Dazu √ºbergeben wir der Funktion einfach die entsprechende Spalte. Das Ergebnis speichern wir in der neuen Spalte geburtsjahr.\n\n# Entfernt Leerzeichen am Anfang und Ende der strings und speichert das Ergebnis in der neuen Spalte \"geburtsjahr\"\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = str_trim(A601_01))\n\nunique(df_lokal$geburtsjahr)\n\n [1] \"1981\"         \"1957\"         \"1962\"         \"1997\"         \"1967\"        \n [6] \"1984\"         \"1961\"         \"1989\"         \"1978\"         \"1964\"        \n[11] \"1971\"         \"1993\"         \"1973\"         \"1991\"         \"Deutschland\" \n[16] \"2005\"         \"1972\"         \"1988\"         \"1965\"         \"1966\"        \n[21] \"1982\"         \"1958\"         \"1985\"         \"1953\"         \"1974\"        \n[26] \"1979\"         \"1963\"         \"1970\"         \"1959\"         \"1954\"        \n[31] \"1990\"         \"1975\"         \"1976\"         \"1960\"         \"1956\"        \n[36] \"1999\"         \"1968\"         \"1969\"         \"1987\"         \"2004\"        \n[41] \"1983\"         \"1980\"         \"2002\"         \"1977\"         \"1952\"        \n[46] \"1950\"         \"1995\"         \"01.11.1967\"   \"1996\"         \"1944\"        \n[51] \"1994\"         \"1986\"         \"1955\"         \"1948\"         \"1951\"        \n[56] \"2001\"         \"1942\"         \"1949\"         \"2000\"         \"1947\"        \n[61] \"1941\"         \"1939\"         \"w000\"         \"2003\"         \"1998\"        \n[66] \"1992\"         \"1946\"         NA             \"1945\"         \"Keine Angabe\"\n[71] \"1943\"         \"1936\"         \"1938\"         \"2007\"         \"1935\"        \n[76] \"1940\"         \"1934\"         \"16.02.1957\"   \"Datenschutz\"  \"&lt;60\"         \n[81] \"1933\"         \"24.10.1945\"   \"I 966\"        \"1937\"        \n\n\nAls n√§chstes k√∂nnen wir die F√§lle behandeln, die ihr vollst√§ndiges Geburtsdatum angegeben haben. Dazu nutzen wir die str_sub()-Funktion, die es uns erlaubt, Teile von strings auf Basis ihrer Position zu extrahieren. Indem wir -4 angeben, sagen wir der Funktion, dass wir nur die letztn vier Stellen behalten wollen.\n\n# Entfernt alle Zeichen bis auf die letzten 4\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4))\n\nunique(df_lokal$geburtsjahr)\n\n [1] \"1981\" \"1957\" \"1962\" \"1997\" \"1967\" \"1984\" \"1961\" \"1989\" \"1978\" \"1964\"\n[11] \"1971\" \"1993\" \"1973\" \"1991\" \"land\" \"2005\" \"1972\" \"1988\" \"1965\" \"1966\"\n[21] \"1982\" \"1958\" \"1985\" \"1953\" \"1974\" \"1979\" \"1963\" \"1970\" \"1959\" \"1954\"\n[31] \"1990\" \"1975\" \"1976\" \"1960\" \"1956\" \"1999\" \"1968\" \"1969\" \"1987\" \"2004\"\n[41] \"1983\" \"1980\" \"2002\" \"1977\" \"1952\" \"1950\" \"1995\" \"1996\" \"1944\" \"1994\"\n[51] \"1986\" \"1955\" \"1948\" \"1951\" \"2001\" \"1942\" \"1949\" \"2000\" \"1947\" \"1941\"\n[61] \"1939\" \"w000\" \"2003\" \"1998\" \"1992\" \"1946\" NA     \"1945\" \"gabe\" \"1943\"\n[71] \"1936\" \"1938\" \"2007\" \"1935\" \"1940\" \"1934\" \"hutz\" \"&lt;60\"  \"1933\" \" 966\"\n[81] \"1937\"\n\n\nDiese Vorarbeit reicht, um fast alle problematischen F√§lle mit einem weiteren Schritt zu bereinigen. Wir k√∂nnen nun die as.integer()-Funktion benutzen, um die Spalte in eine Zahl umzuwandeln. Alles was nicht umgewandelt werden kann, wird automatisch zu einem NA.\n\n# Wandelt geburtsjahr in eine Zahl um\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr))\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\nunique(df_lokal$geburtsjahr)\n\n [1] 1981 1957 1962 1997 1967 1984 1961 1989 1978 1964 1971 1993 1973 1991   NA\n[16] 2005 1972 1988 1965 1966 1982 1958 1985 1953 1974 1979 1963 1970 1959 1954\n[31] 1990 1975 1976 1960 1956 1999 1968 1969 1987 2004 1983 1980 2002 1977 1952\n[46] 1950 1995 1996 1944 1994 1986 1955 1948 1951 2001 1942 1949 2000 1947 1941\n[61] 1939 2003 1998 1992 1946 1945 1943 1936 1938 2007 1935 1940 1934 1933  966\n[76] 1937\n\n\nDas sieht schon deutlich besser aus! Nur ein einziger Fall bleibt problematisch: Eine Person hat den Wert 966. Da es recht unwahrscheinlich ist, dass eine so alte Person an der Befragung teilgenommen hat, m√ºssen wir entscheiden, wie wir mit dem Wert umgehen. Wenn wir uns die vorherigen Ausgaben der unique()-Funktion ansehen, sehen wir, dass die Person urspr√ºnglich \"I 966\" angegeben hatte. Wir k√∂nnten nun eher streng sein und den Wert als NA deklarieren, da die Eingabe unsinnig ist. Oder wir gehen davon aus, dass 1966 gemeint war. In dem Fall k√∂nnten wir den einzelnen Wert einfach umcodieren oder 1000 addieren. Das ist ein sch√∂nes Beispiel daf√ºr, dass es bei der Datenaufbereitung nicht immer eindeutig richitge oder falsche Entscheidungen gibt. In diesem konkreten Fall wandeln wir die 966 in eine 1966 um. Dazu nutzen wir die ifelse()-Funktion, die immer drei Argumente ben√∂tigt:\n\nEine Bedingung, die gepr√ºft werden soll.\nWas getan werden soll, falls die Bedingung zutrifft.\nUnd was getan werden soll, falls die Bedingung nicht zutrifft.\n\nUm nur den Wert 966 zu √§ndern, k√∂nnen wir als Bedingung erfragen, ob der aktuelle Wert kleiner als 1000 ist. Falls dem so ist, k√∂nnen wir 1000 addieren und ansonsten den alten Wert √ºbernehmen. All das nat√ºrlich in einem mutate()-Aufruf.\n\n# Addiert 1000 zu allen Werten von geburtsjahr unter 1000\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr))\n\nunique(df_lokal$geburtsjahr)\n\n [1] 1981 1957 1962 1997 1967 1984 1961 1989 1978 1964 1971 1993 1973 1991   NA\n[16] 2005 1972 1988 1965 1966 1982 1958 1985 1953 1974 1979 1963 1970 1959 1954\n[31] 1990 1975 1976 1960 1956 1999 1968 1969 1987 2004 1983 1980 2002 1977 1952\n[46] 1950 1995 1996 1944 1994 1986 1955 1948 1951 2001 1942 1949 2000 1947 1941\n[61] 1939 2003 1998 1992 1946 1945 1943 1936 1938 2007 1935 1940 1934 1933 1937\n\n\nUm jetzt aus dem Geburtsjahr das Alter zu berechnen, k√∂nnen wir wieder mutate() nutzen, um eine neue Variable zu berechnen. Die Befragung wurde 2022 durchgef√ºhrt, also k√∂nnen wir davon den Wert aus geburtsjahr subtrahieren. Damit bekommen wir zwar strenggenommen nicht das Alter zum Zeitpunkt der Befragung, sondern zum Jahresende, aber genauer liegen die Daten nicht vor, sodass wir damit leben m√ºssen.\n\n# Berechnet das Alter der Befragten\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\n\n\n3.2.3 Spalten ausw√§hlen\nManchmal enthalten Datens√§tze Spalten, die wir nicht ben√∂tigen. Um Speicherplatz zu sparen oder insgesamt effizienteren Code zu haben, k√∂nnen wir einzelne Spalten selektieren. Dazu nutzen wir die dplyr-Funktion select(). Sie k√∂nnen der Funktion einfach die Namen derjenige Spalten √ºbergeben, die Sie behalten wollen. Wenn wir beispielsweise nur Alter und Geschlecht behalten wollen, sieht das wie folgt aus:\n\n# Erstell einen Datensatz der nur aus Alter und Geschlecht der Befragten besteht\n\ndf_lokal_alterUndGeschlecht &lt;- df_lokal |&gt;\n  select(alter, geschlechtMitNAs)\n\nAlternativ k√∂nnen Sie auch mit einem Minuszeichen einzelne Spalten ausschlie√üen. Wenn wir z.B. die Zwischenschritte unserer Datentransformationen oben entfernen m√∂chten, geht das deutlich leichter √ºber den Ausschluss einiger weniger Spalten als den Einschluss aller anderen. Dabei k√∂nnen wir wieder mal die c()-Funktion nutzen, um gleich mehrere Spalten auf einmal loszuwerden:\n\n# Schlie√üt die Zwischenschritte aus der Transformation aus dem Datensatz aus\n\ndf_lokal_transformiert &lt;- df_lokal |&gt;\n  select(-c(A602, geschlecht, A601_01, geburtsjahr))\n\n\n\n3.2.4 Zeilen nach Inhalt filtern\nIn anderen F√§llen kann es sinnvoll sein, bestimmte F√§lle - also Zeilen - aus dem Datensatz auszuschlie√üen oder umgekehrt: nur bestimmte F√§lle zu behalten. Dazu k√∂nnen wir die filter()-Funktion benutzen. Als Argument √ºbergeben wir hier eine oder mehrere Bedingungen, die erf√ºllt sein m√ºssen, damit ein Fall behalten wird. Beispielsweise k√∂nnen wir einen Datensatz erstellen, in dem nur Befragten enthalten sind, die j√ºnger als 60 sind:\n\n# Entfernt Befragte 60+\n\ndf_lokal_u60 &lt;- df_lokal |&gt;\n  filter(alter &lt; 60)\n\nWir k√∂nnen auch die is.na()-Funktion nutzen (bzw. dere Negation mit !), um Befragte aszuschlie√üen, die ihr Geschlecht nicht angegeben haben.\n\n# Entfernt Befragte ohne Angaben zum Geschlecht\n\ndf_lokla_geschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(geschlechtMitNAs))\n\nManchmal kann es auch sinnvoll sein, zwei Bedingungen zu kombinieren. Das geht mit &:\n\n# Entfernt Befragte die unter 60 und nicht m√§nnlich sind\n\ndf_lokal_alteMaenner &lt;- df_lokal |&gt;\n  filter(geschlechtMitNAs == \"m√§nnlich\" & alter &gt;= 60)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Pakete und Datentransformationen</span>"
    ]
  },
  {
    "objectID": "Skalenniveaus und deskriptive Datenanalyse.html",
    "href": "Skalenniveaus und deskriptive Datenanalyse.html",
    "title": "4¬† Skalenniveaus und deskriptive Datenanalyse",
    "section": "",
    "text": "4.1 Skalenniveaus und zentrale Lagema√üe",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Skalenniveaus und deskriptive Datenanalyse</span>"
    ]
  },
  {
    "objectID": "Skalenniveaus und deskriptive Datenanalyse.html#deskiptive-datenanalyse",
    "href": "Skalenniveaus und deskriptive Datenanalyse.html#deskiptive-datenanalyse",
    "title": "4¬† Skalenniveaus und deskriptive Datenanalyse",
    "section": "4.2 Deskiptive Datenanalyse",
    "text": "4.2 Deskiptive Datenanalyse\nIn diesem Abschnitt werden wir uns anschauen, wie wir die verschiedenen Lagema√üe aus dem Video in R berechnen k√∂nnen. Au√üerdem lernen Sie, wie Sie Daten in Abh√§ngigkeit ihres Skalenniveaus visualisieren k√∂nnen.\n\n4.2.1 Modus\nR hat nach der Installation keine Funktion, die den Modus (oder die Modi) einer Verteilung ermittelt. Wir k√∂nnen aber das Paket DescTools installieren, die eine solche Funktion enth√§lt.\n\n# Installiert das Paket \"DescTools\", falls es noch nicht installiert ist und l√§dt es anschlie√üend. Andernfalls wird es nur geladen.\n\nif(!require(DescTools)){\n  install.packages(\"DescTools\")\n  library(DescTools)\n  }\n\nLade n√∂tiges Paket: DescTools\n\n\nWarning: Paket 'DescTools' wurde unter R Version 4.4.2 erstellt\n\n\nAnschlie√üend laden wir wieder den Datensatz und wandeln die Geschlechtsabfrage um. Den Code kennen Sie schon aus dem letzten Kapitel. Da f√ºr dieses Kapitel ein neues Skript sinnvoll ist, f√ºhren wir auch den Code noch mal aus.\n\n# L√§dt das tidyverse\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Einlesen der Daten \n\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Erstellt eine Spalte aus der Geschlechtsabfrage. Erst wird der Wert \"keine Angabe\" als fehlend deklariertm dann wird ein Faktor mit den √ºbrigen drei Kategorien erstellt\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlechtMitNAs = na_if(A602, 4)) |&gt;\n  mutate(geschlechtMitNAs = factor(geschlechtMitNAs, labels = c(\"m√§nnlich\", \"weiblich\", \"divers\")))\n\nAnschlie√üend k√∂nnen wir die Mode()-Funktion aus dem DescTools-Paket verwenden. Um damit den Modus zu berechnen, m√ºssen wir die Funktion innerhalb der dplyr-Funktion summarise() aufrufen. Diese verdichtet Datens√§tze. Schauen wir uns einmal an, was passiert, wenn wir Mode() einfach entsprechended ausf√ºhren:\n\n#Versucht den Modus der Spalte geschlechtMitNAs zu berechnen\n\nmodus_geschlecht &lt;- df_lokal |&gt;\n  summarise(Modus = Mode(geschlechtMitNAs))\n\nmodus_geschlecht\n\n  Modus\n1    NA\n\n\nWie Sie sehen, gibt die Funktion ein NA zur√ºck. Das ist Rs Art uns zu sagen, dass eine Berechnung nicht durchgef√ºhrt werden kann, weil die Daten fehlende Werte enthalten. Wir k√∂nnen das Problem beheben, indem wir der Mode()-Funktion das Argument na.rm = TRUE √ºbergeben. na.rm steht f√ºr NA remove. Mit dem Wert TRUE sagen wir also, dass fehlende Werte vor der Berechnung entfernt werden sollen.\n\n#Berechnet den Modus der Spalte geschlechtMitNAs \n\nmodus_geschlecht &lt;- df_lokal |&gt;\n  summarise(Modus = Mode(geschlechtMitNAs, na.rm = TRUE))\n\nmodus_geschlecht\n\n     Modus\n1 weiblich\n\n\nNun sehen wir, dass mit 996 F√§llen der Wert weiblich am h√§ufigsten vorkommt.\nSchauen wir uns als n√§chstes an, wie Sie nominale Daten bzw. den Modus visualisieren k√∂nnen. Im letzten Kapitel wurde in K√ºrze das tidyverse vorgestellt und auf das Paket ggplot2 verwiesen, mit dem wir Plots erstellen k√∂nnen.\nIm Folgenden werden Schritt f√ºr Schritt ein einfaches Balkendiagramm erstellen und es nach und nach verbessern. Wir fangen damit an, dass wir das tidyverse laden. Wir erstellen dann ein neues Objekt f√ºr unseren Plot. Dazu geben wir unseren Datensatz mit der Pipe an die Funktion ggplot() weiter. Das ist die Hauptfunktion des Pakets. √úblicherweise wird innerhalb dieser Funktion die Funktion aes() (f√ºr aesthetics) aufgerugen, in der wir je nach Diagramm angeben, welche Spalten auf der x- und y-Achse dargestellt werden soll. F√ºr ein Balkendiagramm ben√∂tigen wir nur die x-Achse, geben also x = geschlechtMitNAs an. Damit sagen wir erstmal nur, welche Spalte wir darstellen wollen, aber noch nichts dar√ºber, was f√ºr eine Darstellung es werden soll. Um die Art des Diagramms festzulegen, gibt es in ggplot2 unz√§hlige Funktionen, die alle mit geom_ beginnen (f√ºr geometry). Hinter dem Unterstrich folgt dann der (englische) Name des Diagrammtyps. In unserem Fall eines Balkendiagramms, hei√üt die entsprechende Funktion geom_bar(). Anders als sonst, verbinden wir die Funktionen in ggplot2 nicht √ºber die Pipe, sondern ein Pluszeichen. In der Summe sieht der Code dann so aus:\n\n# Erstellt ein einfaches Balkendiagramm der Geschlechtsabfrage\n\nplotGeschlecht &lt;- df_lokal |&gt;\n  ggplot(aes(x = geschlechtMitNAs))+\n  geom_bar()\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nDas ist - nun ja - sagen wir mal, es ist nicht sonderlich h√ºbsch. Folgende Dinge fallen auf:\n\nEs gibt einen Balken f√ºr NAs, dabei enthalten diese ja per definitionem keine Informationen.\nDie Angabe absoluter H√§ufigkeiten ist etwas problematisch; besser w√§ren relative H√§ufigkeiten.\nDie Werte der einzelnen Kategorien k√∂nnen wir aktuell nur sch√§tzen.\nDer Hintergrund und die Farbe der Balken sind nicht sonderlich ansehnlich.\nDie Beschriftungen der Achsen (geschlechtMitNAs und count) sind nicht gerade selbsterkl√§rend.\n\nDiese Liste k√∂nnen wir nun einfach abarbeiten. Manchmal ist es sinnvoll, die Daten noch ein bisschen aufzubereiten, bevor wir sie an ggplot() √ºbergeben. Daf√ºr deklarieren wir ein neues Objekt, das die Daten enthalten soll. Als erstes k√∂nnen wir dann mit der filter()-Funktion, die Sie im letzten Kapitel kennengelernt haben, die NAs entfernen. Anschlie√üend nutzen wir die group_by()-Funktion aus dplyr. Diese Funktion sorgt daf√ºr, dass die nachfolgenden Funktionen nicht auf den gesamten Datensatz angewendet werden, sondern auf die jeweiligen Gruppen (m√§nnlich, weiblich, divers). Anschlie√üend nutzen wir wieder die summarise()-Funktion. Dort k√∂nnen wir die Prozentwerte der einzelnen Gruppen mit der folgenden Formel berechnen: n()/nrow(df_lokal)*100. n() gibt die Anzahl der F√§lle zur√ºck. Durch das Aufrufen von group_by() sind es hier die F√§lle pro Auspr√§gung von geschlechtMitNAs. Diesen Wert teilen wir durch nrow(df_lokal). Diese Funktion gibt die Anzahl der Zeilen im kompletten Datensatz zur√ºck. Das Ergebnis multiplizieren wir mit 100, um einen Prozentwert zu erhalten. Als letztes nutzen wir mutate(), um die Prozentwerte auf zwei Nachkommastellen zu runden. Das Ergebnis sehen Sie unten:\n\n# Erstellt einen reduzierten Datensatz, der die relativen H√§ufigkeiten der Auspr√§gungen von geschlechtMitNAs enth√§lt\n\ndf_plot_geschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(geschlechtMitNAs)) |&gt;\n  group_by(geschlechtMitNAs) |&gt;\n  summarise(prozent = n()/nrow(df_lokal)*100) |&gt;\n  mutate(prozent = round(prozent, 2))\n\ndf_plot_geschlecht\n\n# A tibble: 3 √ó 2\n  geschlechtMitNAs prozent\n  &lt;fct&gt;              &lt;dbl&gt;\n1 m√§nnlich           44.0 \n2 weiblich           54.0 \n3 divers              0.38\n\n\nWenn wir diesen Datensatz an ggplot() √ºbergeben und versuchen, ein Balkendiagramm zu erstellen, haben wir zwar keinen Balken f√ºr NA mehr, daf√ºr ein neues Problem: Alle Balken sind gleich hoch.\n\n# Versucht, ein Balkendiagramm der Geschlechtsabfrage ohne NAs zu erstellen\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs))+\n  geom_bar()\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nUm dieses Problem zu beheben, k√∂nnen wir angeben, dass die y-Achse den Wert aus der Spalte prozent darstellen soll. Zus√§tzlich m√ºssen wir beim Aufrufen von geom_bar() das Argument stat = \"identity\" angeben. Damit sagen wir der Funktion, dass sie nichts berechnen muss, sondern wir schon die finalen Werte als y-Wert angegeben haben.\n\n# Erstellt ein Balkendiagramm der relativen H√§ufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\")\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nAls n√§chstes wollen wir die Werte beschriften. Dazu f√ºgen wir unserem Plot eine neue geom-Funktion hinzu, n√§mlich geom_text(). Dieser Funktion √ºbergeben wir auch wieder aes(), um zu bestimmen, was angezeigt werden soll. Das Argument f√ºr Beschriftungen lautet label. Als Wert k√∂nnen wir die Spalte prozent angeben. Die Standardeinstellung ist, dass der Wert an seine Position auf der y-Achse geschrieben wird. Das ist etwas unpraktisch, da dort ja auch die Balken aufh√∂ren. Indem wir geom_text() das Argument vjust (f√ºr vertical justification) und den Wert -0,5 (in R reicht -.5) √ºbergeben, k√∂nnen wir die Beschriftung leicht nach oben verschieben.\n\n# Erstellt ein beschriftetes Balkendiagramm der relativen H√§ufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\")+\n  geom_text((aes(label = prozent)), vjust = -.5)\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nAls n√§chstes passen wir die Farben etwas an. Gleich vorab: ggplot2 bietet nahezu unendlich viele M√∂glichkeiten, das Aussehen von Diagrammen anzupassen. Hier machen wir es uns relativ einfach und nutzen vorhandene Funktionen. So wie es viele geom_Funktionen gibt, gibt es auch einige theme_ Funktionen. Hier erg√§nzen wir theme_minimal() zu unserem Diagramm. Damit wird zwar der Hintergrund, nicht aber die Farbe der Balken angepasst. Das k√∂nnen wir tun, indem wir der geom_bar()-Funktion das Argument fill und eine Farbe √ºbergeben. Diese m√ºssen auf Englisch angegeben werden. Hier verwenden wir ein helles grau.\n\n# Erstellt ein beschriftetes Balkendiagramm der relativen H√§ufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\", fill = \"lightgrey\")+\n  geom_text((aes(label = prozent)), vjust = -.5)+\n  theme_minimal()\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nAls letztes √§ndern wir die Achsenbeschriftungen. Dazu f√ºgen wir die labs()-Funktion hinzu. Mit den Argumenten x und y k√∂nnen wir die Beschriftung anpassen.\n\n# Erstellt ein beschriftetes Balkendiagramm der relativen H√§ufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\", fill = \"lightgrey\")+\n  geom_text((aes(label = prozent)), vjust = -.5)+\n  theme_minimal()+\n  labs(x = \"Geschlecht\", y = \"relative H√§ufigkeit in Prozent\")\n\nplotGeschlecht\n\n\n\n\n\n\n\n\n\n\n4.2.2 Median\nAnders als beim Modus gibt es f√ºr den Median eine R-Funktion, die wir ohne Weiteres nutzen k√∂nnen: die median()-Funktion. Auch hier m√ºssen wir darauf achten, na.rm = TRUE anzugeben, damit der Median berechnet werden kann. Im folgenden Beispiel berechnen wr den Median der Spalte A203_06. In der Spalte ist codiert, wie h√§ufig die Befragten Lokalzeitungen lesen (von 1 = ‚Äúnie‚Äù bis 6 = ‚Äúmehrmals t√§glich‚Äù).\n\n# Benenntdie Spalte A203_06 in lokalzeitung um\ndf_lokal &lt;- df_lokal |&gt;\n rename(lokalzeitung = A203_06) \n\n# Berechnet den Median der Lokalzeiungsnutzung\nmedian_lokalzeitung &lt;- df_lokal |&gt;\n  summarise(median = median(lokalzeitung, na.rm = TRUE))\n\nmedian_lokalzeitung\n\n  median\n1      4\n\n\nDer Median ist 4, was einer Nutzung mehrmals pro Woche entspricht. Es gibt viele verschiedene M√∂glichkeiten, den Median bzw. die Verteilung von ordinalen Daten zu visualisieren. Bei wenigen Auspr√§gungen, so wie im Fall der Nutzung von Lokalzeitungen, k√∂nnen wir √§hnlich vorgehen wie beim Modus oben. Dazu m√ºssen wir die Spalte in einen Faktor umwandeln, bevor wir sie an ggplot() √ºbergeben. Anschlie√üend gehen wir √§hnlich vor wie oben, allerdings bleiben wir der einfachheithalber bei absoluten H√§ufigkeiten. Eine relevante Erg√§nzung nehmen wir aber vor: Mit der geom_vline()-Funktion (f√ºr vertical line) und dem Argument xintercept = 4, k√∂nnen wir eine Linie hinzuf√ºgen, die den Median anzeigt.\n\n# Wandelt die Nutzung von Lokalzeitungen in einen Faktor um und plottet die Daten als Balkendiagramm\nbalkenPlot_lokalzeitung &lt;- df_lokal |&gt;\n  mutate(lokalzeitungFaktor = factor(lokalzeitung, labels = c(\"nie\", \"weniger als ein Mal im Monat\",\n                                                              \"mehrmals im Monat\", \"mehrmals in der Woche\",\n                                                              \"t√§glich\", \"mehrmals t√§glich\"))) |&gt;\n  filter(!is.na(lokalzeitungFaktor)) |&gt;\n  ggplot(aes(x = lokalzeitungFaktor))+\n  geom_bar(fill = \"lightgrey\")+\n  theme_minimal()+\n  labs(x = \"Nutzung von Lokalzeitungen\", y = \"H√§ufigkeit\")+\n  geom_vline(xintercept = 4, linetype = \"dashed\")\n\nbalkenPlot_lokalzeitung\n\n\n\n\n\n\n\n\nDas ist schon sehr nah an einer akzeptablen Darstellung, aber die Wertbeschriftungen sehen furchtbar aus! Hier m√ºssen wir etwas Hand anlegen und Zeilenumbr√ºche einf√ºgen. Die Beschriftungen k√∂nnen wir mit der Funktion scale_x_discrete() und darin mit dem labels-Argument anpassen. Um einen Zeilenumbruch hinzuzuf√ºgen, k√∂nnen wir an einer beliebigen Stelle in einem string \\n erg√§nzen. Diese Funktion k√∂nnen wir mit einem + unserem bisherigen Objekt balkenPlot_lokalzeitung hinzuf√ºgen:\n\n# Ver√§ndert die Beschriftungen der Balken\n\nbalkenPlot_lokalzeitung &lt;- balkenPlot_lokalzeitung+\n  scale_x_discrete(labels=c(\"nie\" = \"nie\", \"weniger als ein Mal im Monat\" = \"weniger als\\n ein Mal im Monat\",\n                              \"mehrmals im Monat\" = \"mehrmals\\n im Monat\", \"mehrmals in der Woche\" = \n                              \"mehrmals\\n in der Woche\", \"t√§glich\" = \"t√§glich\",\n                              \"mehrmals t√§glich\" = \"merhmals\\n t√§glich\"))\n\nbalkenPlot_lokalzeitung\n\n\n\n\n\n\n\n\nEine andere h√§ufige Visualisierung von ordinalen Daten ist der sogenannte Boxplot, der mit der Funktion geom_boxplot() erstellt wird. Beachten Sie im Beispiel unten, dass wir die Spalte lokalzeitung im Aufruf von ggplot() bzw. darin aes() als y-Wert definieren. Wir k√∂nnten auch den x-Wert w√§hlen, dann w√ºrde der Boxplot auf der Seite liegen.\n\nboxplot_lokalzeitung &lt;- df_lokal |&gt;\n  filter(!is.na(lokalzeitung)) |&gt;\n  ggplot(aes(y = lokalzeitung))+\n  geom_boxplot()+\n  theme_minimal()+\n  labs(y = \"H√§ufigkeit der Lokalzeitungsnutzung\")\n\nboxplot_lokalzeitung\n\n\n\n\n\n\n\n\nWas Sie hier sehen ist erstmal nicht sonderlich h√ºbsch, sollte aber dennoch kurz erkl√§rt werden: Die dicke schwarze Linie beim Wert 4 zeigt den Median. Die eingekasteten Bereiche dar√ºber und darunter zeigen das 75. bzw. das. 25. Quartil. Oder einfach gesagt: 25 % der Befragten haben den Wert 2 oder weniger angegeben und weitere 25 % den Wert 5 oder mehr. Die Linien nach unten und oben gehen bis zum Minimum bzw. Maximum.\nFolgende Probleme hat die Darstellung:\n\nDer Boxplot ist sehr breit. Das sieht furchtbar aus!\nDie y-Achse ist nur sp√§rlich beschriftet.\nDie x-Achse hat eine Beschriftung, die √ºberhaupt nicht nachvollziehbar ist.\nDas Koordinatensystem hat senkrechte Linien, die keinen Sinn ergeben, da wir ja eigentlich gar nichts auf der x-Achse abbilden.\n\nFangen wir mit den ersten beiden Problemen an. Wir sehen auf der Grafik oben, dass der auf der x-Achse der Bereich von x = -0,4 bis x = 0,4 (was auch immer diese Werte bedeuten m√∂gen!) dargestellt ist und der Boxplot genau diesen Bereich einnimmt. Wir k√∂nnen die Funktion xlim() nutzen, um den dargestellten Bereich zu erweitern. Dazu m√ºssen wir einfach nur zwei Werte angeben, z.B. -1 und 1.\nUm die y-Achse etwas sch√∂ner zu machen, k√∂nnen wir eine √§hnliche Funktion nutzen, wie im Balkendiagramm oben: scale_y_continuous(). Mit dem Argument breaks k√∂nnen wir angeben, welche Werte beschriftet sein sollen. Hier k√∂nnen wir 1:6 angeben, um alle ganzen Zahlen zwischen 1 und 6 anzeigen zu lassen.\n\nboxplot_lokalzeitung &lt;- boxplot_lokalzeitung+  \n  xlim(-1,1)+\n  scale_y_continuous(breaks = 1:6)\n\n\nboxplot_lokalzeitung\n\n\n\n\n\n\n\n\nDas sieht schon etwas besser aus. Wir haben nun aber ein neues Problem: Auf der y-Achse werden nun waagerechte Linien zwischen den ganzen Zahlen angezeigt, dabei konnte die Variable diese Werte gar nicht annhemen.\nDieses Problem k√∂nnen wir gemeinsam mit den √ºbrigen Punkte von oben in einem Rutsch erledigen, indem wir die theme()-Funktion nutzen. Diese Funktion kann zugegebenerma√üen etwas abschreckend sein. Sie k√∂nnen damit die Darstellung aller einzelnen Elemente eines Plots anpassen oder - und das ist f√ºr uns hier aber auch generell h√§ufig entscheidend - sie entfernen! Das Schema ist immer gleich: Sie geben ein Element an und schreiben hinter ein Gleichheitszeichen, wie es dargestellt werden soll. Geben Sie dort element_blank() an, wird das Element entfernt. Das nutzen wir hier um die folgenden Elemente zu entfernen:\n\nDie Beschriftung der x-Achse ‚Äì&gt; das Element hei√üt axis.text.x\nDie vertikalen Linien im Koordinatensystem ‚Äì&gt; die Elemente hei√üen panel.grid.major.x und panel.grid.minor.x\nDie horizontalen Linien zwischen den ganzen Zahlen ‚Äì&gt; das Element hei√üt panel.grid.minor.y\n\n\nboxplot_lokalzeitung &lt;- boxplot_lokalzeitung+\n  theme(axis.text.x = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\nboxplot_lokalzeitung\n\n\n\n\n\n\n\n\nDeutlich h√§ufiger werden Sie Boxplots begegnen (oder selbst erstellen), wenn es um die Darstellung mehrerer Gruppen geht. Im folgenden Beispiel sehen Sie einen Boxplot f√ºr die Nutzung von Lokalzeitungen nach Geschlecht der Befragten. Im wesentlichen ist er sehr √§hnlich wie der Plot oben, allerdings m√ºssen wir diesmal keine Elemente entfernen. Vor allem aber m√ºssen wir im Aufruf von ggplot() bzw. darin aes() angeben, dass das Geschlecht der Befragten auf der x-Achse dargestellt werden soll.\n\nboxplot_lokalzeitung_geschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(lokalzeitung)) |&gt;\n  filter(!is.na(geschlechtMitNAs)) |&gt;\n  ggplot(aes(y = lokalzeitung, x = geschlechtMitNAs))+\n  geom_boxplot()+\n  theme_minimal()+\n  scale_y_continuous(breaks = 1:6)+\n  labs(y = \"H√§ufigkeit der Lokalzeitungsnutzung\", x = \"Geschlecht\")\n\nboxplot_lokalzeitung_geschlecht\n\n\n\n\n\n\n\n\nDas Ergebnis sieht schon sehr ordentlich aus. Der einsame Punkt in der Spalte divers steht f√ºr einen Ausrei√üer: Eine Person liest deutlich h√∂ufiger Lokalzeitungen als andere Menschen, die sich nicht-bin√§r identifizieren. In erster Linie liegt das an der sehr geringen Fallzahl in der Gruppe (vgl. das Balkendiagramm von oben). Um das sichtbar zu machen, k√∂nnen wir die Rohdaten anzeigen lassen. Das geht grunds√§tzlich mit geom_point(), hat aber den Nachteil, dass dann alle Datenpunkte an derselben Stelle dargestellt werden:\n\nboxplot_lokalzeitung_geschlecht+\n  geom_point()\n\n\n\n\n\n\n\n\nDas hilft uns nicht wirklich weiter. Eine bessere M√∂glichkeit ist geom_jitter(). Damit werden die Rohdaten etwas gestreut geplottet. Durch das Argument alpha = .25 k√∂nnen wir die Punkte zus√§tzlich etwas transparent machen.\n\nboxplot_lokalzeitung_geschlecht &lt;- boxplot_lokalzeitung_geschlecht+\n  geom_jitter(alpha = .25)\n\nboxplot_lokalzeitung_geschlecht\n\n\n\n\n\n\n\n\n\n\n4.2.3 Mittelwert und Standardabweichung\nF√ºr Mitelwert und Standardabweichung gibt es ebenfalls zwei R-Funktionen, die wir direkt nutzen k√∂nnen: mean() und sd(). Auch hier m√ºssen wir darauf achten, dass wir na.rm = TRUE angeben.\nIm folgenden Beispiel berechnen wir zun√§chst das Alter der Befragten mit dem Code aus dem letzten Kapitel. Anschlie√üend nutzen wir summarse(), um den Datensatz auf Mittelwert und Standardabweichung des Alters zu reduzieren. Innerhalb von summarise() berechnen wir entsprechen mit mean() den Mittelwert und mit sd() die Standardabweichung. Beides runden wir mit round() auf zwei Nachkommastellen.\n\n# Berechnet das Alter der Befragten\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = str_trim(A601_01)) |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4)) |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr)) |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\n# Berechnet Mittelwert und Standardabweichung des Alters\n\ndf_alter &lt;- df_lokal |&gt;\n  summarise(MWAlter = round(mean(alter, na.rm = TRUE), 2),\n            SDAlter = round(sd(alter, na.rm = TRUE), 2))\n\ndf_alter\n\n  MWAlter SDAlter\n1   49.66   15.31\n\n\nWir sehen, dass die Befragten im Mittel 49,66 also fast 50 Jahre als waren, bei einer Standardabweichung von 15,31 Jahren. Im Video oben haben Sie erfahren, dass bei einer Normalverteilung ca. 68 % aller Werte innerhalb der Region Mittelwert - 1 Standardabweichung bis Mittelwert + 1 Standardabweichung liegen. Hier w√§re das entsprechend der Bereich von 34,35 bis 64.97 Jahren, zumindest sofern die Variable normalverteilt ist. Um das zu pr√ºfen und genereall um metrische Daten zu visualisieren, k√∂nnen wir ein sogenanntes Histogramm zeichnen. Dazu nutzen wir geom_histogramm(). Im Prinzip handelt es sich dabei um eine Art Balkendiagramm f√ºr metrische Daten, bei der einzelne Auspr√§gungen zusammengefasst werden,\n\nhistogramm_alter &lt;- df_lokal |&gt;\n  filter(!is.na(alter)) |&gt;\n  ggplot(aes(x = alter))+\n  geom_histogram(fill = \"lightgrey\", bins = 40)+\n  theme_minimal()+\n  labs(x = \"Alter der Befragten\", y = \"H√§ufigkeit\")\n  \n\nhistogramm_alter\n\n\n\n\n\n\n\n\nDem Histogramm k√∂nnen wir entnehmen, dass die Daten ann√§hnernd normalverteilt sind. Das linke Ende der Verteilung ist etwas steiler. Das ist zu erwarten, denn √ºblicherweise gibt es ein Mindestalter zur Teilnahme an Befragungen. Wir sehen auch, dass Menschen um die 60 Jahre und √§lter relativ stark vertreten sind. Gemessen an der Bev√∂lkerung ist auch das nicht sonderlich. F√ºr die meisten statistischen Zweck k√∂nnten Sie bei so einer Verteilung aber davon ausgehen, dass Sie zumindest nah genug an einer Normalverteilung dran sind.\nW√§hrend uns das Histogramm einen guten √úberblick √ºber die Verteilung als Ganze gibt, ist es manchmal sinnvoll, Mittelwert und Standardabweichung direkt darzustellen. Das gilt insbesondere dann, wenn Sie mehrere Gruppen vergleichen wollen. Im folgenden Beispiel stelle wir das Durchschnittsalter (also den Mittelwert) der Befragten nach Geschlecht dar. Dazu wollen wir die Streuung um den Mittelwert der jeweiligen Gruppen darstellen. Hier machen wir das, indem wir die Standardabweichung ebenfalls darstellen. In wissenschaftlichen Arbeiten werden Sie auch immer mal Darstellungen begegnen, in denen andere Ma√üe genutzt werden: entweder der Standardfehler oder sogenannte Konfidenzintervalle. Die Begriffe werden wir noch kennenlernen, ignorieren sie aber in diesem Kapitel noch.\nF√ºr unser Beispiel berechnen wir als erstes Mittelwert und Standardabweichung der jeweiligen Gruppen. Alles, was wir daf√ºr brauchen, haben wir schon kennengelernt: Wir nutzen filter() um fehlende Werte auszuschlie√üen, nutzen group_by(), um die Daten zu Gruppieren und rufen dann mean() und sd() innerhalb von summarise() auf.\n\n# Berechnet Mittelwert und Standardabweichung nach Geschecht\ndf_lokal_alterUndGeschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(geschlechtMitNAs)) |&gt;\n  filter(!is.na(alter)) |&gt;\n  group_by(geschlechtMitNAs) |&gt;\n  summarise(MWAlter = mean(alter),\n            SDAlter = sd(alter))\n\nUm die Gruppenmittelwerte mit jeweiliger Standardabweichug abzubilden, nutzen wir zwei neue geom_ Funktionen: geom_point() f√ºr die Mittelwerte und geom_errorbar() f√ºr die Standardabweichungen. Aber fangen wir obne an: zun√§chst legen wir in ggplot() und aes() fest, dass wir das Alter auf der y-Achse und das Geschlecht auf der x-Achse darstellen wollen. geom_point() sorgt daf√ºr, dass die Gruppenmittelwerte jeweils durch einen Punkt dargestellt werden. geom_errorbar() zeichnet Balken um diese Punkte. Dazu m√ºssen wir wieder in aes() angeben, wo diese Balken anfangen und aufh√∂ren sollen. Den Startpunkt legen wir mit ymin=MWAlter-SDAlter und den Endpunkt mit ymax=MWAlter+SDAlter fest.\n\n# Plottet die Gruppenmittelwerte und Standardabweichungen\nalter_nach_geschlecht &lt;- df_lokal_alterUndGeschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = MWAlter))+\n  geom_point()+\n  geom_errorbar(aes(ymin=MWAlter-SDAlter, ymax=MWAlter+SDAlter))+\n  labs(x = \"Geschlecht\", y = \"Alter\")+\n  theme_minimal()\n\nalter_nach_geschlecht\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrafiken speichern\n\n\n\nWenn Sie einen Plot speichern wollen, k√∂nnen Sie die ggsave()-Funktion verwenden. Folgende Argumente sollten Sie der Funktion √ºbergeben:\n\nfilename = Den Namen, den die Datei tragen soll (in Anf√ºhrungszeichen).\nplot = Den Namen des Objekts, das Sie speichern wollen.\nwidth = Die gew√ºnschte Breite der Grafik.\nheight = Die gew√ºnschte H√∂he der Grafik.\nunits = Die Ma√üeinheit in der Breite und H√∂he angegeben werden: ‚Äúmm‚Äù, ‚Äúcm‚Äù, ‚Äúpx‚Äù oder ‚Äúin‚Äù f√ºr millimeter centimeter, pixel oder inch.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Skalenniveaus und deskriptive Datenanalyse</span>"
    ]
  },
  {
    "objectID": "Hypothesen und Testtheorie.html",
    "href": "Hypothesen und Testtheorie.html",
    "title": "5¬† Hypothesen und Testtheorie",
    "section": "",
    "text": "5.1 Hypothesen\nGanz allgemein gesprochen, verstehen wir unter einer Hypothese eine allgemeine Aussage √ºber einen vermuteten Zusammenhang zwischen empirischen oder logischen Sachverhalten. In unserem Kontext gelten drei Anforderungen an Hypothesen:\nGrunds√§tzlich k√∂nnen Sie immer eine Hypothese aufstellen, wenn Sie eine ganz konkrete Annahme haben. Allerdings entspricht es guter wissenschaftlicher Praxis, dass Sie Ihre Hypothesen aus dem aktuellen Forschungsstand Ihres Themas, d.h. aktuellen Theorien und verwandten empirischen Befunden, ableiten. Beispielsweise entspricht die Hypothese ‚ÄúAm Freitag schmeckt das Essen in der Mensa der Uni Erfurt schlechter als an den anderen Wochentagen‚Äù den oben genannanten Annforderungen. Allerdings handelt es sich dabei um nicht viel mehr als einen auf meiner Wahrnehmung beruhenden fl√ºchtigen Gedanken.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Hypothesen und Testtheorie</span>"
    ]
  },
  {
    "objectID": "Hypothesen und Testtheorie.html#hypothesen",
    "href": "Hypothesen und Testtheorie.html#hypothesen",
    "title": "5¬† Hypothesen und Testtheorie",
    "section": "",
    "text": "Sie d√ºrfen keine Einzelf√§lle beschreiben.\nSie m√ºssen die Struktur eines sinnvollen Konditionalsatzes aufweisen (z.B. wenn-dann, je-desto). Diese ist logisch notwendig, muss aber nicht zwingend expliziert formuliert sein.\nSie m√ºssen falsifizierbar sein.\n\n\n\n\n\n\n\nFalsifizierbarkeit\n\n\n\nFalsifizierbarkeit bedeutet im Kern nichts anderes, als dass wir in der Lage sein m√ºssen, die Hypothese zu widerlegen. In der Forschungspraxis bedeutet das konkret, dass wir in der Lage sein m√ºssen, Daten zu erheben, anhand derer wir die Hypothese testen k√∂nnen.\n\n\n\n\n5.1.1 Arten von Hypothesen\nIn den nachfolgenden Abschnitten werden wir uns anschauen, wie verschiedene Hypothesen differenziert werden k√∂nnen.\n\n5.1.1.1 Null- und Alternativhypothese\nEinen ersten Unterschied, den Sie kennen sollten, ist der zwischen Null- und Alternativhypothese. Manchmal werden die beiden auch als H0 und H1 bezeichnet. Letztere ist immer das, was Sie inhaltlich eigentlich annehmen. Die Nullhypothese besagt dagegen, dass Ihre Annahme nicht zutrifft. Die Nullhypothese ist deshalb wichtig, weil die statistischen Verfahren, die Sie in dieser Veranstaltung lernen werden, nicht die Alternativ-, sondern die Nullhypothese testen. Streng genommen gelten die oben genannten Kriterien also in erster Linie f√ºr die Nullhypothese. Das gilt insbesondere f√ºr die Falsifizierbarkeit!\nStellen wir uns einmal vor, dass Sie annehmen, dass j√ºngere Menschen mehr Zeit mit der Nutzung sozialer Medien verbringen als √§ltere Menschen. Eine m√∂gliche Formulierung der Alternativhypothese lautet:\n\nH1: Es besteht ein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\nDagegen lautet die Nullhypothese:\n\nH0: Es besteht kein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\n\n\n5.1.1.2 Gerichtete und ungerichtete Hypothesen\nEin weiterer wichtiger Aspekt, nach dem Sie Hypothesen unterscheiden k√∂nnen, ist, ob diese gerichtet oder ungerichtet sind. Gerichtet sind Hypothesen immer dann, wenn Sie eine Vermutung √ºber die Richtung eines Zusammenhangs haben. Ungerichtet bedeutet dagegen, dass Sie einfach nur annehmen, dass es einen Zusammenhang gibt, ohne zu vermuten, wie genau dieser ausf√§llt. Nehmen wir noch einmal das Beispiel von oben. Im Text haben wir gesagt, dass Sie vermuten, dass j√ºngere Menschen mehr Zeit mit der Nutzung verbringen als √§ltere. Das ist ein Beispiel f√ºr eine gerichtete Hypothese, da wir eine Vermutung dar√ºber haben, welche Personen mehr bzw. weniger Zeit mit der Nutzung verbringen. Die Formulierung der H1 im Beispiel oben ist dagegen ungerichtet, da nur gesagt wird, dass ein Zusammenhang besteht. Formulieren wir die Hypothese also um:\n\nH1: J√ºngere Menschen verbringen mehr mit der Nutzung sozialer Netzwerke als √§ltere Menschen.\n\nEntsprechend √§ndert sich auch die H0:\n\nH0: J√ºngere Menschen verbringen nicht mehr mit der Nutzung sozialer Netzwerke als √§ltere Menschen.\n\nBeachten Sie, dass diese Nullhypothese nicht nur dann falsifiziert wird, wenn es keinen Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke gibt, sondern auch, falls es zwar einen Zusammenhang gibt, dieser aber in die entgegengesetzte Richtung l√§uft. Also Menschen mehr Zeit mit der Nutzung verbringen, je √§lter sie sind.\n\n\n5.1.1.3 Hypothesen √ºber Zusammenh√§nge und Unterschiede\nDie meisten Hypothesen, die Sie w√§hrend Ihres Studiums aufstellen und testen werden, befassen sich entweder mit Zusammenh√§ngen, so wie im bisherigen Beispiel, oder mit Unterschieden zwischen (mindestens) zwei Gruppen. Solche Hypothesen sind immer dann sinnvoll, wenn Sie entweder an Differenzen zwischen nat√ºrlich auftretenden Gruppen interessiert sind (z.B. Studierende vs.¬†Azubis, Arbeitnehmerinnen und Arbeitnehmer vs.¬†Selbstst√§ndige, Menschen aus Europa vs.¬†den USA) oder wenn Sie im Rahmen eines Experiments die Unterschiede zwischen einer Experimental- und einer Kontrollgruppe untersuchen. Oder anders gesagt: Hypothesen √ºber Unterschiede sind immer dann sinnvoll, wenn Ihre Hypothese eine Aussage √ºber Gruppen enth√§lt, die Sie mit einer nominalen Variable messen k√∂nnen.\nSchauen wir uns mal ein Beispiel f√ºr eine Hypothese √ºber Unterschiede an. Es gelten dieselben Kriterien wie oben:\n\nH1: Menschen im Ruhestand und Menschen, die nicht im Ruhestand sind, schauen unterschiedlich oft lineares Fernsehen.\n\nDiese Hypothese beschreibt einen vermuteten Unterschied zwischen Rentnerinnen und Rentnern und allen anderen Menschen. Gleichzeitig ist es eine ungerichtete Hypothese, da sie keine Annahme dar√ºber enth√§lt, welche der beiden Gruppen h√§ufiger (bzw. seltener) lineares Fernsehen schaut. Die zugeh√∂rige H0 lautet dementsprechend:\n\nH0: Menschen im Ruhestand und Menschen, die nicht im Ruhestand sind, schauen gleich oft lineares Fernsehen als Menschen.\n\nW√ºrden wir stattdessen davon ausgehen, dass Rentnerinnen und Rentner h√§ufiger klassisches Fernsehen schauen (z.B. weil sie einfach mehr Zeit haben), k√∂nnten wir die folgende gerichtete Alternativhypothese mit zugeh√∂riger Nullhypothese aufstellen.\n\nH1: Menschen im Ruhestand schauen √∂fter lineares Fernsehen als Menschen, die nicht im Ruhestand sind.\n\n\nH0: Menschen im Ruhestand schauen nicht √∂fter lineares Fernsehen als Menschen, die nicht im Ruhestand sind.\n\n\n\n\n5.1.2 Statistische Hypothesen\nBisher haben wir uns in erster Linie mit inhaltlichen Aspekten von Hypothesen besch√§ftigt. Als N√§chstes werfen wir einen Blick darauf, welche statistischen Annahmen hinter den Hypothesen stecken.\nIm Fall von Hypothesen √ºber Zusammenh√§nge wird in der Regel ein Ma√ü berechnet, das etwas √ºber die St√§rke eines Zusammenhangs aussagt, z. B. einen sogenannten Korrelationskoeffizienten (dazu im √ºbern√§chsten Kapitel mehr). Bei ungerichteten Hypothesen lautet die Nullhypothese immer, dass dieses Ma√ü genau den Wert 0 annimmt. Schauen wir uns das am Beispiel von oben an. Inhaltlich haben wir dort die folgende Alternativ- bzw. Nullhypothese aufgestellt:\n\nH1: Es besteht ein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\n\nH0: Es besteht kein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\nDie zugeh√∂rigen statistischen Hypothesen sehen Sie untenstehend. r ist dabei ein Platzhalter f√ºr das Zusammenhangsma√ü:\n\nstatistische H1: \\(r_{Alter,~Nutzung~sozialer~Medien} \\neq 0\\)\n\n\nstatistische H0: \\(r_{Alter,~Nutzung~sozialer~Medien} = 0\\)\n\nWie oben angedeutet, verh√§lt es sich bei gerichteten Hypothesen etwas anders, da die Nullhypothese nur aussagt, dass die Richtung nicht zutrifft. Dort hatten wir die folgenden Hypothesen aufgestellt:\n\nH1: J√ºngere Menschen verbringen mehr Zeit mit der Nutzung sozialer Netzwerke als √§ltere Menschen.\n\n\nH0: J√ºngere Menschen verbringen nicht mehr mit der Nutzung sozialer Netzwerke als √§ltere Menschen.\n\nIn diesem Fall gehen wir von einem negativen Zusammenhang aus. Das bedeutet nichts anderes, als dass kleinere Messwerte in der einen Variable (das Alter) mit h√∂heren Werten in der anderen Variable (die Nutzung sozialer Medien) einhergehen. W√ºrden wir das Gegenteil vermuten, also dass eher √§ltere Menschen mehr Zeit mit der Nutzung sozialer Medien verbringen, w√ºrden wir einen positiven Zusammenhang annehmen (hohe Werte gehen mit hohen Werten einher). Daraus folgt, dass die Nullhypothese nicht aussagt, dass es keinen Zusammenhang gibt, sondern, dass es entweder keinen oder einen positiven Zusammenhang gibt. Anders gesagt: keinen negativen Zusammenhang. Die statistischen Hypothesen lauten also wie folgt:\n\nstatistische H1: \\(r_{Alter,~Nutzung~sozialer~Medien} &lt; 0\\)\n\n\nstatistische H0: \\(r_{Alter,~Nutzung~sozialer~Medien} \\ge 0\\)\n\nIm Fall von Hypothesen √ºber Unterschiede verh√§lt es sich im Prinzip √§hnlich. Allerdings m√ºssen wir hier definieren, was genau wir eigentlich mit einem Gruppenunterschied meinen. In der Regel ist das der Mittelwert. Wir gehen also davon aus, dass der Mittelwert der einen Gruppe gr√∂√üer oder kleiner ist als der Mittelwert der anderen Gruppe. F√ºr unsere ungerichtete Hypothese von oben sieht das entsprechend so aus, wobei M eine Abk√ºrzung f√ºr Mittelwert ist:\n\nstatistische H1: \\(M_{Fernsehnutzung,~Ruhestand} \\neq M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\n\nstatistische H0: \\(M_{Fernsehnutzung,~Ruhestand} = M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\nDie gerichtete Version dieser Hypothese lautet dagegen wie folgt:\n\nstatistische H1: \\(M_{Fernsehnutzung,~Ruhestand} &gt; M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\n\nstatistische H0: \\(M_{Fernsehnutzung,~Ruhestand} \\le M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\nDie Grundlagen der statistischen Hypothesen sind wichtig, weil sie das abbilden, was Sie mit statistischen Verfahren eigentlich testen! Allerdings ist eher un√ºblich, statistische Hypothesen in Abschlussarbeiten oder gar wissenschaftlichen Ver√∂ffentlichungen zu schreiben. Selbst die Nullhypothese werden Sie dort in der Regel nicht antreffen. Stattdessen reicht es in der Regel, die Alternativhypothese aufzuschreiben. Sofern diese anst√§ndig formuliert ist, impliziert sie sowohl die statistische als auch die Nullhypothese.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Hypothesen und Testtheorie</span>"
    ]
  },
  {
    "objectID": "Hypothesen und Testtheorie.html#testtheorie",
    "href": "Hypothesen und Testtheorie.html#testtheorie",
    "title": "5¬† Hypothesen und Testtheorie",
    "section": "5.2 Testtheorie",
    "text": "5.2 Testtheorie\n\n5.2.1 p-Werte\nIm Lauf der kommenden Wochen werden wir verschiedene Verfahren kennenlernen, mit denen Sie Hypothesen testen k√∂nnen. Die Idee dahinter ist aber immer dieselbe: Unsere Daten bilden (in der Regel) nur eine Stichprobe der Grundgesamtheit ab. Das Ziel eines Hypothesentests liegt darin, zu pr√ºfen, ob die von uns beobachteten Zusammenh√§nge bzw. Unterschiede auch in der Grundgesamtheit zu erwarten sind. Die Verfahren werden unter dem Begriff Inferenzstatistik zusammengefasst und enthalten jeweils einen sogenannten Signifikanztest. Damit pr√ºfen wir, ob wir H0 verwerfen m√ºssen, H1 wird also immer nur indirekt getestet. Die Entscheidung dar√ºber, ob H0 verworfen wird, basiert auf sogenannten p-Werten, die von den Signifikanztests berechnet werden.\nWas nun folgt, ist eine etwas sperrige Definition (Spoiler: Davon gibt es in der Statistik leider sehr viele!):\n\n\n\n\n\n\np-Wert\n\n\n\nDer p-Wert gibt an, wie wahrscheinlich es ist, die beobachteten Daten oder noch extremere Daten, zu beobachten, falls die Nullhypothese zutrifft.\n\n\nSchauen wir uns diese Definition mal im Detail an: Der p-Wert gibt eine Wahrscheinlichkeit an (das p steht f√ºr ‚Äúprobability‚Äù) und liegt daher immer zwischen 0 (sehr, sehr unwahrscheinlich) und 1 (extrem wahrscheinlich). Der Definition k√∂nnen wir entnehmen, dass diese Wahrscheinlichkeit aussagt, wie wahrscheinlich die von uns beobachteten Daten sind, falls die Nullhypothese zutrifft. Wenn diese Wahrscheinlichkeit sehr gering ist, √ºblicherweise kleiner als 5% (der berechnete p-Wert also kleiner als 0,05 ist), sagen wir, dass ein Ergebnis statistisch signifikant ist. Wenn Sie also einmal einen statistischen Test berechnen und einen entsprechend kleinen p-Wert sehen, k√∂nnen Sie sich relativ sicher sein, dass die Nullhypothese verworfen werden kann, also nicht zutrifft. Sie wurde dann falsifiziert. Das bedeutet zwar nicht automatisch, dass unsere Alternativhypothese zutrifft, aber mangels besserer Informationen k√∂nnen wir vorerst so tun, als w√§re dies der Fall.\n\n\n5.2.2 Fehlschl√ºsse\nWarum aber diese 5 %? Diese Zahl ergibt sich aus der Logik, die dieser Art von Statistik zugrunde liegt. Die Idee ist, dass wir als Forscherinnen und Forscher versuchen, langfristig nur in 5% der F√§lle f√§lschlicherweise davon ausgehen wollen, dass es einen Effekt (also einen Unterschied oder einen Zusammenhang) gibt, obwohl dem nicht der Fall ist. Diese Art von Fehlschluss nennen wir auch Alpha-Fehler oder Fehler 1. Art. Die 5 % sind dabei reine Konvention!\nDiese Fehler kommen zustande, weil p-Werte gleichverteilt sind, wenn die H0 zutrifft. Wenn es also keinen Unterschied oder Zusammenhang gibt, werden wir trotzdem in 5 % der F√§lle ein statistisch signifikantes Ergebnis bekommen. Stellen wir uns einmal vor, wir w√ºrden eine der Hypothesen oben 10.000 Mal testen und die berechneten p-Werte aufschreiben und anschlie√üend grafisch darstellen. Das Ergebnis k√∂nnte so aussehen:\n\n\n\n\n\n\n\n\n\nWie Sie sehen, sind die p-Werte gleichverteilt. Das hei√üt, Werte zwischen 0 und 0,05 sind genauso h√§ufig wie Werte zwischen 0,95 und 1 oder 0,73 und 0,78. Da wir gesagt haben, dass Werte zwischen 0 und 0,5 als statistisch signifikant gelten, w√ºrden wir also in ca. 5 % der F√§lle einen Fehlschluss ziehen.\n\n\n\n\n\n\n\n\n\nGenauso, wie wir f√§lschlicherweise zu dem Schluss gelangen k√∂nnen, dass es einen Effekt gibt, obwohl dies nicht der Fall ist, k√∂nnen wir einen realen Effekt nicht finden und entsprechend darauf schlie√üen, dass es ihn nicht gibt (bzw. dass H0 zutrifft). Wir sprechen dann von einem Beta-Fehler oder auch Fehler 2. Art. Diese Art von Fehler kann zwar grunds√§tzlich verschiedene Ursachen haben, allerdings h√§ngt die Wahrscheinlichkeit, einen solchen Fehler zu begehen, in erster Linie mit der Stichprobengr√∂√üe zusammen. Es gilt: Je gr√∂√üer die Stichprobe, desto h√∂her ist die Wahrscheinlichkeit, einen Effekt zu finden, sofern dieser tats√§chlich existiert. Man spricht auch von der statistischen Power eines Tests.\nAuch hier gibt es wieder eine Konvention: Studien (bzw. die darin enthaltenen Tests) sollten mindestens 80% Power haben, also einen in der Realit√§t existierenden Effekt in 4 von 5 F√§llen identifizieren k√∂nnen. Online werden Sie f√ºr die Verfahren, die wir in den kommenden Wochen kennenlernen werden, oftmals Faustregeln zur Stichprobnengr√∂√üe finden, um diese Power zu erreichen. Z.B.ca. 30 Personen pro Gruppe, wenn ein t-Test gerechnet werden soll (was das ist, werden wir noch lernen!). Solche Faustregeln sind meistens relativ alt, also aus einer Zeit, in der es sehr schwer und kostspielig war, Forschung mit Menschen zu betreiben. Sie sollten daher besser vermieden werden. Zwar gibt es Verfahren, mit denen bestimmt werden kann, wie gro√ü Ihre Stichprobe sein muss, um auf 80% Power zu kommen, aber diese werden wir uns in dieser Veranstaltung nicht anschauen. Wenn Sie im Rahmen eines Forschungsprojektes im Studium eine Stichprobe rekrutieren sollen, sprechen Sie daher am besten mit Ihrem Betreuer oder Ihrer Betreuerin, um zu kl√§ren, wie gro√ü die Stichprobe sein sollte und was f√ºr Sie in Ihrem Forschungskontext realistisch ist!",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Hypothesen und Testtheorie</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen nominalen und ordinalen Variablen.html",
    "href": "Zusammenh√§nge zwischen nominalen und ordinalen Variablen.html",
    "title": "6¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Kreuztabellen",
    "section": "",
    "text": "6.1 Statistische Grundlagen",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Kreuztabellen</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen nominalen und ordinalen Variablen.html#deskription-und-visulisierung-der-daten",
    "href": "Zusammenh√§nge zwischen nominalen und ordinalen Variablen.html#deskription-und-visulisierung-der-daten",
    "title": "6¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Kreuztabellen",
    "section": "6.2 Deskription und Visulisierung der Daten",
    "text": "6.2 Deskription und Visulisierung der Daten\nBevor wir starten, m√ºssen wir ein paar Vorkrehrungen treffen. Konkret laden wir das tidyverse laden danach das Paket effectsize, das wir sp√§ter bei der statistischen Analyse ben√∂tigen werden. Anschlie√üend lesen wir die Daten ein. Au√üerdem nutzen wir die options()-Funktion. Damit k√∂nnen wir die Einstellungen von R √§ndern. Hier nutzen wir das Argument scipen mit dem Wert 999. Im Prinzip sorgen wir damit nur daf√ºr, dass sehr kleine Zahlen so angezeigt werden, wie Sie es erwarten w√ºrden. Das werden wir sp√§ter bei den satistischen Analysen ben√∂tigen.\n\n# L√§dt das tidyverse\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# L√§dt bzw. installiert und l√§dt das Paket \"effectsize\"\nif(!require(effectsize)){\n  install.packages(\"effectsize\")\n  library(effectsize)\n}\n\nLade n√∂tiges Paket: effectsize\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\n\nSchauen wir uns nun einmal eine Kreuztabelle an. Anschlie√üend visualisieren wir die Daten. Wir nehmen dazu die Spalte Bula, die angibt, aus welchem Bundesland die Befragten stammen und die Spalte A502_01, die angibt, ob die Menschen Mitglied in einem Sportverein sind. Um eine einfache Kreuztabelle zu erstellen, k√∂nnen wir die table()-Funktion nutzen, der wir die beiden Spalten √ºbergeben. Vorher wandeln wir A502_01 in einen Faktor um, sodass wir etwas besser damit arbeiten k√∂nnen.\n\n# Wandelt die Spalte A502_01 in einen Faktor mit den Stufen \"nein\" und \"ja\" um.\ndf_lokal &lt;- df_lokal |&gt;\n    mutate(Sportverein = factor(A502_01, labels = c(\"nein\", \"ja\")))\n\n# Erstellt eine einfache 2x2 Tabelle, die wir \"tabelleSportNachBundesland\" nennen\n# select() w√§hlt die Spalten aus, die dann an table() weitergereicht werden\ntabelleSportNachBundesland &lt;- df_lokal |&gt;\n  select(Bula, Sportverein) |&gt;\n  table() \n\ntabelleSportNachBundesland\n\n     Sportverein\nBula  nein  ja\n  RLP  649 385\n  TH   636 172\n\n\nF√ºr sich genommen sagt uns diese Tabelle noch nicht allzu viel. Wir sehen, dass Befragte aus beiden Bundesl√§ndern √§hnlich oft angegeben haben, nicht Mitglied eines Sportvereins zu sein, allerdings gab in Rheinland-Pfalz ein paar mehr Menschen, die in Vereinen aktiv sind.\nIm n√§chsten Schritt visualisieren wir diese Daten. Wir gehen dabei √§hnlich vor wie bei den Balkendiagrammen mit relativen H√§ufigkeiten in Kapitel 4. Das hei√üt, wir erstellen einen reduzierten Datensatz. Dazu nutzen wir erst filter() und rufen darin !is.na() auf. Dabei m√ºssen wir darauf achten, dass wir die Funktion f√ºr beide Variablen aufrufen und mit einem & verbingen. Anschlie√üend nutzen wir group_by() und dann summarise(). Das Ergebnis ist ein Datensatz mit vier Zeilen, von denen jede eine Zelle aus der Tabelle oben darstellt.\n\n# Erstellt einen reduzierten Datensatz, der die relativen H√§ufigkeiten der Auspr√§gungen enth√§lt\ndf_plot_kreuztabelle &lt;- df_lokal |&gt;\n  filter(!is.na(Sportverein) & !is.na(Bula)) |&gt;\n  group_by(Bula, Sportverein) |&gt;\n  summarise(Anzahl = n())\n\n`summarise()` has grouped output by 'Bula'. You can override using the\n`.groups` argument.\n\ndf_plot_kreuztabelle\n\n# A tibble: 4 √ó 3\n# Groups:   Bula [2]\n  Bula  Sportverein Anzahl\n  &lt;chr&gt; &lt;fct&gt;        &lt;int&gt;\n1 RLP   nein           649\n2 RLP   ja             385\n3 TH    nein           636\n4 TH    ja             172\n\n\nDiesen Datensatz k√∂nnen wir jetzt f√ºr die Visualisierung nutzen. Auch hier gehen wir im Prinzip wie in Kapitel 4 vor. Allerdings mit einem wichtigen Unterschied: Um die vier Zellen aus der Tabelle abbilden zu k√∂nnen, reichen einfache, nebeneinander stehende Balken nicht mehr aus. Zwar k√∂nnten wir theoretisch vier Balken zeichnen, allerdings w√§re das nicht sonderlich √ºbersichtlich. Stattdessen bietet sich ein sogenanntes Stapeldiagramm an.\nDie gute Nachricht ist, dass ein Stapediagramm sehr √§hnlich erstellt wird, wie die Balkendiagramme, die Sie bereits kennen. Beim Aufruf von ggplot() und darin deraes()-Funktion √ºbergeben wir eine Spalte (hier Bundesland) f√ºr die x-Achse und eine andere (Anzahl) f√ºr die y-Achse. Zus√§tzlich nutzen wir das fill-Argument und geben dort die Spalte Sportverein an. Damit sagen wir ggplot, dass diese Spalte genutzt werden soll, um die Balken einzuf√§rben. Das hei√üt, die Auspr√§gungen ‚Äúja‚Äù und ‚Äúnein‚Äù erhalten andere Farben. Diese k√∂nnen wir in scale_fill_manual festlegen. In diesem Beispiel geben wir au√üerdem in geom_bar position = \"fill\" an. Dadurch werden die Werte in relative H√§ufigkeiten umgewandelt und beide Balken sind gleich hoch.\n\nplot_kreuztabelle &lt;- df_plot_kreuztabelle |&gt;\n  ggplot(aes(x = Bula, y = Anzahl, fill = Sportverein))+\n    geom_bar(position = \"fill\", stat = \"identity\")+\n    theme_minimal()+\n    scale_fill_manual(values = c(\"#F5C000\", \"#0035F5\"))+\n    labs(x = \"Bundesland\", y = \"relative H√§ufigkeit\", fill = \"Mitglied\\nim Sportverein\")\n\nplot_kreuztabelle\n\n\n\n\n\n\n\n\nDie Visualisierung der Daten macht deutlich, dass in Th√ºringen prozentual weniger Befragte Mitglied in einem Sportverein sind als in Rheinland-Pfalz. Das legt nahe, dass die beiden Variablen zusammenh√§ngen. Als n√§chstes pr√ºfen wir mit einem Signifikanztest, ob dies tats√§chlich der Fall ist.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Kreuztabellen</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen nominalen und ordinalen Variablen.html#signifikanztests-f√ºr-kreuztabellen-in-r-berechnen",
    "href": "Zusammenh√§nge zwischen nominalen und ordinalen Variablen.html#signifikanztests-f√ºr-kreuztabellen-in-r-berechnen",
    "title": "6¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Kreuztabellen",
    "section": "6.3 Signifikanztests f√ºr Kreuztabellen in R berechnen",
    "text": "6.3 Signifikanztests f√ºr Kreuztabellen in R berechnen\nUm zu testen, ob die beiden Variablen zusammenh√§ngen oder unabh√§ngig voneinander sind, nutzen wir, wie oben im Video erl√§utert, den Chi¬≤-Test, den wir mit der chisq.test()-Funktion ausf√ºhren k√∂nnen. Dieser Funktion k√∂nnen wir unsere Tabelle von oben (tabelleSportNachBundesland) √ºbergeben. Die Funktion gibt eine Liste zur√ºck, die wir in einem Objekt speichern sollten. Indem wir das Objekt danach aufrufen, wird uns das Ergebnis angezeigt.\n\n# Berechnet einen Chi¬≤-Test und speichert das Ergebnis in einer Liste namens \"kt_test\"\nkt_test &lt;- chisq.test(tabelleSportNachBundesland)\n\nkt_test\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tabelleSportNachBundesland\nX-squared = 53.925, df = 1, p-value = 0.0000000000002083\n\n\nDas Ergebnis enth√§lt drei Informationen:\n\nDen Chi¬≤-Wert (hier 53,925). Hierbei handelt es sich um die songeannte Teststatistik des Chi¬≤-Tests. Wie im Video erkl√§rt, wird er aus der Abweichung zwischen beobachteten und erwarteten Werten berechnet.\nDie Anzahl der sogenannten Freiheitsgrade (df f√ºr degrees of freedom; hier 1). Freihtsgrade sind wieder eines der Konzepte in der Statistik, die leider nicht wirklich intuitiv sind. Unten finden Sie eine Definition.\nDer p-Wert (hier 0,0000000000002083). Wie im lezten Kapitel beschrieben, sprechen wir ab p-Werten von 0,05 von statistischer Signifikanz. √úblicherweise wird nur angegeben, ob ein p-Wert gr√∂√üer als 0,05, also nicht-signifikant, kleiner als 0,05, kleiner als 0,01 oder kleiner als 0,001ist. Hier w√ºrden wir also lediglich, dass p &lt; 0,001 und entsrepchend festhalten, dass der Zusammenhang zwischen dem Bundesland, aus dem die Befragten stammen, und ihrer Mitgliedschaft in einem Sportverein signifikant ist. √úbrigens: Dadurch, h√§tten wir oben nicht options(scipen = 999) angegeben, w√ºrde der p-Wert hier als 2.083e-13 ausgegeben werden. Das steht f√ºr die Zahl 2,083, vor die 13 Nullen geschrieben werden.\n\nMit diesen drei Werten k√∂nnen wir den Test wie folgt verschriftlichen:\n\nEin Chi¬≤-Test zeigt, dass ein signifikanter Zusammenahang zwischen dem Bundesland, aus dem die Befragten stammen, und ihrer Mitgliedschaft in einem Sportverein besteht (Chi¬≤(1) = 53,925; p &lt; 0,001).\n\n\n\n\n\n\n\nFreiheitsgrade\n\n\n\nStark simplifiziert sagen sie etwas dar√ºber aus, wie viele Informationen in die Sch√§tzung eines Parameters (hier Chi¬≤) eingeflossen sind. Etwas genauer: Sie geben an, wie viele Werte wir frei variieren k√∂nnen, um auf das tats√§chliche Ergebnis zu kommen. Stellen Sie sich z.B. vor, Sie haben 3 Zahlen und wissen nur, dass deren Mittelwert 5 ist. Daraus k√∂nnen Sie schlie√üen, dass die Summe 15 sein muss (denn: 3 x 5 = 15). Nun gibt es aber unendlich viele M√∂glichkeiten, drei Zahlen auszusuchen, deren Summe genau 15 ist. Die erste Zahl k√∂nnte z.B. eine 3 sein und die zweite eine 11. Nun muss die letzte Zahl eine 1 sein, um auf die Summe 15 bzw. den Mittelwert 5 zu kommen. Da wir uns die ersten beiden Zahlen v√∂llig frei aussuchen durften, die dritte dann aber fest vorgegeben war, hat dieser Mittelwert 2 Freiheitsgrade. Die Freiheitsgrade des Chi¬≤-Tests ergeben sich immer aus der Anzahl der Auspr√§gungen der beiden Variablen: Von beiden wird 1 subtrahiert, dann werden diese Werte miteinander multipliziert. Hier also (2-1) * (2-1) = 1\n\n\nAls n√§chsten ben√∂tigen wir noch die Effektst√§rke Cramers V. Das effectsize-Paket, das wir oben installiert haben, enth√§lt eine Funktion dazu (cramers_v), der wir unsere Tabelle √ºbergeben m√ºssen. Zus√§tzlich geben wir als weiteres Argument alternative = \"two.sided\" an. Damit sagen wir der Funktion, dass wir bevor wir mit unseren Berechnungen angefangen haben keine gerichtete Hypothese hatten.\n\n# Berechnet die Effektst√§rke \"Cramers V\"\ncramersVSportBundesand &lt;- cramers_v(tabelleSportNachBundesland, alternative = \"two.sided\")\n\ncramersVSportBundesand\n\nCramer's V (adj.) |       95% CI\n--------------------------------\n0.17              | [0.12, 0.22]\n\n\nDas Ergebnis der Funktion besteht aus zwei Teilen: Erstens dem Wert von Cramers V (hier 0,17). Gem√§√ü den Angaben im Video k√∂nnen wir also von einem schwachen Zusammenhang sprechen. Zweitens gibt uns die Funktion einen Bereich von 0,12 bis 0,22 aus, den sogenannte 95% Konfidenzintervall (CI Englisch f√ºr confidence interval). Hier haben wir es, mal wieder, mit einem dieser unintuitiven Konzepte der Statistik zu tun.\n\n\n\n\n\n\nKonfidenzintervalle\n\n\n\nKonfidenzintervalle sind ein Ma√ü, das Auskunft dar√ºber gibt, wie viel Unischerheit mit einer Sch√§tzung (hier z.B. die Sch√§tzung von Cramers V) verbunden ist. Sie basieren auf einer Kernidee der Statistik, n√§mlich dass jede Sch√§tzung auf einer Stichprobe basiert und wir langfristig nur Sicherheit gewinnen k√∂nnen, indem wir immer wieder verschiedene Stichproben ziehen und bestimmte Parameter (z.B. einen Mittelwert oder eben eine Effektst√§rke wie Cramers V) sch√§tzen. Die Definition lautet daher, dass langfristig 95% aller berechneten Konfidenzintervalle den gesch√§tzten Parameter enthalten.\n\n\nMit dem Ergebnis der cramers_v()-Funktion k√∂nnen wir die Verschriftlichung unseres Ergebnisses von oben erweitern:\n\nEin Chi¬≤-Test zeigt, dass ein schwacher signifikanter Zusammenahang zwischen dem Bundesland, aus dem die Befragten stammen, und ihrer Mitgliedschaft in einem Sportverein besteht (Chi¬≤(1) = 53,925; p &lt; 0,001; Cramers V = 0,17; 95%KI = [0,12; 0,22]).\n\nF√ºr die Darstellung des Chi¬≤-Tests in einem Forschungsbericht reicht dieser Satz im Prinzip aus. Allerdings ist es f√ºr Leserinnen und Leser wissenschaftlicher Texte immer leichter, eine Berechnung nachzuvollziehen, wenn Sie deskriptive Angaben machen. Im Fall von Kreuztabellen bietet sich daf√ºr, wer h√§tte es gedacht, eine Tabelle an.\nDie beobachteten Werte k√∂nnen wir der Tabelle entnehmen, die wir ganz am Anfang erstellt haben (tabelleSportNachBundesland). Wie im Video besprochen sind diese Werte nur bedingt aussagekr√§ftig, sodass wir auch relative H√§ufigkeiten angeben sollten. Diese k√∂nnen wir relativ einfach in dem Objekt berechnen, dass wir oben f√ºr das Stapeldiagramm angelegt haben (df_plot_kreuztabelle). Als ersten nutzen wir group_by(), um die Daten anch Bundesland zu gruppieren. Anschlie√üend k√∂nnen wir die absoluten H√§ufigkeiten pro Zelle (gespeichert in Anzahl) durch die Gesamtsumme aller Befragten aus einem Bundesland teilen (sum(Anzahl)). Die erwarteten Werte sind dagegen wieder einfacher, denn sie sind Teil der Liste, die uns die chisq.test()-Funktion zur√ºckgegeben hat. Wir k√∂nnen Sie aufrufen, indem wir das entsprechende Listenelement ansprechen: kt_test$expected.\n\n# Beobachtete Werte\ntabelleSportNachBundesland\n\n     Sportverein\nBula  nein  ja\n  RLP  649 385\n  TH   636 172\n\n# Berechnet beobachtete Werte in %\ndf_plot_kreuztabelle &lt;- df_plot_kreuztabelle |&gt;\n  group_by(Bula) |&gt;\n  mutate(Prozent = round((Anzahl / sum(Anzahl))*100,2))\n\ndf_plot_kreuztabelle$Prozent\n\n[1] 62.77 37.23 78.71 21.29\n\n# Erwartete Werte\nkt_test$expected\n\n     Sportverein\nBula      nein       ja\n  RLP 721.3301 312.6699\n  TH  563.6699 244.3301\n\n\nDiese Werte k√∂nnen wir dann in eine Tabelle √ºbertragen:\n\n\n\n\n\n\n\n\n\nBundesland\nkein Mitglied im Sportverein\nMitglied im Sportverein\nGesamt\n\n\n\n\nRheinland-Pfalz\n\n\n\n\n\nBeobachtet\n649\n385\n1034\n\n\nBeobachtet in %\n62,77 %\n37,23 %\n\n\n\nErwartet\n721,33\n312,67\n\n\n\nTh√ºringen\n\n\n\n\n\nBeobachtet\n636\n172\n808\n\n\nBeobachtet in %\n78,71 %\n21,29 %\n\n\n\nErwartet\n563,67\n244,33",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Kreuztabellen</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html",
    "href": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html",
    "title": "7¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "",
    "text": "7.1 Statistische Grundlagen",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#deskription-und-visulisierung-der-daten",
    "href": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#deskription-und-visulisierung-der-daten",
    "title": "7¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "7.2 Deskription und Visulisierung der Daten",
    "text": "7.2 Deskription und Visulisierung der Daten\nWir starten wie im letzten Kapitel damit, unsere R-Umgebung vorzubereiten, indem wir das tidyverse laden, den Datensatz einlesen und die Optionen so √§ndern, dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n\n# L√§dt das tidyverse\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\n\nEine gute M√∂glichkeit, den Zusammenhang zwischen zwei metrischen Variablen grafisch darzustellen, ist durch ein sogenanntes Streudiagramm bzw. eine Punktewolke. Dabei wird eine Variable auf der x- und die andere auf der y-Achse dargestellt. Schauen wir uns das einmal am Besipel der Spalten A202_01 und A202_02 an, in denen das Interesse an Nachrichten √ºber lokale bzw. nationale Geschehnisse abgefragt wurde.1 Zun√§chst benennen wir beiden Spalten um. Anschlie√üend rufen wir ggplot() auf, geben dort innerhalb von aes() an, welche Variable wir auf der x- bzw. y-Achse darstellen wollen. Dann m√ºssen wir nur noch geom_point() erg√§nzen. Mit theme_minimal() und labs() versch√∂nern wir unseren Plot gleich noch ein wenig.\n\n# Benennt die Spalten A202_01 und A202_02 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(interesseLokal = A202_01,\n         interesseDE = A202_02)\n\n# Erstellt ein Streudiagramm der beiden Spalten\nstreudiagrammInt &lt;- df_lokal |&gt;\n  ggplot(aes(x = interesseLokal, y = interesseDE))+\n  geom_point()+\n  theme_minimal()+\n  labs(x = \"Interesse an lokalen Geschehnissen\", y = \"Interesse an nationalen Geschehnissen\")\n\nstreudiagrammInt\n\n\n\n\n\n\n\n\nDas sieht gar nicht schlecht aus. Wir sehen allerdings, dass relativ viele Befragte die Skala vollst√§ndig ausgreizt haben und den jeweiligen Maximalwert (101) angegeben haben. Daran k√∂nnen wir auch ein Verhalten von geom_point() erhnen, das tendenziell problematisch ist. Und zwar werden identische Datenpunkte einfach √ºbereinander gelegt. Wenn also zwei Personen die exakt gleichen Antworten gegeben haben, zeigt geom_point() nur einen Punkt an.\nSchauen wir uns das mal am Beispiel der Spalten A208_01 und A208_03 an. In beiden Spalten wurden Aspekte der politischen Selbstwirksamkeit abgefragt, jeweils bezogen auf den eigenen Wohnort. Die konkreten Formulierungen lauteten:\n\nA208_01: Wichtige Fragen der Lokalpolitik kann ich gut verstehen und einsch√§tzen.\nA208_03: Ich traue mir zu, mich an einem Gespr√§ch √ºber Fragen der Lokalpolitik aktiv zu beteiligen.\n\nSchauen wir uns einmal ein Streudiagramm dieser beiden Variablen an. Da die Items Teil einer gr√∂√üeren Abfrage waren und √ºblicherweise nicht einzeln ausgwertet werden w√ºrden, sind die Beschriftungen hier sehr pragmatisch gew√§hlt.\n\n# Benennt die Spalten A208_01 und A208_03 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(polSelbstw1 = A208_01,\n         polSelbstw3 = A208_03)\n\n# Erstellt ein Streudiagramm der beiden Spalten\n\nstreudiagrammSelbstw &lt;- df_lokal |&gt;\n  ggplot(aes(x = polSelbstw1, y = polSelbstw3))+\n  geom_point()+\n  theme_minimal()+\n  labs(x = \"lokale politische Selbstwirksamkeit Item 1\", y = \"lokale politische Selbstwirksamkeit Item 3\")\n\nstreudiagrammSelbstw\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nHier wird das Problem an geom_point() deutlich. Die Grafik verr√§t uns herzlich wenig. Wir haben nach wie vor keinerlei Vorstellung davon, wie stark der Zusammenhang sein k√∂nnte. Wir erfahren lediglich, dass jede m√∂gliche Wertekombination im Datensatz enthalten ist. Es gibt also z.B. Leute, die auf eins der Items mit 1 (= ‚Äústimme √ºberhaupt nicht zu‚Äù) und auf das andere mit 5 (= ‚Äústimme sehr zu‚Äù) geantwortet haben.\nIn solchen F√§llen ist es sinnvoll, die Alternative geom_jitter() zu nutzen. Jitter ist Englisch f√ºr zittern und genau das tut die Funktion: Sie verschiebt die einzelen Punkte minimal nach oben, unten, rechts und links (l√§sst sie also zittern), sodass wir besser erkennen k√∂nnen, wie die Daten verteilt sind. Um das umzusetzen, m√ºssen wir nur geom_point() durch geom_jitter() ersetzen.\n\n# Erstellt ein Streudiagramm der beiden Spalten mit geom_jitter()\n\nstreudiagrammSelbstw &lt;- df_lokal |&gt;\n  ggplot(aes(x = polSelbstw1, y = polSelbstw3))+\n  geom_jitter()+\n  theme_minimal()+\n  labs(x = \"lokale politische Selbstwirksamkeit Item 1\", y = \"lokale politische Selbstwirksamkeit Item 3\")\n\nstreudiagrammSelbstw\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWir sehen nun relativ eindeutig, dass es einen Zusammenhang zwischen den beiden Variablen zu geben scheint.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#korrelationen-berechnen",
    "href": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#korrelationen-berechnen",
    "title": "7¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "7.3 Korrelationen berechnen",
    "text": "7.3 Korrelationen berechnen\n\n7.3.1 Pearson Korrelationen\nPearson Korrelationen, also normale Korrelationen zwischen zwei metrischen Variablen, k√∂nnen wir mit der cor.test()-Funktion berechnen, der wir mit den Argumenten xund y zwei Variablen √ºbergeben m√ºssen. Die Funktion gibt uns dann eine Liste zur√ºck. Das Element estimate enth√§lt den Korrelationskoeffizienten. Den dazugeh√∂rigen p-Wert k√∂nnen wir √ºber das Element p.value abrufen. Beides speichern wir hier in einem neuen Objekt, indem wir cor.test() innerhalb von summarise() aufrufen. Der √úbersicht halber runden wir die jeweiligen Ergebnisse auf 3 Nachkommastellen.\n\n# Erstellt ein neues Objekt in dem der Korrelationskoeffizient und der zugeh√∂rigen p-Wert f√ºr die Korelation zwischen interesseLokal und interesseDE gespeichert wird.\nkorrelationInt &lt;- df_lokal |&gt;\n  summarise(Korrelation = round(cor.test(x = interesseLokal, \n                                         y = interesseDE)$estimate, 3),\n            pWert = round(cor.test(x = interesseLokal, \n                                   y = interesseDE)$p.value, 3))\n\nkorrelationInt\n\n  Korrelation pWert\n1       0.422     0\n\n\nDie Korrelation betr√§gt demnach 0,422. Wir k√∂nnen also von einer m√§√üigen Korrelation sprechen. Der gerundete p-Wert wird als 0 angegeben. Da p-Werte aber immer zwischen 0 und 1 liegen m√ºssen und nie genau 0 (oder 1) sein k√∂nnen, k√∂nnen wir dem entnehmen, dass die Abweichung von 0 erst nach der dritten Nachkommastelle kommt2. Entsprechend w√ºrden wir den p-Wert als &lt;0,001 angeben. Bevor wir die Ergebnisse verschriftlichen k√∂nnen, sollten wir noch die Mittelwerte und Standardabweichungen der beiden Variablen berechnen, die immer zus√§tzlich angegeben werden sollten.\n\n# Berechnet Mittelwert und Standardabweichung der Variablen interesseLokal und interesseDE\n\nMWsInteresse &lt;- df_lokal |&gt;\n  summarise(MWIntLokal = round(mean(interesseLokal, na.rm = TRUE), 2),\n            SDIntLokal = round(sd(interesseLokal, na.rm = TRUE), 2),\n            MWIntDE = round(mean(interesseDE, na.rm = TRUE), 2),\n            SDIntDE = round(sd(interesseDE, na.rm = TRUE), 2))\n\nMWsInteresse\n\n  MWIntLokal SDIntLokal MWIntDE SDIntDE\n1      81.83      20.34   80.73   20.91\n\n\nDamit haben wir alle notwendigen Informationen, um die Ergebnisse zu verschriftlichen:\n\nDurch eine Korrelation wurde gepr√ºft, ob ein Zusammenhang zwischen dem Interesse an lokalen Geschehnissen (M = 81,83; SD = 20,34) und dem Interesse an nationalen Geschehnissen (M = 80,73; SD = 20,91) besteht. Das Ergebnis zeigt, dass ein m√§√üig starker, signifikanter Zusammenhang besteht (r = 0,422; p &lt; 0,001).\n\n\n\n7.3.2 Rangkorrelationen\nBei der Korrelation, die wir gerade berechnet haben, handelt es sich um eine normale Korrelation zwischen zwei metrischen Variablen. Wie im Video besprochen, k√∂nnen wir auch sogeannte Rangkorrelationen berechnen, wenn mindestens eine der beiden Variablen ordinal skaliert ist. Dazu m√ºssen wir der cor.test()-Funktion lediglich das zus√§tzliche Argument method mit dem Wert \"spearman\" √ºbergeben.\n\n# Benennt die Spalten A604 und A605 um \n\ndf_lokal &lt;- df_lokal |&gt;\n  rename(Wohndauer = A604,\n         Ortsgroe√üe = A605)\n\n\n# Erstellt ein neues Objekt in dem der Rangkorrelationskoeffizient und der zugeh√∂rigen p-Wert f√ºr die Korelation zwischen Wohndauer und Ortsgroe√üe gespeichert wird.\n\n\nkorrelationOrt &lt;- df_lokal |&gt;\n  summarise(Korrelation = round(cor.test(x = Wohndauer, \n                                         y = Ortsgroe√üe, \n                                         method = \"spearman\")$estimate, 3),\n            pWert = round(cor.test(x = interesseLokal, \n                                   y = interesseDE,\n                                   method = \"spearman\")$p.value, 3))\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\n‚Ñπ In argument: `Korrelation = round(...)`.\nCaused by warning in `cor.test.default()`:\n! Kann exakten p-Wert bei Bindungen nicht berechnen\n‚Ñπ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nkorrelationOrt\n\n  Korrelation pWert\n1      -0.089     0\n\n\nWenn wir den Befehl ausf√ºhren, gibt R eine Warnung aus. Der Kern der Botschaft lautet: Kann exakten p-Wert bei Bindungen nicht berechnen. Damit weist R uns lediglich darauf hin, dass der berechnete p-Wert nur eine Sch√§tzung und keine genaue Berechnung ist. Sie k√∂nnen die Warnung entweder ignorieren, oder dem Aufruf von cor.test() das Argument exact = FALSE hinzuf√ºgen. Beachten Sie, dass das nur n√∂tig ist, wenn Sie eine Spearman-Korrelation berechnen.\nBevor wir die Ergebnisse berichten k√∂nnen, m√ºssen wir wieder deskriptive Werte berechnen. Anders als im Beispiel oben, entscheiden wir uns diesmal f√ºr den Median, da es sich um ordinale Variablen handelt.\n\n# Berechnet den Median, der Variablen Wohndauer und Ortsgroe√üe\n\nmedianDauerGroe√üe &lt;- df_lokal |&gt;\n  summarise(medianDauer = median(Wohndauer, na.rm = TRUE),\n            medianGroe√üe = median(Ortsgroe√üe, na.rm = TRUE))\n\nmedianDauerGroe√üe\n\n  medianDauer medianGroe√üe\n1           6            3\n\n\nNun haben wir alle relevanten Informationen, um das Ergebnis zu verschriftlichen.\n\nDurch eine Rangkorrelation wurde gepr√ºft, ob ein Zusammenhang zwischen der Wohndauer (Median = 6; ‚Äúmehr als 20 Jahre‚Äù) und der Gr√∂√üe des Wohnorts (Median = 3; Kleinstadt) besteht. Die beiden Variablen h√§ngen signifikant, aber sehr schwach, negativ zusammen (r = -0,089; p &lt; 0,001).\n\n\n\n7.3.3 Korrelationskoeffizienten visualisieren\nOben haben wir uns bereits angeschaut, wie wir ein einfaches Streudiagramm von zwei Variablen erstellen k√∂nnen. Wenn wir eine Korrelation berechnen, ist es oft sinnvoll, diese auch grafisch darzustellen. Dazu k√∂nnen wir unser Diagramm von oben durch geom_smooth() mit dem Argument method = \"lm\" erg√§nzen. Diese Funktion zeichnet eine Linie ein. Durch method = \"lm\" geben wir an, dass wir eine Gerade zeichnen wollen, die der Korrelation entspricht. Um diese Linie herum wird ein grauer Bereich eingezeichnet. Hierbei handelt es sich um das Konfidenzintervall, das wir im letzten Kapitel kennengelernt haben.\n\n# Erstellt ein Streudiagramm der beiden Variablen interesseLokal und interesseDE mit eingezeichneter Korrelationsgerade\n\nstreudiagrammInt &lt;- df_lokal |&gt;\n  ggplot(aes(x = interesseLokal, y = interesseDE))+\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  theme_minimal()+\n  labs(x = \"Interesse an lokalen Geschehnissen\", y = \"Interesse an nationalen Geschehnissen\")\n\nstreudiagrammInt\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#korrelationen-erkennen-und-einsch√§tzen",
    "href": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#korrelationen-erkennen-und-einsch√§tzen",
    "title": "7¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "7.4 Korrelationen erkennen und einsch√§tzen",
    "text": "7.4 Korrelationen erkennen und einsch√§tzen\nKorrelationen wie wir sie in diesem Kapitel kennengelernt haben anhand von Daten zu erkennen, ist gar nicht so einfach. Gleichzeitig k√∂nnen sehr kleine p-Werte dazu verleiten, die tats√§chliche Bedeutung eines Zusammenhangs zu √ºbersch√§tzen. Beispielsweise hat eine Auswertung von Meta-Analysen in der Kommunikationswissenschaft ergeben, dass die durchschnittliche Effektst√§rke im Fach gerade einmal r = 0,21 betr√§gt (Rains et al., 2018). Grafisch dargestellt sieht eine solche Korrelation etwa so aus:\n\n\n\n\n\n\n\n\n\nDie beiden fiktiven Variablen h√§ngen zwar zusammen, aber wirklich leicht zu erkennen ist das optisch nicht. Zusammenh√§nge zu erkennen und Gef√ºhlt daf√ºr zu bekommen, wie verschieden starke Korrelationen eigentlich aussehen ist vor allem √úbungssache. Wenn Sie Lust haben, k√∂nnen Sie mit dem kleinen Spiel unten etwas √ºben.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#footnotes",
    "href": "Zusammenh√§nge zwischen ordinalen und metrischen Variablen.html#footnotes",
    "title": "7¬† Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "",
    "text": "Auf die Datentransformation aus der Pr√§senz√ºbung verzichten wir an dieser Stelle.‚Ü©Ô∏é\nIn diesem konkreten Fall folgt die erste Ziffer, die nicht Null ist an Stelle 81. Der p-Wert lautet: 0,000000000000000000000000000000000000000000000000000000000000000000000000000000008204762‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Zusammenh√§nge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Regressionen I.html",
    "href": "Regressionen I.html",
    "title": "8¬† Regressionen I",
    "section": "",
    "text": "8.1 Statistische Grundlagen",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Regressionen I</span>"
    ]
  },
  {
    "objectID": "Regressionen I.html#vorbereitung",
    "href": "Regressionen I.html#vorbereitung",
    "title": "8¬† Regressionen I",
    "section": "8.2 Vorbereitung",
    "text": "8.2 Vorbereitung\nWir starten wider damit, unsere R-Umgebung vorzubereiten, indem wir das tidyverse und das Paket effectsize laden, den Datensatz einlesen und die Optionen so √§ndern, dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n\n# L√§dt das tidyverse\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# L√§dt effectsize\nlibrary(effectsize)\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\n\nAu√üerdem sollten wir die Variablen, mit denen wir Arbeiten umbenennen und ggf. transformieren.\nIm folgenden Beispiel werden wir drei Variablen brauchen, die Sie alle schon kennen: Die Spalten A202_01 und A202_02 enthalten das Interesse an lokalen und nationalen Geschehnissen. Die Spalte A601_01 das Geburtsjahr. Zun√§chst benennen wir die Spalten um.\n\n# Benennt die Spalten A202_01 und A202_02 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(interesseLokal = A202_01,\n         interesseDE = A202_02,\n         geburtsjahr = A601_01)\n\nAls n√§chstes transformieren wir die Spalten interesseLokal und interesseDE so, dass sie nicht mehr Werte von 1 bis 101 enthalten, sondern von 0 bis 1.\n\n# Transformiert die Spalten so, dass sie Werte von 0 bis 1 statt 1 bis 101 enthalten.\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(interesseLokalRec = (interesseLokal-1)/100,\n         interesseDERec = (interesseDE-1)/100)\n\nAbschlie√üend transformieren wir das Geburtsjahr in das Alter um. Der Vorgang ist relativ komplex, Sie kennen ihn aber bereits aus Kapitel 3.\n\n# Transfomiert das Geburtsjahr zum Alter. Siehe Kapitel 3 f√ºr Details\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(alter = str_trim(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4)) |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr)) |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\n\nAnschlie√üend k√∂nnen wir mit der Berechnung der Regression beginnen.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Regressionen I</span>"
    ]
  },
  {
    "objectID": "Regressionen I.html#regressionen-berechnen",
    "href": "Regressionen I.html#regressionen-berechnen",
    "title": "8¬† Regressionen I",
    "section": "8.3 Regressionen berechnen",
    "text": "8.3 Regressionen berechnen\nUm Regressionen zu berechnen nutzen wir die lm()-Funktion. lm steht dabei f√ºr lineares Modell. Der Funktion m√ºssen wir eine Formel √ºbergeben, die immer nach demselben Schema aufgebut ist: links steht die abh√§ngige Varibale, darauf folgt eine Tilde (~). Rechts von dieser stehen dann alle unabh√§ngigen Varibalen. Die Tilde k√∂nnen Sie mit der Tastenkombinstion  +  schreiben. Das Ergebnis dieser Funktion sollten Sie immer in ein Objekt schreiben.\nWichtig ist, dass Sie der lm()-Funktion immer den Datensatz durch das data-Argument √ºbergeben.\n\n8.3.1 Einfache lineare Regression\nSchauen wir uns zun√§chst an, wie wir eine einfache Regression mit einer unabh√§ngigen Variable berechnen k√∂nnen.\nKonkret versuchen wir, das Interesse an lokalen Geschehnissen mit dem Alter der Befragten zu erkl√§ren. Bevor wir die Regression berechnen, schauen wir uns die Korrelation der beiden Variablen an. Das ist nicht immer zwingend notwendig, aber h√§ufig sinnvoll.\n\n# Berechnet die Korrelation vom Interesse an lokalen Geschehnissen und dem Alter der Befragten\nkorrIntAlter &lt;- df_lokal |&gt;\n  summarise(Korrelation = round(cor.test(x = interesseLokalRec, \n                                         y = alter)$estimate, 3),\n            pWert = round(cor.test(x = interesseLokalRec, \n                                   y = alter)$p.value, 3))\n\nkorrIntAlter\n\n  Korrelation pWert\n1       0.204     0\n\n\nDie Korrelation ist schwach (r = 0,204) und signifikant (p &lt; 0,001).\nAls n√§chstes berechnen wir die Regression. Als Formel √ºbergeben wir der Funktion interesseLokalRec ~ alter.\n\n# Berechnet eine Regression mit dem Interesse an lokalen Geschehnissen als AV und dem Alter als UV\nlmInteresseLokal &lt;- lm(interesseLokalRec ~ alter, data = df_lokal)\n\nMit der summary()-Funktion k√∂nnen wir nun das Ergebnis betrachten:\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteresseLokal)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter, data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.87735 -0.08972  0.04675  0.14720  0.28495 \n\nCoefficients:\n             Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept) 0.6744726  0.0158084  42.666 &lt;0.0000000000000002 ***\nalter       0.0027050  0.0003042   8.892 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1988 on 1821 degrees of freedom\n  (23 Beobachtungen als fehlend gel√∂scht)\nMultiple R-squared:  0.04161,   Adjusted R-squared:  0.04108 \nF-statistic: 79.06 on 1 and 1821 DF,  p-value: &lt; 0.00000000000000022\n\n\nGehen wir das Ergebnis einmal der Reihe nach durch. Ganz oben in der Ausgabe sehen sie die √úberschrift Call:. Darunter sagt R uns, was wir genau berechnet haben.\nAls n√§chstes sehen wir die Residuals, also die Sch√§tzfehler. Konkret sagt uns R etwas √ºber die Verteilung. F√ºr heute ignorieren wir diesen Teil.\nDanach wird es unter der √úberschrift Coefficients spannend. Hier erfahren wir etwas √ºber die Koeffizienten. Der erste, die sogenannte Regressionskonstante oder Intercept gibt an, welchen Wert die abh√§ngige Variable dem Modell nach hat, wenn die unabh√§ngige Variable den Wert 0 hat. Beachten Sie, dass das in unserem konkreten Fall wenig Sinn ergibt. Weder haben wir Personen im Alter von 0 Jahren befragt, noch ist es vorstellbar, dass das irgendwie m√∂glich ist. Relevanter ist dagegen der Koeffizient f√ºr das Alter der Befragten. In der Spalte Estimate sehen Sie den Regressionskoeffizienten B. Auf den ersten Blick sieht dieser Wert sehr klein aus (B = 0,002), aber bedenken Sie, dass die abh√§ngige Variable (Interesse an lokalen Geschehnissen) nur von 0 bis 1 geht. In der zweiten Spalte steht der dazugeh√∂rige Standardfehler (hier: 0.0003). Darauf folgt der t-Wert. Hierbei handet es sich um eine Teststatistik, die f√ºr den Signifikanztest berechnet wird. Das Prinzip kennen Sie schon vom Chi¬≤-Test, nur dass hier eine andere Statistik berechnet wird. Der t-Wert wird uns hier als 8,892 angegeben. Als letztes sehen Sie den p-Wert. Hier sehen wir direkt, dass der Wert kleiner als 0,001 und somit signifikant ist.\nDie n√§chsten paar Zeilen k√∂nnen wir √ºberspringen. Relevant wird es erst wieder bei der Angabe von R¬≤. Hier sehen wir zwei Werte: Multiple R-squared und Adjusted R-squared. Der erste Wert wurde im Video nur als R¬≤ bezeichnet. Und wir dort besprochen entspricht er genau der Korrelation unserer beiden Varibalen zum Quadrat:\n\n# Mutipliziert den oben berechneten Korrelationskoeefizienten mit sich selbst:\nkorrIntAlter$Korrelation * korrIntAlter$Korrelation\n\n[1] 0.041616\n\n\nDie unabh√§ngige Variable erkl√§rt also ungef√§hr 4 Prozent der Varianz der abh√§ngigen Variable. Bei Adjusted R-suqred handelt es sich um den korrigierten R¬≤ Wert, den Sie nur angeben m√ºssen, wenn Sie mehr als einen Pr√§diktor (also mehr als eine unabh√§ngige Variable) nutzen.\nIn der letzten Zeile finden Sie einen Test des Gesamtmodells. Zun√§chst steht dort die F-Statistic. √Ñhnlich wie Chi¬≤ und oben t, handelt es sich hierbei um eine weitere Teststatistik, diesmal eben f√ºr das Gesamtmodell. Der zugeh√∂rige Wert ist hier 79,06. Dahinter stehen die zugeh√∂rigen Freiheitsgerade (DF f√ºr degrees of freedom; 1 und 1821), die etwas √ºber die Anzahl der Pr√§diktoren und die Stichprobengr√∂√üe sagen. Schlie√ülich sehen Sie einen Weiteren p-Wert (&lt; 0,001), der uns verr√§t, dass das Gesamtmodell signifikant ist.\nDamit haben wir schon fast alle relevanten Infos, um das Ergebnis zu verschriftlichen. Was fehlt, ist nur der standardisierte Koeffizient beta f√ºr das Alter. Diesen k√∂nnen wir mit der standardize_parameters()-Funktion aus dem effectsize-Paket anzeigen lassen. Dieser Funktion √ºbergeben wir das Objekt, in das wir oben das Ergebnis der Regression gespeichert habe:\n\n# Zeigt den standardisierten Koeffizienten beta f√ºr das Alter an. \nstandardize_parameters(lmInteresseLokal)\n\n# Standardization method: refit\n\nParameter   | Std. Coef. |        95% CI\n----------------------------------------\n(Intercept) |  -1.98e-16 | [-0.04, 0.04]\nalter       |       0.20 | [ 0.16, 0.25]\n\n\nIn der Spalte Std. Coef. (f√ºr standardized Coefficient) zeigt R uns den standardisierten Koeffizienten beta an, der hier 0,20 betr√§gt. Wie im Video angesprochen handelt es sich dabei genau um die Korrelation zwischen den beiden Variablen. Aber beachten Sie, dass das nur bei einfachen Regressionen der Fall ist. Zus√§tzlich gibt uns die Funktion ein Konfidenzintervall aus\nTragen wir die Ergebnisse also einmal zusammen: Das Alter hat einen signifikanten, aber schwachen positiven Effekt auf das Interesse an lokalen Geschehnissen. √Ñltere Menschen tendieren also eher dazu, sich daf√ºr zu interessieren. Au√üerdem ist das Gesamtmodell signifikant, erkl√§rt aber nur etwa 4 Prozent der Varianz. Etwas formaler k√∂nnen wir die Ergebniss so verschriftlichen:\n\nDurch eine Regression wurde gepr√ºft, ob das Alter der Befragten (M = 49,66; SD = 15,31) einen Einfluss auf ihr Interesse an lokalen Geschhnissen hat (M = 0,81; SD = 0,20). Das Modell war insgesamt signifikant (F(1, 1821) = 79,06; p &lt; 0,001), konnte aber nur etwa 4 Prozent der Varianz erkl√§ren (R¬≤ = 0,042). Der Effekt des Alters war signifikant, aber schwach (beta = 0,20; p &lt; 0,001).\n\n\n\n8.3.2 Multiplie Regression\nDas Vorgehen bei multiplen Regressionen ist quasi identisch. Um weitere Pr√§diktoren hinzuzuf√ºgen, k√∂nnen wir unsere Formel ganz einfach erweitern. Schauen wir es uns hier einmal an, indem wir der Regression von oben das Interesse an Geschehnissen in Deutschland als Pr√§diktor hinzuf√ºgen:\n\n# Erweitert die Regression von oben um das Interesse an Geschehnissen in Deutschland\nlmInteresseLokalErweitert &lt;- lm(interesseLokalRec ~ alter + interesseDERec, data = df_lokal)\n\nSchauen wir uns das Ergebnis an:\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteresseLokalErweitert)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter + interesseDERec, data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.89259 -0.08302  0.04036  0.10736  0.51708 \n\nCoefficients:\n                Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)    0.4243107  0.0198217  21.406 &lt; 0.0000000000000002 ***\nalter          0.0015028  0.0002866   5.244          0.000000176 ***\ninteresseDERec 0.3886329  0.0209870  18.518 &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1824 on 1820 degrees of freedom\n  (23 Beobachtungen als fehlend gel√∂scht)\nMultiple R-squared:  0.1936,    Adjusted R-squared:  0.1927 \nF-statistic: 218.4 on 2 and 1820 DF,  p-value: &lt; 0.00000000000000022\n\n\nVerglichen mit dem Ergebnis von oben sollten Ihnen hier einige Dinge auffallen:\n\nDas (korrigierte) R¬≤ ist deutlich h√∂her! Das ist auch nachvollziehbar, schlie√ülich haben wir schon im letzten Kapitel gesehen, dass das Interesse an Geschehnissen in Deutschland und das Interesse an lokalen Geschehnissen m√§√üig stark korrelieren.\nEntsprechend hat sich auch der Test des Gesamtmodells leicht ge√§ndert (anderer F-Wert, andere Freiheitsgrade).\nDer Effekt des Alters ist etwas schw√§cher als im ersten Modell.\nDer Effekt des Interesses an Geschehnissen in Deutschland deutlich st√§rker als der des Alters. Aber: Beachten Sie, dass wir bisher nur die unstandardisierten Koeffizienten betrachtet haben!\n\nAu√üerdem sollten Sie eine wichtige Sache beachten: Die Interpretation der Koeffizienten √§ndert sich in der multiplen Regression leicht! Im Video haben wir gesagt, dass die Effekte jeweils so interpretiert werden k√∂nnen, dass die Effekte der anderen Variablen ‚Äúrausgerechnet‚Äù werden. Ganz konkret ist es so, dass die Effekte jeweils angeben, wie stark der Einfluss einer Variable ist, wenn alle anderen Variablen den Wert 0 annehmen. Wie oben schon, haben wir hier allerdings das Problem, dass der Wert 0 nicht immer sinnvoll ist, z.B. beim Alter. Dieses Problem haben die standardisierten Koeffizienten nicht.\nSchauen wir die uns also noch an:\n\n# Zeigt den standardisierten Koeffizienten beta f√ºr die beiden Pr√§diktoren an\nstandardize_parameters(lmInteresseLokalErweitert)\n\n# Standardization method: refit\n\nParameter      | Std. Coef. |        95% CI\n-------------------------------------------\n(Intercept)    |  -2.65e-16 | [-0.04, 0.04]\nalter          |       0.11 | [ 0.07, 0.16]\ninteresseDERec |       0.40 | [ 0.36, 0.44]\n\n\nF√ºr die Berechnung der standardisierten Koeffizienten, werden die Varibalen selbst standardisiert. Das bedeutet, dass sie so transformiert werden, dass sie den Mittelwert 0 und die Standardabweichung 1 haben. Das hei√üt, der Effekt einer Varibale entspricht nun nicht mehr dem Effekt, wenn alle anderen Varibalen den Wert 0 haben, sondern wenn diese Variablen ihren Mittelwert annehmen.\nSchauen wir uns nun aber die eigentlichen Effekte an. Wie wir oben schon erahnen konnten, ist der Effekt des Alters etwas schw√§cher. Er wird nun nur noch als 0,11 angegeben. Der Effekt des Interesses an Geschehnissen in Deutschland betr√§gt dagegen 0,40. Er ist also m√§√üig stark. Beachten Sie, dass die beta-Werte nun nicht mehr der einfachen Korrelation zwischen den jeweiligen Variablen entsprechen.\nVerschriftlichen wir die Ergebnisse noch einmal:\n\nDurch eine Regression wurde gepr√ºft, ob das Alter der Befragten (M = 49,66; SD = 15,31) und das Interesse an Geschehnissen in Deutschland (M = 0,80; SD = 0,21) einen Einfluss auf ihr Interesse an lokalen Geschhnissen haben (M = 0,81; SD = 0,20). Das Modell war insgesamt signifikant (F(2, 1820) = 218,4; p &lt; 0,001) und konnte etwa 19,3 Prozent der Varianz erkl√§ren (R¬≤ = 0,193). Der Effekt des Alters war signifikant, aber schwach (beta = 0,11; p &lt; 0,001). Dagegen hatte das Interesse an Geschehnissen in Deutschland einen m√§√üigen Effekt (beta = 0,40; p &lt; 0,001).",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Regressionen I</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html",
    "href": "Regressionen II.html",
    "title": "9¬† Regressionen II",
    "section": "",
    "text": "9.1 Vorbereitung\nWir starten wider damit, unsere R-Umgebung vorzubereiten, indem wir das tidyverse und das Paket effectsize laden, den Datensatz einlesen und die Optionen so √§ndern, dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n# L√§dt das tidyverse\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# L√§dt effectsize\nlibrary(effectsize)\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\nWir verwenden wieder einige Spalten, die Sie mittlerweile kennen. Auf die entsprechenden Transformationen gehen wir daher nicht erneut ein. Die einzige √Ñnderung zu vorherigen Versionen dieser Transformationen ist, dass wir beim Geschlecht auch den Wert ‚Äúdivers‚Äù als fehlend deklarieren. Das liegt ganz einfach daran, dass wir nur sehr wenige F√§lle in dieser Gruppe haben und die Interpretation dadurch f√ºr dieses Beispiel unn√∂tig kompliziert wird.\n# Benennt die Spalten A202_01 und A202_02 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(interesseLokal = A202_01,\n         interesseDE = A202_02,\n         geburtsjahr = A601_01)\n\n\n# Transformiert die Spalten so, dass sie Werte von 0 bis 1 statt 1 bis 101 enthalten.\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(interesseLokalRec = (interesseLokal-1)/100,\n         interesseDERec = (interesseDE-1)/100)\n\n\n# Transfomiert das Geburtsjahr zum Alter. Siehe Kapitel 3 f√ºr Details\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(alter = str_trim(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4)) |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr)) |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\n# Erstellt eine neue Spalte aus der Geschlechtsabfrage. Erst werden die Werte \"keine Angabe\" und \"divers\" als fehlend deklariertm dann wird ein Faktor mit den √ºbrigen  Kategorien erstellt\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlecht = ifelse(A602 == 3 | A602 == 4, NA, A602)) |&gt;\n  mutate(geschlecht = factor(geschlecht, labels = c(\"m√§nnlich\", \"weiblich\")))",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html#multiple-regressionen-mit-nominalem-pr√§diktor",
    "href": "Regressionen II.html#multiple-regressionen-mit-nominalem-pr√§diktor",
    "title": "9¬† Regressionen II",
    "section": "9.2 Multiple Regressionen mit nominalem Pr√§diktor",
    "text": "9.2 Multiple Regressionen mit nominalem Pr√§diktor\nGrunds√§tzlich k√∂nnen wir nominale Pr√§diktoren ganz normal dem Regressionsmodell hinzuf√ºgen, wie wir es auch bei den metrischen Pr√§diktoren gemacht haben. Schauen wir uns das einmal an, indem wir die Regression aus dem letzten Kapitel um das Geschlecht als UV erweitern:\n\n# Berechnet eine Regression mit dem Interesse an lokalen Geschehnissen als AV und dem Alter, dem Interesse an Geschehnissen in Deutschland und dem Geschlecht als UVs\nlmInteresseLokal &lt;- lm(interesseLokalRec ~ alter + interesseDERec + geschlecht, data = df_lokal)\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteresseLokal)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter + interesseDERec + geschlecht, \n    data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.89442 -0.07994  0.03707  0.10846  0.50426 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)        0.4019646  0.0209543  19.183 &lt; 0.0000000000000002 ***\nalter              0.0016333  0.0002896   5.639         0.0000000198 ***\ninteresseDERec     0.3880690  0.0210399  18.444 &lt; 0.0000000000000002 ***\ngeschlechtweiblich 0.0300721  0.0086718   3.468             0.000537 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1811 on 1791 degrees of freedom\n  (51 Beobachtungen als fehlend gel√∂scht)\nMultiple R-squared:  0.199, Adjusted R-squared:  0.1977 \nF-statistic: 148.4 on 3 and 1791 DF,  p-value: &lt; 0.00000000000000022\n\n\nWie Sie sehen, haben wir nun eine neue Zeile in der Tabelle √ºber die Effekte, die mit geschlechtweiblich betitelt ist. Die Zeile gibt an, inwiefern sich die abh√§ngige Variable (also das Interesse an loklaen Geschehnissen) √§ndert, wenn eine befragte Person nicht m√§nnlich, sondern weiblich ist. D.h., der positive Effekt in der Zeile geschlechtweiblich bedeutet, dass Frauen ein h√∂heres Interesse an lokalen Geschehnissen haben als M√§nner.\nAu√üerdem √§ndert sich beim Einschluss von kategorialen Pr√§diktoren die Interpretation der Regressionskontante (Intercept). Im letzten Kapitel haben wir gelernt, dass dieser Wert dem durchschnittlichen Wert der abh√§ngigen Variable entspricht, wenn alle unabh√§ngigen Variablen den Wert 0 annehmen. Das ist grunds√§tzlich auch weiterhin der Fall, allerdings m√ºssen wir nun beachten, dass dieser Wert nur noch dem Durchschnitt der M√§nner in der Stichprobe entspricht. Man sagt auch, dass es sich bei der Auspr√§gung m√§nnlich um die Referenzkategorie der Variable geschlecht handelt. Am einfachsten erkennen Sie das daran, dass oben in der Tabelle f√ºr die Effektst√§rke die andere Auspr√§gung (also ‚Äúweiblich‚Äù) aufgef√ºhrt sind.\nWerfen wir als n√§chstes einen Blick auf die standardisierten Effektst√§rken:\n\n# Zeigt den standardisierten Koeffizienten beta f√ºr die  Pr√§diktoren an\nstandardize_parameters(lmInteresseLokal)\n\n# Standardization method: refit\n\nParameter             | Std. Coef. |         95% CI\n---------------------------------------------------\n(Intercept)           |      -0.08 | [-0.14, -0.02]\nalter                 |       0.12 | [ 0.08,  0.17]\ninteresseDERec        |       0.40 | [ 0.36,  0.44]\ngeschlecht [weiblich] |       0.15 | [ 0.06,  0.23]\n\n\nWir sehen einerseits, dass sich die Effektst√§rken des Alters und des Interesses an Geschehnissen in Deutschland im Vergleich zum Modell aus dem letzten Kapitel leicht ge√§ndert haben. Andererseits sehen wir nun auch eine Zeile f√ºr den Effekt der Variable geschlecht. Im Video im letzten Kapitel hatten wir festgehalten, dass standardisierte Effekte nur f√ºr metrische Pr√§diktoren sinnvoll angegeben werden k√∂nnen, da sie angeben, um wie viele Standardabweichungen sich die abh√§ngige Variable √§ndert, wenn sich die entsprechende unabh√§ngige Variable um eine Standardabweichung erh√∂ht. Was bedeutet dieser Effekt also nun? F√ºr nominale Variablen gibt die Funktion weiterhin aus, wie sich die abh√§ngige Variable ver√§ndert, wenn sich die nominale Variable um eine Einheit erh√∂ht bzw. ver√§ndert (also z.B. weiblich statt m√§nnlich). Der Unterschied zur Tabelle der Koeffiziente aus der summary()-Funktion besteht darin, dass die Ver√§nderung hier jetzt nicht mehr einer Ver√§nderung in den Rohdaten entspricht, sondern in Standardabweichungen ausgedr√ºckt wird. Oder anders gesagt: verglichen mit M√§nnern haben Frauen ein um 0,15 Standardabweichungen h√∂heres Interesse an lokalen Geschehnissen.\nBeachten Sie, dass Sie beim Berichten von diesem Effekten ein bisschen Vorsicht walten lassen m√ºssen. Wenn Sie ansonsten nur nicht-standardisierte Effekte berichten, haben Sie zwar kein Problem mit nominalen Pr√§diktoren, aber m√∂glicherweise sind Ihre Ergebnisse dann etwas schwerer verst√§ndlich. Wenn Sie aber alle Effekte von metrischen Variablen in standardisierter Form ausdr√ºcken, sollten Sie Ihren Leserinnen und Lesern unmissverst√§ndlich klar machen, dass sich die standardisierung bei den Effekten von nominalen Pr√§diktoren nur auf die abh√§ngige Variable bezieht.\n\n\n\n\n\n\nOrdinale Pr√§diktoren\n\n\n\nGrunds√§tzlich k√∂nnen Sie ordinale Pr√§diktoren genauso behandeln wie nominale Pr√§diktoren. Sollte die ordinale Variable aber viele Auspr√§gungen haben (z.B. √ºber 10 verschiedene Einkommensgruppen), wird die Interpretation der Ergebnisse schnell sehr komplex. In solchen F√§llen kann es sinnvoll sein, entweder die Anzahl der Auspr√§gungen zu reduzieren (z.B. zu geringen, mittleren und hohen Einkommen) oder die Variable als quasi-metrisch zu behandeln. Sein Sie hierbei aber sehr vorsichtig bei der Interpretation!",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html#interaktionseffekte",
    "href": "Regressionen II.html#interaktionseffekte",
    "title": "9¬† Regressionen II",
    "section": "9.3 Interaktionseffekte",
    "text": "9.3 Interaktionseffekte\n\n9.3.1 Was sind Interaktionseffekte?\nOben im Kapitel haben wir bereits erfahren, dass Interaktionseffekt im Prinzip nichts anderes bedeutet, als dass der Effekt einer Variable von einer anderen abh√§ngig ist. Stellen Sie sich z.B. vor, dass Sie herausfinden m√∂chten, ob das Schauen eines Films mit Alterfreigabe FSK 16 einen Effekt auf die Stimmung von unter 16-J√§hrigen am n√§chsten Tag hat. Um den elterlichen Einfluss zu kontrollieren, erheben Sie auch, ob die Eltern im Anschluss an den Film mit ihren Kindern √ºber das Gesehene gesprochen haben. Ein klassischer Interaktionseffekt w√ºrde dann vorliegen, wenn Sie zwar einen negativen Effekt des Films auf die Stimmung finden, aber nur in den F√§llen, in denen kein Anschlussgespr√§ch stattgefunden hat, wohingegen Kinder, die mit ihren Eltern √ºber den Film gesprochen haben, entweder eine unver√§nderte oder sogar bessere Stimmung am n√§chsten Tag aufweisen.\nMathematisch funktionieren Interaktionseffekte so, dass das Produkt der beiden Variablen in das Modell aufgenommen wird.\n\n\n9.3.2 Interaktionseffekte berechnen\nUm einen Interaktionseffekt von zwei Variablen zu berechnen, m√ºssen wir nur die Gleichung in unserem Aufruf der lm()-Funktion etwas anpassen. Statt zwei Pr√§diktoren mit einem + zu verbinden, k√∂nnen wir sie mit einem * verbinden. Das Resultat sehen Sie hier:\n\n# Berechnet eine Regression mit dem Interesse an lokalen Geschehnissen als AV und dem Alter, dem Interesse an Geschehnissen in Deutschland und dem Geschlecht als UVs. Dabei wird ein Interaktionseffekt zwischen Alter und Geschlecht angenommen.\nlmInteraktion &lt;- lm(interesseLokalRec ~ alter*geschlecht + interesseDERec, data = df_lokal)\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteraktion)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter * geschlecht + interesseDERec, \n    data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.89015 -0.08269  0.03840  0.10593  0.49950 \n\nCoefficients:\n                           Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)               0.3654555  0.0263466  13.871 &lt; 0.0000000000000002 ***\nalter                     0.0023459  0.0004257   5.510         0.0000000411 ***\ngeschlechtweiblich        0.0948118  0.0296693   3.196              0.00142 ** \ninteresseDERec            0.3874885  0.0210168  18.437 &lt; 0.0000000000000002 ***\nalter:geschlechtweiblich -0.0012933  0.0005669  -2.281              0.02264 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1809 on 1790 degrees of freedom\n  (51 Beobachtungen als fehlend gel√∂scht)\nMultiple R-squared:  0.2014,    Adjusted R-squared:  0.1996 \nF-statistic: 112.8 on 4 and 1790 DF,  p-value: &lt; 0.00000000000000022\n\n\nIn der Tabelle aus der summary()-Funktion sehen wir jetzt, dass die Effekte des Alters und des Geschlechts (weiblich vs.¬†m√§nnlich) weiterhin positiv sind. Diese beiden Effekte werden auch als Haupteffekte der beiden Variablen bezeichnet. Wichtig ist, dass diese Effekte in Anwesenheit einer signifikanten Interpretation mit √§u√üester Vorsicht interpretiert werden sollten! Schlie√ülich wissen Sie dann schon, dass die Effekte von der jeweils anderen Variable abh√§ngig sind.\nDie neue Zeile ganz unten (alter:geschlechtweiblich) zeigt den Interaktionseffekt an, der negativ und signifikant ist. Das bedeutet, Frauen haben zwar insgesamt ein h√∂heres Interesse an lokalen Geschehnissen als M√§nner und √§ltere Menschen haben ein h√∂heres Interesse als j√ºngere Menschen, aber je √§lter die Frauen werden, desto geringer ist ihr Interesse im Vergleich zu √§lteren M√§nnern.\nZugegebenerma√üen ist diese Interpretation nicht ganz offensichtlich. Bei der Einordnung hilft, sich ins Ged√§chtnis zu rufen, dass die Effekte immer aussagen, wie sich die abh√§ngige Variable ver√§ndert, wenn wir die Werte der unabh√§ngigen Variablen einzeln √§ndern. Also konkret: der positive Effekt des Alters sagt aus, dass √§ltere Menschen ein √ºberdurchscnittliches Interesse an lokalen Geschehnissen haben, wenn alle anderen Variablen konstant gehalten werden. Gleiches gilt f√ºr Frauen vs.¬†M√§nner. Der Interaktionseffekt sagt nun aus, wie sich das Interesse ver√§ndert, wenn eine Person weiblich statt m√§nnlich ist und √§lter statt j√ºnger. Wir √§ndern also beide Variablen gleichzeitig und halten nur noch das Interesse an Geschehnissen in Deutschland konstant.\nDer Vollst√§ndigkeit halber lassen wir uns auch noch die standardisierten Effektst√§rken anzeigen:\n\n# Zeigt den standardisierten Koeffizienten beta f√ºr die Pr√§diktoren an\nstandardize_parameters(lmInteraktion)\n\n# Standardization method: refit\n\nParameter                     | Std. Coef. |         95% CI\n-----------------------------------------------------------\n(Intercept)                   |      -0.09 | [-0.15, -0.03]\nalter                         |       0.18 | [ 0.11,  0.24]\ngeschlecht [weiblich]         |       0.15 | [ 0.07,  0.24]\ninteresseDERec                |       0.40 | [ 0.36,  0.44]\nalter √ó geschlecht [weiblich] |      -0.10 | [-0.18, -0.01]\n\n\n\n\n9.3.3 Interaktionseffekte visualisieren\nEine einfache M√∂glichkeit, Interaktionseffekte zu verstehen ist, sie zu visualisieren. Dazu nutzen wir die Funktion interact_plot() aus dem Paket interactions, das wir zun√§chst noch installieren m√ºssen.\nDie Funktion erstellt basierend auf ggplot() eine Grafik, nimmt uns dabei aber viel manuelle Arbeit ab. Der Nachteil ist, dass wir etwas weniger M√∂glichkeiten haben, die Grafik individuell anzupassen.\nGrunds√§tzlich reicht es, der Funktion einige wenige Argumente zu √ºbergeben:\n\nDas Modell, das wir zuvor mit lm() gesch√§tzt haben.\nDen Pr√§diktor, den wir auf der x-Achse darstellen wollen. Das Argument hei√üt pred. Hier nehmen wir das Alter.\nDen Moderator, den wir im Argument modx angeben. Hier also das Geschlecht.\n\nAu√üerdem geben wir einige weitere Argumente an, durch die das Resultat noch etwas besser wird:\n\nDurch interval = TRUE k√∂nnen wir Konfidenzintervalle einzeichnen, wodurch die mit der Sch√§tzung verbundene Unsicherheit visualisiert wird.\nMit x.label und y.label k√∂nnen wir die Achsen manuell beschriften.\nMit legend.main k√∂nnen wir den Titel der Legende anpassen.\n\n\n# Versucht das Paket \"interactions\" zu laden. Falls es nicht installiert ist, wird es erst installiert und dann geladen\nif(!require(interactions)){\n  install.packages(\"interactions\")\n  library(interactions)\n}\n\nLade n√∂tiges Paket: interactions\n\n\nWarning: Paket 'interactions' wurde unter R Version 4.4.2 erstellt\n\n# Erstellt das Objekt \"plotInteraktion\", in dem die Interaktion visualisiert wird\nplotInteraktion &lt;- interact_plot(lmInteraktion, pred = alter, modx = geschlecht, interval = TRUE, x.label = \"Alter\", y.label = \"Interesse an lokalen Geschehnissen\", legend.main = \"Geschlecht\")\n\n# Zeigt die Grafik an\nplotInteraktion\n\n\n\n\n\n\n\n\nDie Grafik zeigt nun relativ eindeutig, dass j√ºngere Frauen ein deutlich h√∂heres Interesse haben als j√ºngere M√§nner. Daf√ºr ist der Effekt f√ºr M√§nner dann st√§ker, sprich, die Gerade ist deutlich steiler. Daraus resltiert dann, dass √§ltere M√§nner ein etwas h√∂heres Interesse an lokalen Geschehnissen haben, wobei sich die beiden Gruppen im hohen Alter nur noch geringf√ºgig unterscheiden.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html#voraussetzungen",
    "href": "Regressionen II.html#voraussetzungen",
    "title": "9¬† Regressionen II",
    "section": "9.4 Voraussetzungen",
    "text": "9.4 Voraussetzungen\nIn diesem Teil wird es zwsichendurch ziemlich komplex, daher vorab das f√ºr Sie Wichtigste: Die meisten Voraussetzungen von Regressionen k√∂nnen wir in den meisten F√§llen ignorieren! Lesen Sie die ersten beiden Aufmerksam durch, auch Nummer 3 ist noch gut zu wissen. Alles danach sollten Sie auch lesen, aber machen Sie sich keine Sorgen, wenn Sie dabei nicht mehr ganz mitkommen. Fragen d√ºrfen Sie nat√ºrlich trotzdem immer!\n\n9.4.1 Welche Voruassetzungen haben Regressionen?\nSchauen wir uns abschlie√üend an, welche Voraussetzungen die Regressionsanalyse hat. Vorweg: Dieser Teil kann etwas abschreckend sein, aber die gute Nachricht ist, dass es in vielen F√§llen reicht, die Voraussetzungen im Hinterkopf zu haben. Und noch ein Disclaimer: Dieser Teil basiert in weiten Teilen auf Kapitel 11.1 auf einem Lehrbuch von Gelman, Hill und Vethari, das online verf√ºgbar ist.\nDie zwei wichtigsten Voraussetzungen haben relativ wenig mit der eigentlichen Statistik zu tun:\n\nDie Daten m√ºssen valide sein. Der Begriff ist Ihnen wahrscheinlich schon aus dem Studium bekannt. Wir verstehen darunter die Frage, ob die Daten (bzw. die Datenerhebung) wirklich das Messen, was sie messen sollen. Im Kontext von Regressionen (und den anderen Verfahren, die wir noch kennenlernen werden!) bedeutet es aber auch, dass unser Modell als Ganzes eine gute Repr√§sentation des zu untersuchenden Sachverhalts sein sollte. Ganz konkret sollten z.B. alle relevanten Pr√§diktoren ber√ºcksichtigt werden. Das ist in der Praxis gar nicht immer so einfach, allein schon deshalb, weil oftmals vor der Datenerhebung gar nicht klar ist, welche Konstrukte relevat sein k√∂nnten. Aber es ist immer gut, diese Frage im Hinterkopf zu haben und ggf. bei der Interpretation der Ergebnisse zu ber√ºcksichtigen.\nImmer, wenn wir eine Regression berechnen, versuchen wir basierend auf Daten einer Stichprobe Schl√ºsse √ºber eine Grundgesamtheit zu ziehen. Damit diese Schl√ºsse zul√§ssig sind, m√ºssen unsere Daten repr√§sentativ sein. Wichtig ist, dass f√ºr die Regression nicht die Stichprobe selbst ein repr√§sentatives Abbild der Grundgesamtheit sein muss, sondern vielmehr die gemessene Verteilung der abh√§ngigen Variable, die in Abh√§ngigkeit der aller unabh√§nggen Variablen der Grundgesamtheit entsprechen muss. Wenn wir beispielsweise die Gr√∂√üe von Befragten durch ihr Geschlecht und ihre Ern√§hrungsgewohnheiten w√§hrend der Kindheit erkl√§ren wollen, w√§re es v√∂llig in Ordnung, wenn Frauen oder vegan ern√§hrte Kinder √ºberrepr√§sentiert w√§ren. Allerdings h√§tten wir ein Problem, wenn √ºberdurchschnittlich viele gro√üe Menschen in unserer Stichprobe enthalten w√§ren. Ein Problem, dass wir in diesem Kontext immer mal wieder haben ist, dass es schwer bis unm√∂glich sein kann, die Grundgesamtheit √ºberhaupt zu bestimmen. Das ist z.B. immer dann der Fall, wenn Sie Ihre Stichprobe √ºber pers√∂nliche Kontakte und/oder soziale Medien rekrutieren. Allen Ergebnissen, die Sie berechnen, liegt dann die Annahme zu Grunde, dass die gemessenen Daten auf die Grundgesamtheit, an der Sie interessiert sind, √ºbertragbar sind.\n\nDaneben gibt es einige Voraussetzungen, die auch im strengeren Sinne statistischer Natur sind.\n\nRegressionsmodell m√ºssen linear sein. Dar√ºber haben wir bereits im Kontext von Korrelationen gesprochen. Sollten Sie z.B. einmal einen solchen Zusammenhang sehen, k√∂nnen Sie relativ leicht erkennen, dass es sich nicht um einen linearen Zusammenhang handelt. In diesem Fall w√ºrden wir eher von einem quadratischen Zusammenhang sprechen. In solchen F√§llen haben Sie zwei M√∂glichkeiten: Entweder Sie transformieren eine der Variablen (√ºblicherweise die unabh√§ngige Variable) oder sie w√§hlene ein anderes Verfahren (das Sie in dieser Veranstaltung allerdings nicht lernen).\n\n\n\n\n\n\n\n\n\n\n\nDie Effekte in Regressionsmodellen m√ºssen additiv sein. Das hei√üt, wir gehen davon aus, dass die abh√§ngige Variable am besten dadurch erkl√§rt werden kann, dass wir die unabh√§ngigen Variablen addieren, also nach dem Schema: y = x + z. Das ist eine durchaus starke Annahme. Genauso gut w√§re es schlie√ülich denkbar, dass die abh√§ngige Variable das Ergebnis des Produkts von zwei Variablen ist, also: y = x*z. In der Realit√§t kann das schwer zu erkennen sein, aber zum Gl√ºck k√∂nnen wir es relativ leicht ber√ºcksichtigen. Schlie√ülich haben wir oben festgestellt, dass eine Interaktion nichts anderes ist, als das Produkt von zwei Pr√§diktoren.\nDie Sch√§tzfehler (oder Residuen) m√ºssen unabh√§ngig voneinander sein. Das bedeutet, dass die Abweichung eines gemessenen Wertes vom in der Regression gesch√§tzen Wert in einem Fall (also z.B. einem ausgef√ºllten Befragungsbogen) keinen Einfluss auf die Abweichung in einem anderen Fall (also einem anderen ausgef√ºllten Fragebogen) haben darf. In den aller meisten F√§llen k√∂nnen Sie davon ausgehen, dass diese Voraussetzung erf√ºllt ist. In anderen F√§llen ist es dagegen sehr offensichtlich, dass dies nicht der Fall ist, z.B. wenn Sie dieselben Personen immer wieder befragen und davon ausgehen m√ºssen, dass die Antworten aus der ersten Befragungswelle und die Antworten aus der zweiten Welle nicht unabh√§ngig voneinander sind. In anderen F√§llen entsteht eine Abh√§ngigkeit durch das Erhebungssetting. Wenn Sie beispielsweise mehrere Schulklassen untersuchen, ist es gut m√∂glich, dass die Daten aus den jeweiligen Klassen nicht unabh√§ngig voneinander sind, etwa weil die zust√§ndige Lehrkraft einen Einfluss aus√ºbt. In solchen F√§llen sollten Sie keine Regression anwenden.\nDie Sch√§tzfehler sollten eine gleichm√§√üige Streuung aufweisen. Das bedeutet, dass die durchschnittliche Abweichung der gemessenen Werte von den im Modell gesch√§tzten Werten unabh√§ngig davon sein sollte, welchen Wert ein Pr√§diktor hat. Im Bild unten sehen Sie, wie das aussehen k√∂nnte: Je kleiner die Werte von x, ddesto n√§her liegen sie, im Durchschnitt, an der Linie. Die h√∂heren Werte sind dagegen deutlich weiter um die Linie herum gestreut. Man spricht in so einem Fall auch von Heteroskedastizit√§t. Die gute Nachricht ist, dass Sie sich nicht wirklich um Heteroskedastizit√§t sorgen m√ºssen, sofern Sie nur daran interessiert sind, gemessene Daten zu erkl√§ren und nicht das Ziel haben, Werte zu prognostizieren bzw. vorherzusagen.\n\n\n\n\n\n\n\n\n\n\n\nDie Sch√§tzfehler sollten normalverteilt sein. In der Ausgabe der summary()-Funktion haben wir im letzten Kapitel kurz √ºber die Zusammenfassung der Residuen gesprochen. Wie Sie dort sehen, werden Minimal- und Maximalwerte sowie Quartile und der Median dort abgebildet. Was dort leider nicht steht, sind Mittewert und Standardabweichung der Sch√§tzfehler, die wir aber h√§ndisch berechnen k√∂nnten (aber zum Gl√ºck nur sehr selten m√ºssen!). Was wir aber grunds√§tzlich aus der Angabe lernen ist, dass diese Sch√§tzfehler irgendwie verteilt sind. Und diese Verteilung sollte normal sein, also durch eine Glockenkurve beschrieben werden k√∂nnen. Diese Voraussetzung wird in manchen Lehrb√ºchern und Online-Ressourcen f√§lschlicherweise angegeben als Normalverteilung der abh√§ngigen Variable. Das ist nicht der Fall! Die Regression stellt keinerlei Anforderungen daran, wie diese Variable verteilt sein muss. Und es wird noch besser: Wie im Fall der Heteroskedastizit√§t ist diese Voraussetzung nicht wirklich relevant, wenn Sie nur erhobene Daten erkl√§ren wollen und keine Vorhresagen basierend auf Ihrem Modell treffen wollen!\nDie unabh√§ngigen Varialen sollten nicht (zu stark) korrelieren. Man spricht hier auch von einer m√∂glichst geringen Kollinearit√§t oder auch Multikollinearit√§t. Liegt diese vor, also korrelieren die Pr√§diktoren stark miteinander, ist die Sch√§tzung der Effektst√§rken mit mehr Unsicherheit verbunden, d.h., die Standardfehler und darauf basierend die Konfidenzintervalle werden gr√∂√üer. Das ergibt auch irgendwie Sinn, wenn man mal dar√ºber nachdenkt: Eine Korrelation bedeutet am Ende nichts anderes, als dass zwei Variablen dieselben Informationen enthalten. Je mehr Sie √ºber die eine wissen, desto mehr wissen Sie bei einer starken Korrelation auch √ºber die andere. Wenn Sie nun hergehen wollen und basierend auf zwei stark korrelierenden Variablen eine abh√§ngige Variable erkl√§ren wollen, gibt es schlicht keine M√∂glichkeit, mit Sicherheit zu sagen, welche der beiden Variablen f√ºr einen etwaigen Effekt verantwortlich ist. Die Sch√§tzung enth√§lt also viel Unsicherheit. Das muss aber nicht unbedingt ein Problem sein, sondern ist ein v√∂llig legitimes Forschungsergebnis! Im Spezialfall von Interaktionseffekten w√ºrden wir sogar mit einer hohen Kollinearit√§t rechnen und brauchen uns darum keine Sorgen zu machen. Nur in sehr seltenen F√§llen kann es vorkommen, dass eine Regression aufgrund sehr starker Multikollinearit√§t nicht gesch√§tzt werden kann. In solchen F√§llen m√ºssten Sie dann eine der Variablen aus dem Modell ausschlie√üen.\n\n\n\n9.4.2 √úberpr√ºfen der Voraussetzungen\nWie oben angedeutet, reicht es in den allermeisten F√§llen, die Voraussetzungen im Hinterkopf zu haben. Falls Sie doch einmal in die Situation geraten, einzelne Voraussetzungen √ºberpr√ºfen zu wollen, k√∂nnen Sie daf√ºr das performance-Paket nutzen.\n\n# Versucht das Paket \"performance\" zu laden. Falls es nicht installiert ist, wird es erst installiert und dann geladen\nif(!require(performance)){\n  install.packages(\"performance\")\n  library(performance)\n}\n\nLade n√∂tiges Paket: performance\n\n\nDieses Paket enth√§lt eine Vielzahl von Funktionen, mit denen Sie Regressionsmodelle √ºberpr√ºfen k√∂nnen. Das Schema ist dabei immer gleich: Sie m√ºssen der entsprechenden Funktion lediglich berechnete Modell √ºbergeben. Oftmals bietet es sich an, dabei visuell vorzugehen und die Funktionen innerhalb von plot() aufzurufen. Hier einige Beispiele. Fangen mit der Heteroskedastizit√§t an:\n\n# √úberpr√ºft, ob Heteroskedastizit√§t vorliegt und stellt das Ergebnis visuell dar\n\nplot(check_heteroscedasticity(lmInteraktion))\n\n\n\n\n\n\n\n\nHier sehen wir die Streuung der Sch√§tzfehler. Freundlicherweise sagt uns die Funktion, wie das Ergebnis aussehen sollte. So erkennen wir gleich, dass wir die Voraussetzung nicht erf√ºllen. Aber da wir keine Vorhersagen treffen wollen, ist das nicht so schlimm.\nWeiter geht es mit der Normalverteilung der Residuen:\n\n# √úberpr√ºft, ob die Residuen normalverteilt sind und stellt das Ergebnis dar\n\nplot(check_normality(lmInteraktion))\n\nFor confidence bands, please install `qqplotr`.\n\n\n\n\n\n\n\n\n\nZum selben Resultat gelangen wir hier. Die Funktion sagt uns, dass die Punkte der Linie folgen sollten, was allerdings nicht der Fall ist. Aber da wir keine Vorhersagen treffen wollen, ist auch das kein Problem.\nWerfen wir abschlie√üend einen Blick auf die (Multi-)Kollinearit√§t:\n\n# √úberpr√ºft, ob Kollinearit√§t vorliegt und stellt das Ergebnis visuell dar\nplot(check_collinearity(lmInteraktion))\n\nModel has interaction terms. VIFs might be inflated.\n  You may check multicollinearity among predictors of a model without\n  interaction terms.\n\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\n\nHier wird der sogannte Variance Inflation Faktor, kurz VIF, abgebildet. Er gibt an, wie stark die Korrelation zwischen den Pr√§diktoren ist. Werte √ºber 10 gelten als problematisch (aber siehe oben!). Das ist hier f√ºr das Alter und die Interaktion aus Alter und Geschlecht der Fall. Nur: Es ist ja vollkommen logisch, dass die beiden Variablen stark korrelieren, denn die Interaktion ist nichs anderes als Alter*Geschlecht (wobei m√§nnlich = 0 und weiblich = 1)! Alles alles in bester Ordnung.\nSie k√∂nnen auch die check_model()-Funktion verwenden, in der die drei Tests oben plus einige weitere durchgef√ºhrt und dargestellt werden. Das Ergebnis wird aber schnell un√ºbersichtlich, daher machen wir es hier nicht.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "t-Test.html",
    "href": "t-Test.html",
    "title": "10¬† t-Test",
    "section": "",
    "text": "10.1 Vorbereitung\nAUch f√ºr den t-Test ben√∂tigen wir das ‚Äòtidyverse‚Äô und das Paket ‚Äòeffectsize‚Äô. Au√üerdem lesen wir den Datensatz ein und √§ndern die Optionen so , dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n# L√§dt das tidyverse\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# L√§dt effectsize\nlibrary(effectsize)\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\nAu√üerdem werden wir in diesem Kapitel mit den Spalten A501_01 bis A501_04 arbeiten. In den entsprechenden Fragen sollten die Befragten angeben, wie stark ihre Bindung zu ihrem Wohnort ist (z.B. ‚ÄúIch f√ºhle mich als Teil meines Wohnorts‚Äù), wobei der Wert 1 f√ºr geringen Zustimmung zu den Aussagen steht und der Wert 5 f√ºr hohe Zustimmung.\nDa diese vier Variablen alle dasselbe Konstrukt abfragen, berechnen wir zun√§chst pro Person einen Mittelwert aus den vier Spalten. Dazu nutzen wir zun√§chst die Funktion rowwise() aus dem dplyr-Paket. Damit sagen wir R, dass die nachfolgenden Zeilen jeweils f√ºr jede einzelne Zeile im Datensatz ausgef√ºhrt werden sollen. Anschlie√üend nutzen wir mutate() und darin mean(), um den Mittelwert zu berechnen. Wichtig ist, dass wir abschlie√üend die ungroup()-Funktion nutzen, da R ansosnten versucht, auch den nachfolgenden Code, der sich auf den Datensatz bezieht, versucht pro Zeile durchzuf√ºhren.\n# berechnet pro Person einen Mittelwert der Spalten A501_01 bis A501_04\ndf_lokal &lt;- df_lokal |&gt;\n  rowwise() |&gt;\n  mutate(lokaleBindung = mean(c(A501_01, A501_02, A501_03, A501_04), na.rm = TRUE)) |&gt;\n  ungroup()",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>t-Test</span>"
    ]
  },
  {
    "objectID": "t-Test.html#t-test-durchf√ºhren",
    "href": "t-Test.html#t-test-durchf√ºhren",
    "title": "10¬† t-Test",
    "section": "10.2 t-Test durchf√ºhren",
    "text": "10.2 t-Test durchf√ºhren\nUm einen t-Test durchzuf√ºhren ben√∂tigen wir die t.test()-Funktion. Damit k√∂nnen wir alle drei Varianten des t-Tests rechnen, die wir im Video kennengelernt haben.\n\n10.2.1 Einstichproben t-Test\nWie im Video besprochen berechnen wir einen t-Test f√ºr eine Stichprobe immer dann, wenn wir wissen m√∂chten, ob sich der von uns gemessene Mittelwert von einem a priori definierten Wert unterscheidet. Wenn wir z.B. w√ºssten, dass die Menschen in Th√ºringen und Rheinland-Pfalz sich im Durchschnitt nicht sehr an ihren Wohnort gebunden f√ºhlen (also z.B. der Wert 2 dem Mittelwert der Grundgesamtheit entspricht), k√∂nnten wir mit dieser Variante des t-Tests pr√ºfe, ob das auch auf unsere Stichprobe zutrifft.\nUm diesen Test durchzuf√ºhren, √ºbergeben wir der t.test()-Funktion zun√§chst die Daten. Hier also die Spalte engagement. Wichtig ist, dass wir in diesem Beispiel keine Pipe (|&gt;) nutzen und anders als bei der Regression sagen wir der t.test()-Funktion auch nicht, welchen Datensatz wir benutzen. Wir m√ºssen also mit Hilfe des Dollarzeiens erst den Datensatz und dann die Spalte angeben, so wie wir es in Kapitel 2 kennengelernt haben. Au√üerdem nutzen wir das Argument mu. Damit k√∂nnen wir den Wert angeben, gegen den wir unseren Stichprobenmittelwert testen wollen.\n\n# berechnet einen einstichproben t-Test\ntTest1sample &lt;- t.test(df_lokal$lokaleBindung, mu = 2)\n\n# zeigt die Ergebnisse an\ntTest1sample\n\n\n    One Sample t-test\n\ndata:  df_lokal$lokaleBindung\nt = 83.155, df = 1840, p-value &lt; 0.00000000000000022\nalternative hypothesis: true mean is not equal to 2\n95 percent confidence interval:\n 3.889405 3.980683\nsample estimates:\nmean of x \n 3.935044 \n\n\nSchauen wir uns das Ergebnis an. Oben werden uns der t-Wert, also die Teststatistik, die Freiheitsgrade (df) und der p-Wert des Tests angezeigt. Darunter erinnert uns R daran, welche Hypothese wir getestet haben. Darunter befindet sich wiederum ein 95%-Konfidenzintervall. Die Darstellung ist hier etwas ungl√ºcklich denn erst danach, also ganz unten, steht der Stichprobenmittelwert auf den sich das Konfidenzintervall bezieht.\nWir halten fest: Wir haben die Alternativhypothese getestet, dass sich der Stichprobenmittelwert vom Wert 2 unterscheidet. Das Ergebnis lautet: t(1840) = 83,155; p &lt; 0,001. Das bedeutet, dass wir die Nullhypothese (Stichprobenmittelwert = 2) verwerfen m√ºssen und die Alternativhypothese annehmen k√∂nnen.\n\n\n10.2.2 t-Test f√ºr gepaarte Stichproben\nDer t-Test f√ºr gepaarte Stichproben funktioniert im Grunde sehr √§hnlich. Statt das mu-Argument zu nutzen, √ºbergeben wir diesmal aber zwei Spalten aus einem Datensatz. Dazu nutzen wir das Argument paired = TRUE. Da der Datensatz mit dem wir arbeiten eine einfache Querschnittsbefragung darstellt, in dem es keine Paare gibt, k√∂nnen wir leider kein Beispiel rechnen. Wie der Code aussehen w√ºrde, sehen Sie aber unten:\n\n#### BEISPIELCODE, DER NICHT AUSGEF√úHRT WERDEN KANN! ####\n# tTestPaare &lt;- t.test(df$Spalte1, df$Spalte2, paired = TRUE)\n\n\n\n10.2.3 t-Test f√ºr unabh√§ngige Stichproben\nDer t-Test f√ºr unabh√§ngige Stichproben sieht der Regression sehr √§hnlich. Das hei√üt, wir geben auch hier eine ‚ÄúFormel‚Äù ein, bei der die abh√§ngige Variable links von einer Tilde (~) steht und die unabh√§ngige Variable rechts davon. F√ºr das Beispiel nehmen wir wieder die lokale Bindung (df_lokal$lokaleBindung) als AV und dazu das Bundesland aus dem die Befragten stammen (df_lokal$Bula) als UV.\n\n# berechnet einen t-Test f√ºr unabh√§ngige Stichproben\ntTestIndSample &lt;- t.test(df_lokal$lokaleBindung ~ df_lokal$Bula)\n\n# zeigt das Ergebnis an\ntTestIndSample\n\n\n    Welch Two Sample t-test\n\ndata:  df_lokal$lokaleBindung by df_lokal$Bula\nt = -3.2835, df = 1767.9, p-value = 0.001045\nalternative hypothesis: true difference in means between group RLP and group TH is not equal to 0\n95 percent confidence interval:\n -0.2439230 -0.0614935\nsample estimates:\nmean in group RLP  mean in group TH \n         3.868022          4.020730 \n\n\nSchauen wir uns auch hier die Ergebnisse an. Oben stehen wieder die Teststatistik t sowie die dazugeh√∂rigen Freiheitsgrad und der p-Wert. Hier lautet unser Ergebnis also: t(1767,9) = -3,28; p = 0,001.\nWeiter unten sehen wir dann wieder ein Konfidenzintervall. Es bezieht sich hier auf die Differenz zwischen den beiden Gruppenmittelwerten. Diese stehen dann direkt darunter. Wie wir sehen, f√ºhlen sich die Menschen aus Rheinland-Pfalz etwas weniger lokal zugeh√∂rig (M = 3.87) als die Menschen aus Th√ºringen (M = 4,02).\nF√ºr diesen Test berechnen wir nun Cohens d.¬†F√ºr die beiden Tests oben geht das grunds√§tzlich aber auch. Wir nutzen daf√ºr ie cohens_d()-Funktion aus dem Paket effectsize, der wir das Objekt √ºbergeben, in dem wir das Ergebnis des Tests gespeichert haben (hier also tTestIndSample). Au√üerdem √ºbergeben wir der Funktion das Argument pooled_sd = FALSE. Darauf werden wir gleich noch mal kurz eingehen.\n\ncohens_d(tTestIndSample, pooled_sd = FALSE)\n\nCohen's d |         95% CI\n--------------------------\n-0.15     | [-0.25, -0.06]\n\n- Estimated using un-pooled SD.\n\n\nCohens d wird hier mit dem Wert -0,15 ausgegeben.D.h., der Mittelwert der Menschen aus Rheinland-Pfalz liegt um 0,15 Standardabweichungen der AV unter dem Wert der Befragten aus Th√ºringen.\nUm das Ergebnis vollst√§ndig verschriftlichen zu k√∂nnen, ben√∂tigen wir noch die Mittelwerte und Standardabweichungen der beiden Gruppen. Das machen wir wie gewohnt mit Hilfe von summarise(). Damit die Werte f√ºr jede Gruppe erhalten, nutzen wir vorher noch group_by() und geben dort die Spalte Bula an.\n\n# berechnet Mittelwerte und Standardabweichungen f√ºr die beiden Gruppen\nMWsSDs &lt;- df_lokal |&gt;\n  group_by(Bula) |&gt;\n  summarise(MW = round(mean(lokaleBindung, na.rm = TRUE),2),\n            SD = round(sd(lokaleBindung, na.rm = TRUE),2))\n\n# zeigt die Werte an\nMWsSDs\n\n# A tibble: 2 √ó 3\n  Bula     MW    SD\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 RLP    3.87  1.02\n2 TH     4.02  0.97\n\n\nNun k√∂nnen wir das Ergebnis wie folgt aufschreiben: &gt; Durch einen t-Test wurde gepr√ºft, ob sich die Bindung an den Wohnort von Menschen in Rheinland-Pfalz (M = 3,87; SD = 1,02) von der Bindung der Befragten in Th√ºringen (M = 4,02; SD = 0,97). Die beiden Gruppen unterscheiden sich signifikant voneinander (t(1767,9) = -3,28; p = 0,001). Die Th√ºringer f√ºhlen sich signifikant st√§rker an ihren Ort gebunden, aber dieser Effekt ist schwach (Cohens d = -0,15).\n\n\n\n\n\n\nVarianzhomogenit√§t beim t-Test\n\n\n\nAm Ende des letzten Kapitels haben wir die Voraussetzungen von Regressionen kennengelernt. Dort hie√ü es unter anderem, dass die Streuung der Sch√§tzfehler gleichm√§√üig sein muss. Ist das nicht der Fall, sprechen wir von Heteroskedastizit√§t. Ist die Voraussetzung dagegen erf√ºllt, von Homoskedastizit√§t. Im Video in diesem Kapitel haben Sie dann erfahren, dass der t-Test eigentlich nur eine spezielle Form der Regression ist und daher dieselben Voraussetzungen teilt. Im Kontext von t-Tests sprechen wir aber in der Regel von Varianzhomogenit√§t (statt Homo- oder Heteroskedastizit√§t).\nDer t-Test wird in R standardm√§√üig in einer Variante durchgef√ºhrt, die keine gleichen Varianzen voraussetzt. Das ist einerseits sinnvoll, da es immer gut ist, einen Test zu haben, der nominell weniger Voraussetzungen hat. Andererseits liegt hierin auch der Grund, dass wir in unserem Aufruf von cohens_d() das Argument pooled_sd = FALSE angeben mussten. Denn die cohes_d()-Funktion geht davon aus, dass die Version des t-Tests gerechnet wurde, die von Varianzhomogenit√§t ausgeht.\nAlternativ k√∂nnten Sie auch beim Aufruf der t.test()-Funktion das Argument var.equal = TRUE angeben und k√∂nnten im Gegenzug pooled_sd = FALSE beim Aufruf von cohens_d() weglassen.\nIn dieser Variante k√∂nnen wir √ºbrigens sch√∂n sehen, dass der t-Test eigentlich eine Regression ist. Wenn Sie die Ergebnisse des Codes unten aufmerksam vergleichen, werden Sie feststellen, dass die t- und p-Werte des t-Tests und des entsprechenden Koeffizienten in der Regression quasi identisch sind. Gleiches gilt f√ºr die berechnete Effektst√§rke von standardize_parameters() und cohens_d().\n\n# berechnet einen t-Test mit angenommener Varianzhomogenit√§t\ntTest &lt;- t.test(df_lokal$lokaleBindung ~ df_lokal$Bula, var.equal = TRUE)\n\n# zeigt das Ergebnis an\ntTest\n\n\n    Two Sample t-test\n\ndata:  df_lokal$lokaleBindung by df_lokal$Bula\nt = -3.2651, df = 1839, p-value = 0.001114\nalternative hypothesis: true difference in means between group RLP and group TH is not equal to 0\n95 percent confidence interval:\n -0.24443519 -0.06098132\nsample estimates:\nmean in group RLP  mean in group TH \n         3.868022          4.020730 \n\n# berechnet dasselbe Modell als Regression\nregression &lt;- lm(lokaleBindung ~ Bula, data = df_lokal)\n\n# zeigt die Ergebnisse an\nsummary(regression)\n\n\nCall:\nlm(formula = lokaleBindung ~ Bula, data = df_lokal)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0207 -0.6180  0.1320  0.9793  1.1320 \n\nCoefficients:\n            Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)  3.86802    0.03098 124.838 &lt; 0.0000000000000002 ***\nBulaTH       0.15271    0.04677   3.265              0.00111 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9958 on 1839 degrees of freedom\n  (5 Beobachtungen als fehlend gel√∂scht)\nMultiple R-squared:  0.005764,  Adjusted R-squared:  0.005223 \nF-statistic: 10.66 on 1 and 1839 DF,  p-value: 0.001114\n\n\n\n# berechnet Cohens d und zeigt es an\ncohens_d(tTest)\n\nCohen's d |         95% CI\n--------------------------\n-0.15     | [-0.25, -0.06]\n\n- Estimated using pooled SD.\n\n# berechnet standardisierte Effektst√§rken f√ºr die Regression und zeigt sie an\nstandardize_parameters(regression)\n\n# Standardization method: refit\n\nParameter   | Std. Coef. |         95% CI\n-----------------------------------------\n(Intercept) |      -0.07 | [-0.13, -0.01]\nBula [TH]   |       0.15 | [ 0.06,  0.24]",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>t-Test</span>"
    ]
  },
  {
    "objectID": "t-Test.html#ergebnis-visualisieren",
    "href": "t-Test.html#ergebnis-visualisieren",
    "title": "10¬† t-Test",
    "section": "10.3 Ergebnis visualisieren",
    "text": "10.3 Ergebnis visualisieren\nIm bisherigen Lauf der Veranstaltung haben wir schon einige M√∂glichkeiten kennengelernt, um Mittelwerte bzw. die dazugeh√∂rige Verteilung zu visualisieren. F√ºr das Beispiel des t-Tests f√ºr unabh√§ngige Stichproben, den wir oben berechnet haben, lernen Sie nun eine weitere Visualisierung kennen. Wir starten zun√§chst mit einem Histogramm, das die beiden Gruppen ber√ºcksichtigt. Wir starten mit einer sehr einfachen Variante und verfeinern sie nach und nach. Das Endresultat steht dann ganz unten.\nIm ersten Schritt filtern wir fehlende Werte in der Spalte lokaleBindung aus und √ºbergeben unseren Datensatz an ggplot(). Dort legen wir fest, dass die Spalte lokaleBindung auf der x-Achse darstellen werden soll. Beim Histogramm wird auf der y-Achse automatisch die H√§ufigkeit dargestellt. Um die Gruppen abzubilden nutzen wir zus√§tzlich das Argument fill = Bula. Mit geom_histogram() erstellen wir dann das Histogramm. Dabei geben wir bins = 17 an. Unter bins verstehen wir, in wieviele Bereiche die Daten eingeteilt werden sollen. D.h., bei einem Histogramm werden nicht wie bei einem Balkendiagramm alle Werte einzeln abgebildet, sondern kleine Gruppen gebildet. Hier nehmen wir den Wert 17, weil er a) die tats√§chlich beobachteten Werte gut abbildet und b) weil das Resultat besser aussieht als der Standardwert 30 oder andere Werte. Abschlie√üend machen wir den Plot mit theme_minimal() direkt noch etwas sch√∂ner.\n\n# erstellt ein Histogramm der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\nhistBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_histogram(bins = 17)+\n  theme_minimal()\n\n# zeigt das Histogramm an\nhistBindung\n\n\n\n\n\n\n\n\nDas Resultat sieht nicht schrecklich aus, aber kann noch deutlich verbessert werden. Dass die Farben nicht sonderlich sch√∂n sind, ist das eine, aber vor allem handelt es sich hierbei um ein gestalpeltes Histogramm. D.h., die Anzahl, die auf der y-Achse dargestellt wird, ist die Gesamtanzahl der entsprechenden Werte in beiden Gruppen zusammen.\nDas k√∂nnen wir beheben, indem wir geom_histogram() das Argumet position = \"identity\" √ºbergeben. So werden die Balken des Histogramms √ºbereinandergelegt. Au√üerdem passen wir die Farben an. Daf√ºr nutzen wir wie schon in anderen Beispielen die scale_fill_manual()-Funktion und √ºbergeben ihr im Argument values zwei Farben (also eine pro Gruppe).\n\n# erstellt ein Histogramm der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\nhistBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_histogram(bins = 17, position = \"identity\")+\n  theme_minimal()+\n  scale_fill_manual(values=c(\"red\", \"orange\"))\n\n# zeigt das Histogramm an\nhistBindung\n\n\n\n\n\n\n\n\nDas sieht schon besser aus! Da die Balken nun hintereinander liegen und die Th√ºringer im Vordergrund dargestellt werden, wird der Balken f√ºr Rheinland-Pfalz an einigen Stellen verdeckt. Um das zu beheben k√∂nnen wir geom_histogram() das Argument alpha √ºbergeben. Damit machen wir die Balken etwas transparent. Der Wert muss immer zwischen 0 und 1 liegen. Im Beispiel unten wurde 0,6 gew√§hlt. Aber das ist eine Frage der Pr√§ferenz!\nEin etwas weniger offensichtliches Problem gibt es allerdings noch. Und zwar, dass die beiden Gruppen unterschiedlich gro√ü sind. Oben im Test haben wir erfahren, dass die Th√ºringer einen etwas h√∂heren Mittelwert haben als die Menschen aus Rheinland-Pfalz. Allerdings sehen wir in diesem Diagramm, dass in fast alle Wertebereichen mehr Menschen aus Rheinland-Pfalz als aus Th√ºringen fallen. In anderen Worten: die unterschiedlichen Fallzahlen machen es nahezu unm√∂glich, den h√∂heren Mittelwert der Th√ºringer optisch zu erahnen. Wir k√∂nnen es beheben, indem wir die Darstellung auf der y-Achse von absooluten H√§ufigkeiten zur sogenannten Wahrscheinlichkeitsdichte √§ndern. Das machen wir, geom_histogram() die aes()-Funktion √ºbergeben und dort y = after_stat(density) angeben. Dadurch werden die beiden Gruppen vergleichbar. Stark vereinfacht k√∂nnen wir sagen, dass die Wahrscheinlichkeitsdichte angibt, wie wahrscheinlich es ist, dass ein zuf√§lliger Wert aus unserer Stichprobe in einem bestimmten Wertebereich liegt.\nDa wir nun die Bedeutung der Achse ge√§ndert haben, sollten wir auch die Beschriftung der Achsen anpassen. Dazu nutzen wir wieder die labs()-Funktion.\n\n# erstellt ein Histogramm der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\nhistBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_histogram(bins = 17, position = \"identity\", alpha = 0.6, aes(y = after_stat(density)))+\n  theme_minimal()+\n  scale_fill_manual(values=c(\"red\", \"orange\"))+\n  labs(x = \"Bindung an den Wohnort\", y = \"Wahrscheinlichkeitsdichte\")\n\n# zeigt das Histogramm an\nhistBindung\n\n\n\n\n\n\n\n\nEine besonderheit der Wahrscheinlichkeitsdichte ist, dass wir sie auch kontinuierlich darstellen k√∂nnen. Im Prinzip wird dazu auf Basis unserer Beobachtungen eine Funktion gesch√§tzt, die die Verteilung einer kontinuierlichen, metrischne Variable abbildet. Dazu k√∂nnen wir geom_histogram() durch geom_density() ersetzen. Wir nutzen wieder das Argument alpha, um die Darstellung leicht transparent zu machen.\n\n# erstellt einen Densityplot der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\ndensityBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_density(alpha = .6)+\n  theme_minimal()+\n  scale_fill_manual(values=c(\"red\", \"orange\"))+\n  labs(x = \"Bindung an den Wohnort\", y = \"Wahrscheinlichkeitsdichte\")\n\n# zeigt den Densityplot an\ndensityBindung",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>t-Test</span>"
    ]
  }
]