[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Auswertung quantitativer Daten",
    "section": "",
    "text": "Herzlich willkommen!\nDieses Dokument wird Sie durch die Veranstaltung “Auswertung quantitativer Daten” begleiten. Es ist zum und im Wintersemeter 2024/25 an der Universität Erfurt entstanden.",
    "crumbs": [
      "Herzlich willkommen!"
    ]
  },
  {
    "objectID": "Einleitung.html",
    "href": "Einleitung.html",
    "title": "1  Willkommen zum Kurs",
    "section": "",
    "text": "1.1 Lernziele\nKommunikationswissenschaft ist nur mit einem bodenständigen Verständnis von Daten und Statistik möglich. Das gilt einerseits für die Forschung, die selbst quantitativ sein kann, mindestens aber voraussetzt, quantitative Studien lesen und verstehen zu können. Es gilt andererseits aber auch für die Berufspraxis: Viele Berufe erfordern heute ein gutes Verständnis von Daten oder sogar einen sicheren Umgang damit.\nVor diesem Hintergrund verfolgt diese Veranstaltung zwei zentrale Ziele:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#lernziele",
    "href": "Einleitung.html#lernziele",
    "title": "1  Willkommen zum Kurs",
    "section": "",
    "text": "Wir wollen Ihnen die statistischen Grundlagen vermitteln, die Sie im weiteren Verlauf Ihres Studiums benötigen werden, zum Beispiel in der Veranstaltung „Erhebung quantitativer Daten“, möglicherweise aber auch in der PSP oder einem anschließenden Masterstudium.\nWir wollen Ihnen die Werkzeuge an die Hand geben, die Sie benötigen, um vielfältige Arbeiten mit Daten auszuüben. Konkret bedeutet das, dass Sie lernen, Daten computergestützt aufzubereiten (also in ein verwertbares Format bringen), zu beschreiben und zu visualisieren. Dazu werden wir R benutzen.\n\n\n\n\n\n\n\nWas ist R?\n\n\n\nR ist ein Open-Source-Programm, das heißt, Sie können es kostenfrei nutzen. R zeichnet sich durch eine sehr aktive Community aus, diezahlreiche, ebenfalls kostenfreie, Erweiterungen entwickelt haben. In R nennen wir diese Erweiterungen Pakete. Einige davon werden wir im Lauf der Veranstaltung kennenlernen. R ist aber auch eine Programmiersprache mit einem Schwerpunkt auf statistisches Programmieren. Aber keine Sorge: Sie benötigen für diesen Kurs weder Vorkenntnisse in Statistik noch Informatik. Die wichtigsten Grundlagen bringen wir Ihnen bei. Weniger bedrohlich könnte man auch sagen, dass R einfach ein sehr guter und umfangreicher Taschenrechner ist.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#ablauf-und-aufbau-des-kurses",
    "href": "Einleitung.html#ablauf-und-aufbau-des-kurses",
    "title": "1  Willkommen zum Kurs",
    "section": "1.2 Ablauf und Aufbau des Kurses",
    "text": "1.2 Ablauf und Aufbau des Kurses\nDer Kurs ist so konzipiert, dass Sie die Inhalte zwischen den Präsenzsitzungen selbstständig erarbeiten. Die Sitzungen werden wir dann nutzen, um das Erlernte zu üben. Sie sollten also gut vorbereitet kommen! Als Grundlage dazu dient dieses Dokument. Jedes Kapitel erläutert die Inhalte einer Woche.\nIn den ersten Sitzungen werden wir uns Zeit für die Grundlagen nehmen, die Sie im Lauf des Semester immer wieder benötigen werden. Dazu zählen auch einige Grundlagen der Statistik. In den späteren Sitzungen werden wir uns dann mit konkreten statistischen Verfahren beschäftigen. Auch hier werden wir uns sowohl mit der Statistik an sich beschäftigen, als auch mit der Umsetzung in R.\nNachfolgenden finden Sie einen tabellarischen Ablauf der Sitzung\n\n\n\n\n\n\n\n\nDatum\nInhalt\nVorbereitung\n\n\n\n\n15.10.\n\nLernziele\nAblauf und Aufbau des Kurses\nR und RStudio installieren\nProjekt anlegen\nSkript anlegen und speichern\n\n-\n\n\n22.10.\n\nObjekte (Objekte deklarieren, Objekte benennen, Objekttypen)\nDatensätze (Daten erstellen, Objekte in Datensätzen ansprechen, Daten einlesen)\nFunktionen (Argumente und Rückgabe von Funktionen, Funktionen ausführen, Funktionen verschachteln)\n\nKapitel 2\n\n\n29.10.\n\nPakete installieren und Pakete laden\nDatentransformation\n\nKapitel 3\n\n\n05.11.\n\nSkalenniveaus und zenrtale Lagemaße\ndeskriptive Datenanylse\n\nKapitel 4\n\n\n12.11.\n\nHypothesen (Alternativ- und Nullhypothese, Arten von Hypothesen)\nTesttheorie (p-Werte, statistische Signifikanz, statistische Power)\n\nKapitel 5\n\n\n19.11.\n\nZusammenhänge zwischen zwei nominalen Variablen testen (Kreuztabellen)\nZusammenhänge zwischen metrischen oder ordinalen Daten testen (Korrelationen)\n\nKapitel 6\n\n\n26.11.\ntba\n\n\n\n03.12.\ntba\n\n\n\n10.12.\ntba\n\n\n\n17.12.\ntba\n\n\n\n24.12.\nvorlesungsfrei 🎅\n\n\n\n31.12.\nvorlesungsfrei 🎆 🥳\n\n\n\n07.01.\ntba\n\n\n\n14.01.\ntba\n\n\n\n21.01.\ntba\n\n\n\n28.01.\ntba\n\n\n\n04.02.\ntba",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#r-herunterladen",
    "href": "Einleitung.html#r-herunterladen",
    "title": "1  Willkommen zum Kurs",
    "section": "1.3 R herunterladen",
    "text": "1.3 R herunterladen\nBevor es losgehen kann, müssen Sie R auf Ihrem Laptop installieren. Die beste Anlaufstelle dafür ist CRAN (The Comprehensive R Archive Network): https://cran.r-project.org/\nOben mittig auf der Seite können Sie Ihr Betriebssystem auswählen.\n\nWenn Sie Windows nutzen, klicken Sie auf “base” und starten dann auf der nächsten Seite den Download.\nWenn Sie MacOS nutzen, müssen Sie darauf achten, die für Ihr System korrekte R-Version herunterzuladen.\n\nNachdem Sie R heruntergeladen und installiert haben, könnten Sie im Prinzip loslegen. Allerdings ist die Nutzeroberfläche von R nicht gerade leicht verständlich. Darum arbeiten wir in diesem Kurs mit RStudio. Hierbei handelt es sich um eine sogenannte integrierte Entwicklungsumgebung, die das Arbeiten mit R deutlich leichter macht. Sie können es auf https://posit.co/download/rstudio-desktop/ herunterladen. Wählen Sie auch hier die für Ihr Betriebssystem ausgegebene Version herunter und installieren diese.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#in-rstudio-arbeiten",
    "href": "Einleitung.html#in-rstudio-arbeiten",
    "title": "1  Willkommen zum Kurs",
    "section": "1.4 In RStudio arbeiten",
    "text": "1.4 In RStudio arbeiten\n\n1.4.1 Die Nutzeroberfläche von RStudio\nWenn Sie auch RStudio installiert haben, kann es endlich losgehen. Wenn Sie das Programm das erste Mal öffnen, werden Sie gefragt, welche R-Version genutzt werden soll. Hier können Sie angeben, dass die System-Standardversion genutzt werden soll. Das bedeutet auch: Immer, wenn Sie RStudio öffnen, wird R im Hintergrund ebenfalls gestartet. Sie müssen also nicht beide Programme öffnen!\nAnschließend sollte Ihr Programm in etwa so aussehen, wie auf dem Screenshot unten.\n\n\n\nScreenshot RStudio\n\n\nLinks sehen Sie die Konsole. Hier zeigt R Ihnen, welche Befehle ausgeführt wurden und was das Ergebnis ist. Sie können auch direkt Befehle eingeben, aber dazu unten mehr. Oben rechts sehen Sie das sogenannte Environment. Hier finden Sie Objekte, die Sie angelegt haben. Ein Objekt kann erstmal alles mögliche sein, z.B. ein Datensatz, eine Variable oder eine Funktion. Im Lauf des Kurses werden wir darauf noch genauer eingehen. Das Feld unten rechts erfüllt mehrere Funktionen. Die zwei wichtigsten verbergen sich hinter den Reitern Plots und Help. Die Namen sind relativ selbsterklärend: Unter Plots werden uns Grafiken gezeigt, die wir in R erstellen und unter Help finden wir Hilfe. Beides ist im Moment noch nicht relevant für uns, aber wir werden später darauf zurückkommen.\n\n\n1.4.2 Die Konsole\nZunächst schauen wir uns die Konsole etwas genauer an. Hier können Sie direkt mit R interagieren. Durch das Größer-als-Zeichen (&gt;) am Anfang der untersten Zeile signalisiert R Ihnen, dass Sie Befehle ausführen können. Wenn Sie z.B. einfache Rechnungen in der Konsole eingeben und mit Enter bestätigen, wird R Ihnen das Ergebnis ausgeben. Die [1] können Sie zunächst ignorieren. Dazu kommen wir später noch. Daneben sollte nun das Ergebnis der Rechnung stehen, so wie in den folgenden Zeilen:\n\n3+2 \n\n[1] 5\n\n\nEs kann vorkommen, dass Sie in der untersten Zeile der Konsole nicht das Größer-als-Zeichen sehen, sondern ein Plus. Das passiert immer dann, wenn Sie einen unvollständigen Befehl ausführen wollen. Geben Sie z.B. nur 17- ein und versuchen, den Befehl auszuführen, wird R Ihnen ein “+” anzeigen, da es nicht weiß, was von 17 abgezogen werden soll. Sobald Sie eine zweite Zahl eingeben und mit Enter bestätigen, wird Ihnen das Ergebnis angezeigt. Wenn Sie das “+” einmal sehen, aber nicht wissen, woher es kommt bzw. welcher Befehl unvollstädnig war, können Sie einfach irgendetwas in die Konsole eingeben, mit Enter bestätigen und sich dann auf die Suche nach dem Fehler machen.\nMit diesem Wissen könnten wir so ziemlich alle Funktionalitäten von R nutzen, es wäre aber ziemlich unpraktisch. Zwar speichert R den Verlauf unserer Sitzung (verborgen hinter dem Reiter History, oben rechts neben Environmen”), das Format ist aber nicht sonderlicht gut dazu geeignet, unsere Berechnungen und Analysen wiederverwertbar festzuhalten.\n\n\n1.4.3 Arbeit in Projekten\nEine gute Möglichkeit, Ihre Arbeit in R festzuhalten, sind Projekte.Diese haben den Vorteil, dass alle relevanten Dateien an einem Ort gebündelt und durch eine spezielle R-Datei verbunden werden. Das macht zum Beispiel das Laden von Datensätzen deutlich einfacher. Als erstes sollten Sie daher ein Projekt für diesen Kurs anlegen.\nDazu klicken Sie zunächst rechts oben auf “Projekte” und dann “Neues Projekt”\n\nAls nächstes werden Sie gefragt, ob Sie einen einen neuen Ordner anlegen oder vorhandenen Ordner verwenden möchten. Falls Sie noch keinen Ordner für diesen Kurs angelegt haben, wählen Sie die erste Option, anderfalls die zweite.\n\nSofern Sie einen neuen Ordner angelegt haben, klicken Sie nun auf “Neues Projekt”.\n\nZuletzt müssen Sie dem Ordner noch einen Namen geben und angeben, wo er angelegt werden soll und abschließend das Projekt anlegen.\n\n\n\n1.4.4 Skripte\nSkripte sind Datein, in dene Sie R-Code schreiben und speichern können. Der große Vorteil daran ist, dass Sie Ihre Arbeit so dokumentieren und jederzeit wiederholen oder verändern können, ohne alles von vorne in der Konsole eingeben zu müssen. Um ein Skript anzulegen, klicken Sie oben links auf File –&gt; New File –&gt; R Script. Nun öffnet sich über der Konsole das (noch leere) Skript. Speicher Sie es am besten direkt ab, entweder über die Menüleiste (File –&gt; Save) oder wie in anderen Programmen per Tastatur:  + SS. Praktischerweise schlägt R direkt den Ordner vor, in dem wir gerade arbeiten, sprich den vorhin angelegten Projektordner.\nIm Skript können Sie nun R-Code schreiben. Um eine Code-Zeile auszuführen können Sie entweder gleichzeitig  + EnterEnter drücken, oder oben rechts direkt über dem Skript auf “Run” klicken. R führt den Befehl in der aktuellen Zeile aus und springt zum nächsten Befehl. Manchmal erstrecken sich Befehle über mehrere Zeilen, aber das ist kein Problem. R ist ziemlich gut darin, zu erkennen, wann ein Befehl aufhört und wo der nächste beginnt. Zumindest solange Sie keinen Fehler in Ihrem Code haben.\nDas Ergebnis wird Ihnen in der Konsole angezeigt. Probieren Sie es doch mal mit der Addition von oben aus: 3+2\nDamit Sie zukünftig in Ihren Skripten nicht den Überblick verlieren, sollten Sie sich angewöhnen, Kommentare zu schreiben. Dazu können Sie das Hashtag- bzw. Doppelkreuzzeichen `#` verwenden. Alles was in einer Zeile hinter diesem Zeichen steht, wir von R nicht interpretiert, sondern dient lediglich Ihnen und allen anderen, die den Code lesen, als Erklörung oder Erinnerungsstütze. Jetzt am Anfang mag das noch etwas albern wirken, aber unterschätzen Sie nicht, wie wertvoll es sein kann, nach einer längeren Pause an einem Skript eine gute Dokumentation vorzufinden!\nAb der kommenden Woche werden wir intensiv(er) in Skripten arbeiten. Die ersten Kapitel können Sie noch gut in einem Skript bearbeiten. Für die späteren Kapitel empfiehlt es sich, jeweils ein neues Skirpt anzulegen, damit Sie den Überblick nicht verlieren.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Einleitung.html#ressourcen",
    "href": "Einleitung.html#ressourcen",
    "title": "1  Willkommen zum Kurs",
    "section": "1.5 Ressourcen",
    "text": "1.5 Ressourcen\nR ist sehr komplex und kann nicht innerhalb eines Semesters gemeistert werden. Wie oben erwähnt, lernen Sie in dieser Veranstaltung einige wichtige Grundlagen. Die ersten davon haben Sie heute schon gelernt. Dennoch werden Sie in den nächsten Wochen und Monaten einiges an Informationen verarbeiten müssen. Ihre erste Anlaufstelle dafür ist dieses Dokument und die Präsenzübungen. Aber niemand nimmt es Ihnen übel, wenn Sie darüber hinaus weitere Hilfe benötigen oder in Anspruch nehmen!\nDie meisten Probleme, die Sie haben werden, hatten vor Ihnen schon unzählige andere R-Lerner:innen und glücklicherweise hat R eine sehr aktive und hilfsbereite Community, die Ihnen jederzeit weiterhelfen kann. Beispielsweise finden sich in einigen sozialen Netzwerken wie X/Twitter (#rstats) und Reddit (/r/rstats) informelle R-Gruppen, die einander Fragen beantworten. Wenn Sie ein Problem oder eine Fehlermeldung googeln, werden Sie füher oder später auch Ergebnisse von StackOverflow finden, einem Forum für Programmierer:innen. Und keine Sorgen: Niemand erwartet von Ihnen, dass Sie sich aktiv in die Community einbringen!\nDarüber hinaus gibt es zahlreiche Lehrbücher und Online-Kurse über R. Untenstehend finden Sie einige davon:\n\nR für Einsteiger von Maike Luhmann (Zugriff über das Uninetz)\nLearning Statistics with R von Danielle Navarro\nEine Sammlung Häufig verwendeter Datenvisualisierungen\nÄhnliche R-Kurse aus Bremen und Hamburg\n\nFalls Sie in diesen Quellen nicht fündig werden, spricht prinzipiell auch nichts gegen den Einsatz von KI, also zum Beispiel große Sprachmodelle wie ChatGPT. Hiermit erhalten Sie ganz offiziell die Erlaubnis, davon im Rahmen dieses Kurses gebrauch zu machen! Seien Sie bitte trotzdem vorsichtig: Nicht jeder von ChatGPT und ähnlichen Anwendungen erstellte R-Code tut das was Sie wollen oder sich vorgestellt haben. Prüfen Sie die Code daher stets auf Herz und Nieren, bevor Sie ihn als richtig akzeptieren.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zum Kurs</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html",
    "href": "Objekte, Daten, Funktionen.html",
    "title": "2  Objekte, Daten, Funktionen",
    "section": "",
    "text": "2.1 Objekte\nIm letzten Kapitel haben Sie bereits zwei wichtige Dinge über Objekte erfahren:\nIn diesem Kapitel lernen Sie, wie Sie Objekte deklarieren, wie Objekte benannt sein sollten und welche Objekttypen es gibt.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#objekte",
    "href": "Objekte, Daten, Funktionen.html#objekte",
    "title": "2  Objekte, Daten, Funktionen",
    "section": "",
    "text": "Objekte können erst einmal alles mögliche sein, z.B. einzelne Variablen oder ganze Datensätze.\nObjekte werden im Environment angezeigt.\n\n\n\n2.1.1 Objekte deklarieren\nSie können Objekte erstellen und ihnen einen Wert zuzuweisen, indem Sie einen Namen für das Objekt in ihr Skript schreiben, daneben einen Pfeil (&lt;-) und danach den Wert des Objektes deklarieren.1\nSo wie hier:\n\n# Erstellt die Objekte x und y mit den Werten 3 und 6\n\nx &lt;- 3\ny &lt;- 6\n\nMit diesem Code haben wir zwei Objekte erstellt: Das Objekt x mit dem Wert 3 und das Objekt y mit dem Wert 6. Mit diesen Objekten können wir jetzt weiterarbeiten, z.B. indem wir sie addieren. Indem wir z noch mal einzeln in eine Zeile schreiben, können wir uns den Wert direkt in der Konsole anzeigen lassen.\n\n# Berechnet das Objekt z aus den Objekten x und y\nz &lt;- x+y\n\n# Zeigt den Wert von z in der Konsole an\nz\n\n[1] 9\n\n\nWenn wir jetzt den Wert von x oder y ändern, ändert sich durch erneutes Ausführen des Befehls auch der Wert von z.\n\n# Der Wert von x wird geändert\nx &lt;- 7\n\n# z wird neu berechnet\nz &lt;- x+y\nz\n\n[1] 13\n\n\nDie Objekte x, y und z sind bisher jeweils natürliche (also ganze) Zahlen. Sie können aber auch andere Zahlen erstellen, z.B. negative Zahlen oder Zahlen mit Dezimalstellen:\n\n# x und y werden neue Werte zugewiesen, die keine ganze Zahlen sind. \nx &lt;- -7\ny &lt;- 6.5\n\n\n# z wird neu berechnet\nz &lt;- x+y\nz\n\n[1] -0.5\n\n\nJetzt haben wir x den Wert -7 und y den Wert 6,5 zugewiesen. Beachten Sie, dass wir einen Punkt als Dezimalzeichen genutzt haben! Entsprechend dieser Zuweisungen ist z nun -0,5.\nObjekte können auch andere Werte als Zahlen enthalten, z.B. Zeichenketten, sogenannte strings.\n\n# Ein String der \"name\" heißt wird erstellt und mit dem Wert \"Hans\" versehen\n\nname &lt;- \"Hans\"\n\n\n\n\n\n\n\nTipp\n\n\n\nWenn Sie in RStudio Anführungszeichen setzen wollen, geht das um einiges einfacher als z.B. in Word. Wenn Sie in einem Skript z.B. ShiftShift + 22drücken, werden gleich Anführungszeichen für den Anfang und das Ende des strings gesetzt, sodass Sie daziwschen Ihren Text platzieren können. Sie können aber auch jeden vorhandenen Text markieren und dann ShiftShift + 22 drücken und es werden Anführungszeichen um den Text herum gesetzt.\n\n\nOhne weitere Funktionen haben wir allerdings deutlich weniger Möglichkeiten, mit strings zu arbeiten. Wir können Sie z.B. nicht ohne Weiteres kombinieren.\n\n\n2.1.2 Objektnamen\nBisher haben wir unseren Objekten sehr einfache Namen gegeben, die nicht sonderlich hilfreich sind und würden wir nur bei einfachen Buchstaben bleiben, gingen uns bald die Namens aus. Darum empfiehlt es sich, andere Namen zu verwenden. Welche das konkret sind, ist Ihnen überlassen. R gibt allerdings einige Regel vor:\n\nGrundsätzlich sind Zahlen, Punkte, Binde- und Unterstriche und Buchstaben erlaubt.\nUmlaute, Sonderzeichen (exkl. Punkte, Binde- und Unterstriche) und Leerzeichen sind nicht erlaubt.\nObjektnamen müssen mit einem Buchstaben beginnen.\nObjektnamen beachten Groß- und Kleinschreibung.\nObjektnamen sind einzigartig. Das heißt, wenn Sie zwei Objekten nacheinander gleich benennen, wird das Zweite das Erste überschreiben.\nTRUE und FALSE sind als Namen verboten, da es sich hierbei um sogenannte boolesche Operatoren handelt. Da Sie mit T und F abgekürzt werden können, sollten auch diese Namen vermieden werden. Was genau es damit auf sich hat, werden wir im Lauf der Veranstaltung lernen.\n\nDarüber hinaus gibt es einige sinnvolle Konventionen, an die Sie sich halten sollten:\n\nAnschließend an den Ausschluss von TRUE und FALSE bzw. T und F, sollten Namen vermieden werden, die schon anderweitig vergeben sind, z.B. durch Funktionen.\nObjektnamen sollten so gewählt sein, dass sie auch nach einer längeren Pause noch wissen, was sich hinter einem Objekt verbirgt. In einigen Fällen ist das relativ einfach. Wenn Sie zum Beispiel im Rahmen einer Befragung das Alter der Befragten erhoben haben, können Sie die entsprechende Variable einfach Alter nennen. Manchmal wird es aber auch schwieriger. Wenn Sie zum Beispiel die Einstellung der Befragten zur Statistik über mehrere Fragen erhoben haben, empfielt es sich, einen gemeinsamen Präfix zu verwenden, z.B. einstellungStatistik und dann eine Zahl. So wissen Sie zwar nicht mehr unbedingt, was der genaue Wortlaut der Frage war, aber Sie sollten die Variable schnell wiedererkennen können.\nEs gibt verschiedene Konventionen zu längeren Objektnamen. Im vorherigen Punkt wurde z.B. der Konvention gefolgt, das erste Wort klein und das darauffolgende (bzw. alle weiteren Worte) groß zu schreiben. Genauso gut könnten Sie die Worte anders kenntlich machen, z.B. so: einstellung_statistik. Manchmal sieht man auch Dinge wie einstellung.statistik, EINSTELLUNG_STATISTIK, einstellung-statistik oder EinstellungStatistik. Wie sie es machen, ist Ihnen überlassen, aber versuchen Sie sich an eine dieser Konventionen zu halten.\n\n\n\n2.1.3 Objekttypen\nBisher haben wir unseren Objekten nur einfache Zahlenwerte bzw. einen string zugewiesen. Man kann diese Objekte auch einfach Variablen nennen. Aber Vorsicht: Der Begriff ist gewissermaßen zwedeutig: In der Programmierlogik von R nennen bezeichnen wir Objekte als Variable, wenn wir dort etwas Speichern, das wir irgendwie variieren können. In der Statistik meint der Begriff dagegen in der Regel eine Sache, über die wir Daten gesammelt haben. Also zum Beispiel eine Frage im Fragebogen oder eine Kategorie in der Inhaltsanalyse.\nDie sehr einfachen Variablen, die wir oben angelegt haben, kommen in der Praxis relativ selten vor. Stattdessen haben wir es häufig mit einer ganzen Abfolge von Zahlen (oder strings) zu tun, z.B. wenn wir Daten einer Stichprobe erhoben haben.\nGlücklicherweise müssen wir nicht für jede Antwort jeder Person ein eigenes Objekt erstellen, sondern können sogenannte Vektoren verwenden. Hierbei handelt es sich um Objekte, die aus verschiedenen Elementen zusammengesetzt sind. Vektoren sind so etwas wie das Rückgrat von R, da viele Dinge intern als Vektoren behandelt werden, z.B. einzelne Zeilen oder Spalten in einer Tabelle. Entsprechend sind auch viele Funktionen in R darauf ausgelegt, auf Vektoren angewendet zu werden. Wir werden sie uns daher etwas genauer ansehen.\nVektoren können zum Beispiel mit der Funktion (dazu unten mehr) c() erstellt werden. Das c steht dabei für “combine”. Die einzeknen Elemente werden mit einem Komma getrennt.\n\n# Erstellt den Vektor \"Zahlen\", der die Zahlen von 1 bis 10 enthält\n\nzahlen &lt;- c(1,2,3,4,5,6,7,8,9,10)\n\nIn diesem Beispiel haben wir einen Vektor namens zahlen erstellt, der die Zahlen von 1 bis 10 enthält. In solch einfachen Fällen gibt es übrigens einen kleinen Trick und zwar den Doppelpunkt:\n\n# Erstellt den Vektor \"zahlenAnders\", der ebenfalls die Zahlen von 1 bis 10 enthält\n\nzahlenAnders &lt;- 1:10\n\nMit diesem Befehl sagen wir R, dass alle Zahlen von 1 bis einschließlich 10 in einem Vektor kombiniert werden sollen, ohne jede Zahl einzeln aufschreiben zu müssen.\nVielleicht ist Ihnen aufgefallen das die beiden Vektoren zahlen und zahlenAnders im Environment leicht unterschiedlich dargestellt werden. Für den Moment können wir das jedoch ignorieren.\n\nDie einzelnen Zahlen in den oben angelegten Vektoren, werden als Elemente bezeichnet. Sie können einzeln angewählt und ggf. manipuliert werden. Dafür nutzen wir sogenannte Indizes. Hier kommt die [1] ins Spiel, die wir im letzten Kapitel ignoriert haben. Damit hat uns R signalisiert, dass das Ergebnis hinter dieser [1] das erste Element eines Vektors war. Da es nur ein Element gab, wirkt das zunächst etwas überflüssig. In machen Situationen kann es aber vorkommen, dass das Ergebnis eines Befehls mehrere Elemente enthält. Und in wieder anderen Situationen kann es sinnvoll sein, einzelne Elemente eines Vektors direkt anzusprechen. Das geht ebenfalls mit eckigen Klammern. Beispielsweise lassen wir hier das dritte Element des Vektors zahlen anzeigen.\n\n# Das dritte Element von \"zahlen\" wird ausgegeben\n\nzahlen[3]\n\n[1] 3\n\n\nWir können das Element auch ändern:\n\n# Das dritte Element von \"zahlen\" wird geändert und dann ausgegeben\n\nzahlen[3] &lt;- 9\nzahlen[3]\n\n[1] 9\n\n\nUnd genauso, wie wir oben die Zahlen von 1 bis 10 in einen Vektor geschrieben haben, können wir uns auch mehrere Elemente eines Vektors anzeigen lassen, z.B. die ersten drei Elemente:\n\n# Zeigt die ersten drei Elemente von \"zahlen\" an\n\nzahlen[1:3]\n\n[1] 1 2 9\n\n\nOder das erste, zweite und fünfte Element, indem wir die c()-Funktion von oben verwenden:\n\n# Zeigt die ersten beiden und das fünfte Element von \"zahlen\" an\n\nzahlen[c(1:2, 5)]\n\n[1] 1 2 5\n\n\nWir können auch mehrere Elemente auf einmal ändern. Dabei müssen wir aber allerdings ein paar Dinge beachten:\n\nWir können entweder alle Elemente durch einen Wert ersetzen:\n\n\n# Ändert alle Werte in \"zahlen\" zu 1\n\nzahlen[1:10] &lt;- 1\nzahlen\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\n\n\nOder so viele Werte, dass die Anzahl der alten Werte ein vielfaches der Anzahl der neuen Werte sind (z.B. 5 neue auf die 10 alten Werte). Die neuen Werte werden dann so lange wiederholt, bis der Vektror wieder dieselbe Länge hat:\n\n\n# Die Werte in \"zahlen\" werden durch die Werte von 1 bis 5 ersetzt und dann angezeigt\n\nzahlen[1:10] &lt;- 1:5\nzahlen[1:10]\n\n [1] 1 2 3 4 5 1 2 3 4 5\n\n# Die Werte in \"zahlen\" werden durch die Werte von 1 und 2 ersetzt und dann angezeigt\n\nzahlen[1:10] &lt;- 1:2\nzahlen[1:10]\n\n [1] 1 2 1 2 1 2 1 2 1 2\n\n\n\nOder genauso viele Werte angeben, wie wir ersetzen wollen:\n\n\n# Die Werte in \"zahlen\" werden durch die Werte von 10 bis 1 ersetzt und dann angezeigt\n\nzahlen[1:10] &lt;- c(10,9,8,7,6,5,4,3,2,1)\nzahlen[1:10]\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nNach denselben Regeln können wir auch mit den Vektoren rechnen. Wenn Sie in Ihrem Skript die obigen Befehle der Reihe nach ausgefüllt haben, sollten Ihre beiden Vektoren nun die Werte von 10 bis 1 (zahlen) bzw. 1 bis 10 (zahlenAnders) haben:\n\n# Zeigt die Vektoren \"zahlen\" und \"zahlenAnders\" an\n\nzahlen\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\nzahlenAnders\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWir können nun entweder eine einzelne Zahl nehmen und sie zu einem Vektor addieren, davon subtrahieren, dadurch Teilen oder die beiden multiplizieren:\n\n# Addiert y (6,5) zu den Elementen von \"zahlen\"\nzahlen+y\n\n [1] 16.5 15.5 14.5 13.5 12.5 11.5 10.5  9.5  8.5  7.5\n\n# Subtrahiert y von den Elementen von \"zahlen\"\nzahlen-y\n\n [1]  3.5  2.5  1.5  0.5 -0.5 -1.5 -2.5 -3.5 -4.5 -5.5\n\n# Multipliziert y mit den Elementen von \"zahlen\"\nzahlen*y\n\n [1] 65.0 58.5 52.0 45.5 39.0 32.5 26.0 19.5 13.0  6.5\n\n# Dividiert die Elementen von \"zahlen\" durch y \nzahlen/y\n\n [1] 1.5384615 1.3846154 1.2307692 1.0769231 0.9230769 0.7692308 0.6153846\n [8] 0.4615385 0.3076923 0.1538462\n\n\nOder eine Anzahl, die so groß ist, dass die Anzahl der Elemente des Vektors ein Vielfaches davon ist:\n\n# Subtrahiert 1 bsi 5 von den Elementen von \"zahlen\"\n\nzahlen - 1:5\n\n [1]  9  7  5  3  1  4  2  0 -2 -4\n\n\nOder wir nutzen einen Vektor der genauso lang ist:\n\n# Addiert \"zahlen\" und \"zahlenAnders\"\n\nzahlen + zahlenAnders\n\n [1] 11 11 11 11 11 11 11 11 11 11\n\n\nWie oben bereits erwähnt, kommt man in R schon ziemlich weit, wenn man ein gutes Verständnis von Vektoren mitbringt. In diesem Abschnitt haben Sie einige Basics gelernt, die Ihnen bei der Arbeit mit R immer wieder begegnen werden.\nNeben Vektoren gibt es noch zwei weitere Objekttypen, die Ihnen in Ihrer Arbeit mit R begegnen werden. Der erste ist die Liste. Der Name ist relativ selbsterklärend: Es handelt sich dabei um eine Liste von Elementen. Der Unterschied zum Vektor ist, dass Listenelemente alles Denkbare sein können. Also z.B. einzelne Werte wie x, y, z und name von oben, aber auch Vektoren wie zahlen und zahlenAnders. Sogar ganze Datensätze können Teil einer Liste sein! Am häufgisten werden Ihnen Listen als Ergebnis von statistischen Berechnungen begnen, aber Sie können mit der list()-Funktion auch selber welche anlegen. Hier in Beispiel:\n\n# Erstellt eine Liste aller bisher erstellten Elemente\n\nwasBisherGeschah &lt;- list(x, y, z, name, zahlen, zahlenAnders)\n\nIn dieser Liste haben wir alle bisher erstellten Objekte zusammengefasst. Ähnlich wie bei den Vektoren, können wir auch Listenelemente direkt über einen Index anprechen. Diesmal nutzen wir aber doppelte Klammren: [[]]. Zum Beispiel können wir so das vierte Element ausgeben lassen:\n\n# Zeigt das vierte Element der Liste an\n\nwasBisherGeschah[[4]]\n\n[1] \"Hans\"\n\n\nWir können auch erst ein bestimmtes Listenelement ansprechen und dann ein darin enthaltenes Element:\n\n# Zeigt das vierte Element des fünften Elements der Liste an\n\nwasBisherGeschah[[5]][4]\n\n[1] 7\n\n\nEin Vorteil von Listen ist, dass die Elemente darin benannt sein können. Und tatsächlich werden wir benannte Listen in der Realität deutlich häufiger antreffen. Wenn Sie selber eine benannte Liste erstellen wollen, gehen Sie ähnlich vor wie beim Deklarieren von Objekten. Allerdings nutzen Sie dabei nicht den Pfeil, sondern ein Gleichheitszeichen. In diesem Beispiel behalten wir die Namen von oben bei:\n\n# Erstellt eine Liste mit Namen\n\nwasBisherWirklichGeschah &lt;- list(x = x, y = y, z = z,\n                                 name = name, zahlen = zahlen,\n                                 zahlenAnders = zahlenAnders)\n\nNamen für Listenelemente haben den großen Vorteil, dass wir uns nicht merken müssen, an welcher Stelle ein bestimmtes Element auftaucht. Stattdessen können wir es ganz einfach über das Dollarzeichen ($) ansprechen. Dazu schreiben Sie erst den Namen der Liste, dann ein $ und dann den Namen des Elements. Auch hier können Sie wieder einen Index nutzen, um nur bestimmte Elemente anzusprechen:\n\n# zeigt das Element \"zahlenAnders\" der Liste \"wasBisherWirklichGeschah\" an\n\nwasBisherWirklichGeschah$zahlenAnders\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# zeigt das fünfte Element des Element \"zahlenAnders\" der Liste \"wasBisherWirklichGeschah\" an\n\nwasBisherWirklichGeschah$zahlenAnders[5]\n\n[1] 5\n\n\n\n\n\n\n\n\nObjekte inspizieren\n\n\n\nSie haben verschiedene Möglichkeiten, mehr über Objekte im Environment zu erfahren. Insbesondere im Kontext von Listen kann das manchmal sehr nützlich sein. Die beiden soeben erstellten Listen haben im Environment einen kleinen blauen Pfeil neben ihrem Namen. Dort können Sie draufklicken, um die Elemente der Liste zu sehen:\n\nSie können aber auch auf den Namen klicken. Dann öffnet sich oben im Editor (da wo Sie Ihr Skript schreiben) ein neues Tab, in dem Sie sich das Objekt genauer ansehen können.\n\n\nDer letzte Objektyp ist der, wegen dem wir eigentlich hier sind: Datensätze. Wir werden Sie uns nun etwas genauer ansehen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#datensätze",
    "href": "Objekte, Daten, Funktionen.html#datensätze",
    "title": "2  Objekte, Daten, Funktionen",
    "section": "2.2 Daten(sätze)",
    "text": "2.2 Daten(sätze)\nIn der Wissenschaft haben wir es in der Regel mit Daten zu tun. Soweit so gut. Aber was sind Daten eigentlich genau? Die Frage mag auf den ersten Blick trivial erscheinen, ist aber erstaunlich komplex. Beispielsweise könnten Sie im Rahmen einer qualitativen Studie Interviews mit Menschen führen, diese transkribieren und hätten dann Daten in Textform vorliegen. Aber wäre das Ihr erster Gedanke, wenn Sie danach gefragt werden, was Daten eigentlich genau sind? Tatsächlich haben diese Art von Daten, also qualitative Daten, relativ wenig mit dem zu tun, was wir in diesem Kurs machen. Wir beschäftigen uns mit quantitativen Daten. Weil dieser Ausdruck auf Dauer etwas sperrig ist, kürzen wir ihn hier aber etwas ab und sprechen nur von Daten.\n\n2.2.1 Struktur von Datensätzen\nWas also sind denn jetzt Daten im Sinne dieses Kurses? In erster Linie meinen wir mit Daten Informationen, die in Zahlenform vorliegen oder zumindest so repräsentiert werden können. Das erlaubt uns, damit zu rechnen. In R werden diese Zahlen meistens als eine Art Tabelle gespeichert. Die meisten von ihnen folgen einem einfachen Muster: Jede Zeile ist ein Fall, jede Spalte eine Variable. Ein Fall ist z.B. ein ausgefüllter Fragebogen, ein codierter Medieninhalt oder ein Versuchsdurchlauf eines Experiments. Eine Variable ist z.B. eine Frage aus einem Fragebogen, eine Kategorie aus einem Codebuch oder ein im Experiment gemessener Wert.\n\n\n2.2.2 Datensätze erstellen\nWir schauen uns so eine Tabelle mal an einem einfachen Beispiel an, indem wir die data.frame()-Funktion nutzen. Ähnlich wie die list()-Funktion, können wir data.frame() nutzen, um ein Objekt aus mehreren vorhandenen Objekten zu erstellen. Auch hier können wir einzelnen Elementen einen Namen geben. Wir nennen diesen Datensatz df (Abkürzung von data frame), ein generischer Name, dem Sie in Beispielen immer mal wieder begenen werden. Andere geläufige Namen sind dat oder data.\n\n# Erstellt den Datensatz df, der 3 Variablen enthält\n\ndf &lt;- data.frame(var1 = zahlen, var2 = zahlenAnders, var3 = zahlenAnders/zahlen)\n\nWenn wir nun den Namen unseres Datensatzes eingeben und die entsprechende Zeile im Skript ausführen, wird uns die Tabelle angezeigt:\n\n# zeigt df an\n\ndf\n\n   var1 var2       var3\n1    10    1  0.1000000\n2     9    2  0.2222222\n3     8    3  0.3750000\n4     7    4  0.5714286\n5     6    5  0.8333333\n6     5    6  1.2000000\n7     4    7  1.7500000\n8     3    8  2.6666667\n9     2    9  4.5000000\n10    1   10 10.0000000\n\n\n\n\n2.2.3 Elemente von Datensätzen\nDadurch, dass Datensätze Zeilen und Spalten haben, sind sie zweidimensional. Die Spalten können Sie so ansprechen, wie wir es schon mit der benannten Liste oben gemacht haben (wasBisherWirklichGeschah), sprich mit einem $-Zeichen gefolgt vom Namen:\n\n# zeigt die erste Variable in df an\n\ndf$var1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nAb und zu kann es auch vorkommen, dass Sie eine bestimmte Zeile ansprechen wollen. Dazu können wir wieder Indizes benutzen, allerdings etwas anders als zuvor. Zum Beispiel liefert der Befehl df[1] dasselbe Ergebnis wie df$var1, nur etwas anders dargestellt.\n\n# zeigt jeweils die erste Variable in df an\n\ndf[1]\n\n   var1\n1    10\n2     9\n3     8\n4     7\n5     6\n6     5\n7     4\n8     3\n9     2\n10    1\n\ndf$var1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nEinzelne Zeilen können wir ansprechen, indem wir hinter die Zahl im Index ein Komma schreiben. df[1,] Wir sagen R damit, dass wir am ersten Element der ersten Dimension interessiert sind, die immer links vom Komma steht.\n\n# zeigt die erste Zeile in df an\n\ndf[1,]\n\n  var1 var2 var3\n1   10    1  0.1\n\n\nWir können auch rechts vom Komma eine Zahl ergänzen, z.B. wenn wir nur den dritten Wert aus der zehnten Zeile sehen wollen:\n\n# zeigt den Wert aus Zeile 10, Spalte 3 in df an\n\ndf[10,3]\n\n[1] 10\n\n\n\n\n2.2.4 Datensätze laden\nAufbauend auf diesen Grundlagen könnten Sie sich schon einen ganz guten Überblick über einen Datensatz machen. Aber: Woher bekommen Sie eigentlich Daten und wie werden Daten in R eingelesen? Im weiteren Verlauf dieses Kurses werden mit Daten arbeiten, die hier am Seminar für Medien- und Kommunikationswissenschaften entstanden sind. Im späteren Verlauf Ihres Studiums werden Sie dann mit Ihren eigenen Daten arbeiten. Das Einlesen in R ist relativ einfach. Sie brauchen dazu nur einen Datensatz und müssen wissen, wo auf Ihrem System er gespeichert ist. Am einfachsten ist es, wenn Sie die Daten im selben Ordner ablegen, wie Ihr R-Projekt. Damit Sie nicht den Überblick verlieren, ist es sinnvoll, zunächst einen Unterordner anzulegen, in dem Sie die Daten ablegen können.\nHier laden wir mit der read.csv()-Funktion einen Datensatz, der von Prof. Dogruel erhoben wurde. Es handelt sich dabei um eine Befragung zur Nutzung von Lokalmedien von Menschen aus Thüringen und Rheinland-Pfalz. Sie finden den Datensatz sowie ein zugehöriges Codebook bei Moodle. Letzteres enthält Informationen über die einzelnen Spalten im Datensatz.\n\n# Lädt den Datensatz \"lokalkommunikation\" und speichert ihn als Objekt namens \"df_lokal\"\n\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\nMit diesem Datensatz werden wir vorerst weiterarbeiten. Im weiteren Verlauf des Kurses werden aber noch weitere Daten dazukommen. Zunächst benötigen wir aber noch ein paar Basics zur Arbeit in R: Grundwissen über sogenannte Funktionen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#funktionen",
    "href": "Objekte, Daten, Funktionen.html#funktionen",
    "title": "2  Objekte, Daten, Funktionen",
    "section": "2.3 Funktionen",
    "text": "2.3 Funktionen\nFast alle Aufgaben in R lassen sich mit Hilfe von Funktionen lösen. Einige haben Sie in den vorherigen Abschnitten bereits kennengelernt, z.B. c() und list(). In diesem Abschnitt werden Sie einige weitere kennenlernen, Sie sollen aber vor allem lernen, wie Funktionen eigentlich funktionieren.\n\n2.3.1 Argumente\nDas wichtigste Konzept, das Sie dazu verstehen müssen, sind die sogenannten Argumente. Damit sind Informationen gemeint, die wir einer Funktion übergeben und mit denen sie arbeitet. Argumente werden in Klammern hinter dem Namen der Funktion aufgeführt. Als wir oben die c()-Funktion genutzt haben, waren dementsprechend die Zahlen, die wir in die Klammern geschrieben haben die Argumente. Und als Sie die Liste erstellt haben, haben Sie die vorher angelegten Objekte als Argumente übergeben.\nBeides waren relativ simple Fälle, die Ihnen im R-Alltag aber immer wieder begenen werden, denn die allermeisten Funktionen benötigen ein Objekt, mit dem sie arbeiten können. Durch andere Argumente können wir bestimmen, wie die Funktion genau arbeiten soll. Im weiteren Verlauf dieses Kapitels und in den kommenden Wochen werden wir einige solcher Argumente kennenlernen. Zunächst genügt es, festzuhalten, dass Funktionen mit Argumenten darüber informiert werden, an welchem Objekt sie ihre Aufgabe ausüben sollen und ggf., was sie dabei zu beachten haben.\n\n\n2.3.2 Rückgabe\nEin weiteres wichtigtes Konzept ist die Rückgabe von Funktionen. Oder anders gesagt: ihr Ergebnis. In der Regel empfielt es sich, Funktionen nicht einfach nur auszuführen, sondern das Ergebnis in einem neuen Objekt zu speichern. Der Vorteil davon ist, dass Sie dann mit dem Objekt weiterarbeiten können, ohne jedesmal wieder die Funktion aufrufen zu müssen. Das wird besonders an der read.csv()-Funktion deutlich, die wir oben genutzt haben, um den Datensatz zu laden. Nur so können wir überhaupt sinnvoll damit weiterarbeiten.\n\n\n\n\n\n\nHilfe für Funktionen\n\n\n\nWenn Sie einmal nicht wissen, wie eine Funktion funktioniert oder Sie z.B. wissen wollen, welche Argumente eine Funktion benötigt oder was sie zurückgibt, können Sie ganz einfach Hilfe erhalten. Dazu geben Sie einfach ein ? gefolgt vom Namen der Funktion ein, z.B. ?read.csv(). Im Bereich unten rechts zeigt R Ihnen dann die Dokumentation der Funktion an.\n\n\n\n\n2.3.3 Beispiel - Erstellen einer Häufigkeitstabelle\nDie oben genannten Konzepte schauen wir uns nun anhand der table()-Funktion an. Damit können wir - wie der Name vermuten lässt - eine Tabelle erstellen. Der Datensatz df_lokal enthält eine Spalte, die das Geschlecht der Befragten angibt (A602). Der Wert 1 steht für “männlich”, 2 für “weiblich”, 3 für “divers/non-binär” und 4 für “keine Angabe”, eine sogenannte Ausweichkategorie. Wenn wir diese Spalte an die table()-Funktion übergeben, zeigt R uns in der Konsole eine Häufigkeitstabelle an. Wir erfahren also, wie häufig jede Antwort im Datensatz vorkommt.\n\n# Erstellt eine Häufigkeitstabelle der Geschlechtsabfrage\n\ntable(df_lokal$A602)\n\n\n  1   2   3   4 \n813 996   7  18 \n\n\nEs ist etwas mühselig, die Werte gedanklich immer wieder neu zuordnen. Um dies zu vermeiden, können wir die factor()-Funktion benutzen. Diese wandelt einen Vektor (die Spalte A602) in einen Faktor mit beschrifteten Werten um. Faktor bedeutet in diesem Kontext, dass wir wenige distinkte Werte haben. Es handelt sich um eine sogenannte kategorische Variable. Keine Sorge, darüber werden wir in den kommenden Wochen noch mehr reden.\nFür die factor()-Funktion müssen wir neben der Spalte auch das labels-Argument nuzten, also die Beschriftung festlegen. Die Rückgabe der Funktion ist ein Vektor, der genauso lang ist, wie unser Ausgangsvektor (die Spalte A602), aber beschriftete Werte hat. Das können wir nutzen, um uns Arbeit zu sparen. Statt die Rückgabe der Funktion erst in einem neuen Objekt zu speichern, können wir factor() direkt in der table()-Funktion aufrufen.\n\n# Erstellt eine Häufigkeitstabelle der Geschlechtsabfrage, die vorher in einen beschrifteten Faktor umgewandelt wird\n\ntable(factor(df_lokal$A602, labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\")))\n\n\n    männlich     weiblich       divers keine Angabe \n         813          996            7           18 \n\n\nTatsächlich gibt es kein Limit, wie viele Funktionen wir innerhalb von Funktionen aufrufen können. Beispielsweise können wir die prop.table()-Funktion nutzen, um den Anteil der jeweiligen Geschlechter in der Stichprobe auszurechnen.\n\n# Erstellt eine Tabelle der relativen Häufigkeiten der Geschlechtsabfrage, die vorher in einen beschrifteten Faktor umgewandelt wird\n\nprop.table(table(factor(df_lokal$A602, labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))\n\n\n    männlich     weiblich       divers keine Angabe \n 0.443293348  0.543075245  0.003816794  0.009814613 \n\n\nUm das Ergebnis als Prozentwert zu lesen, können wir es mit 100 multiplizieren.\n\n# Multipliziert die relativen Häufigkeiten mit 100, um Prozentwerte zu erhalten\n\nprop.table(table(factor(df_lokal$A602, labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))*100\n\n\n    männlich     weiblich       divers keine Angabe \n  44.3293348   54.3075245    0.3816794    0.9814613 \n\n\nUnd um das Ergebnis noch besser lesbar zu machen, können wir die round()-Funktion nutzen, um das Ergebnis zu runden. Das digits-Argument gibt dabei die Anzahl der Nachkommastellen an.\n\n# Rundet die Prozentwerte auf 2 Nachkommastellen\n\nround(prop.table(table(factor(df_lokal$A602, labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))*100, digits = 2)\n\n\n    männlich     weiblich       divers keine Angabe \n       44.33        54.31         0.38         0.98 \n\n\n\n\n\n\n\n\nTip\n\n\n\nÜbrigens: Funktionen erwarten Argumente in einer festen Reihenfolge, die Sie mit der Hilfsfunktion (? gefolgt vom Namen der Funktion) erfahren können. Solange wir die Argumente in dieser Reihenfolge nuzten, müssen wir sie nicht benennen. Im vorherigen Befehl können wir z.B. das digits = einfach weglassen und erhalten dasselbe Ergebnis.\n\n# Rundet die Prozentwerte auf 2 Nachkommastellen, lässt aber den Namen des digits-Arguments weg.\n\nround(prop.table(table(factor(df_lokal$A602, labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\"))))*100, 2)\n\n\n    männlich     weiblich       divers keine Angabe \n       44.33        54.31         0.38         0.98 \n\n\n\n\n\n\n2.3.4 Pipes\nDas Verschachteln von Funktionen im Beispiel oben funktioniert zwar gut, wird aber schnell schwer nachvollziehbar. Man sagt auch, dass der Code nicht sonderlich lesbar ist. Um diesem Problem zu begegnen, können wir sogenannte Pipes (im Sinne von Pipeline) verwenden. Dazu nutzen wir den |&gt; Operator. Die Funktionsweise ist zugegebenermaßen etwas gewöhnungsbedürftig, mit etwas Übung erleichtert er unser Leben aber sehr. Pipes nehmen ein Objekt, das links von ihnen steht und übergeben es als erstes Argument in eine Funktion, die rechts davon bzw. in der Regel in einer neuen Zeile darunter steht. Wenn wir einen Ausdruck wie im Beispiel mit der Tabelle mit Pipes replizieren wollen, gehen wir von innen nach außen vor. Schauen wir uns das mal an, indem wir zunächst die Spalte A602 in einen Faktor umwandeln. Dazu übergeben wir die Spalte mit dem |&gt; Operator an die factor()-Funktion. R erkennt automatisch, dass das Objekt (also die Spalte) als erstes Argument genutzt werden muss. Wir müssen also nur das labels-Argument ergänzen. Vorsicht, da wir das Ergebnis nicht in einem neuen Objekt speichern, wird es in der Konsole angezeigt und ist sehr lang!\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\")) \n\n   [1] weiblich     männlich     männlich     männlich     männlich    \n   [6] männlich     männlich     weiblich     weiblich     weiblich    \n  [11] männlich     weiblich     weiblich     männlich     männlich    \n  [16] männlich     weiblich     männlich     männlich     männlich    \n  [21] männlich     weiblich     männlich     männlich     männlich    \n  [26] weiblich     weiblich     männlich     männlich     männlich    \n  [31] weiblich     männlich     männlich     männlich     weiblich    \n  [36] männlich     männlich     weiblich     männlich     männlich    \n  [41] männlich     weiblich     männlich     männlich     weiblich    \n  [46] männlich     weiblich     männlich     männlich     männlich    \n  [51] weiblich     weiblich     weiblich     männlich     weiblich    \n  [56] männlich     weiblich     weiblich     männlich     männlich    \n  [61] männlich     weiblich     männlich     männlich     männlich    \n  [66] weiblich     weiblich     divers       weiblich     weiblich    \n  [71] weiblich     männlich     männlich     weiblich     männlich    \n  [76] weiblich     weiblich     weiblich     weiblich     weiblich    \n  [81] weiblich     männlich     männlich     weiblich     männlich    \n  [86] weiblich     männlich     divers       männlich     weiblich    \n  [91] weiblich     weiblich     weiblich     weiblich     weiblich    \n  [96] weiblich     weiblich     weiblich     weiblich     männlich    \n [101] männlich     männlich     männlich     männlich     männlich    \n [106] weiblich     weiblich     weiblich     männlich     männlich    \n [111] männlich     weiblich     weiblich     weiblich     männlich    \n [116] männlich     weiblich     weiblich     weiblich     männlich    \n [121] weiblich     männlich     männlich     weiblich     männlich    \n [126] männlich     weiblich     männlich     weiblich     weiblich    \n [131] weiblich     männlich     weiblich     männlich     männlich    \n [136] weiblich     weiblich     männlich     weiblich     männlich    \n [141] weiblich     männlich     weiblich     weiblich     weiblich    \n [146] männlich     männlich     weiblich     weiblich     weiblich    \n [151] männlich     weiblich     männlich     männlich     weiblich    \n [156] männlich     männlich     weiblich     weiblich     weiblich    \n [161] weiblich     männlich     weiblich     weiblich     &lt;NA&gt;        \n [166] männlich     männlich     weiblich     männlich     männlich    \n [171] divers       männlich     männlich     weiblich     männlich    \n [176] weiblich     weiblich     weiblich     weiblich     weiblich    \n [181] weiblich     weiblich     männlich     weiblich     weiblich    \n [186] männlich     divers       männlich     weiblich     weiblich    \n [191] männlich     weiblich     weiblich     weiblich     männlich    \n [196] weiblich     männlich     männlich     männlich     weiblich    \n [201] männlich     weiblich     weiblich     männlich     männlich    \n [206] weiblich     weiblich     männlich     männlich     weiblich    \n [211] männlich     weiblich     männlich     weiblich     weiblich    \n [216] weiblich     männlich     männlich     weiblich     männlich    \n [221] männlich     weiblich     weiblich     weiblich     männlich    \n [226] weiblich     weiblich     männlich     männlich     weiblich    \n [231] weiblich     weiblich     männlich     weiblich     weiblich    \n [236] weiblich     weiblich     weiblich     weiblich     weiblich    \n [241] weiblich     männlich     weiblich     weiblich     männlich    \n [246] männlich     männlich     weiblich     weiblich     weiblich    \n [251] weiblich     männlich     weiblich     weiblich     weiblich    \n [256] männlich     weiblich     weiblich     weiblich     weiblich    \n [261] weiblich     männlich     männlich     weiblich     männlich    \n [266] weiblich     männlich     männlich     weiblich     weiblich    \n [271] männlich     weiblich     männlich     weiblich     weiblich    \n [276] weiblich     männlich     männlich     weiblich     weiblich    \n [281] weiblich     weiblich     männlich     männlich     männlich    \n [286] weiblich     männlich     weiblich     männlich     männlich    \n [291] weiblich     männlich     weiblich     weiblich     männlich    \n [296] weiblich     männlich     weiblich     männlich     männlich    \n [301] männlich     männlich     weiblich     weiblich     männlich    \n [306] männlich     männlich     weiblich     weiblich     weiblich    \n [311] weiblich     weiblich     männlich     weiblich     weiblich    \n [316] weiblich     männlich     weiblich     männlich     männlich    \n [321] weiblich     männlich     weiblich     weiblich     männlich    \n [326] weiblich     weiblich     weiblich     weiblich     weiblich    \n [331] weiblich     weiblich     weiblich     weiblich     männlich    \n [336] weiblich     weiblich     männlich     männlich     weiblich    \n [341] weiblich     männlich     weiblich     weiblich     weiblich    \n [346] weiblich     weiblich     weiblich     männlich     weiblich    \n [351] weiblich     weiblich     männlich     weiblich     männlich    \n [356] weiblich     männlich     männlich     männlich     weiblich    \n [361] männlich     weiblich     weiblich     weiblich     weiblich    \n [366] weiblich     weiblich     weiblich     weiblich     männlich    \n [371] weiblich     männlich     weiblich     männlich     weiblich    \n [376] männlich     weiblich     weiblich     männlich     männlich    \n [381] weiblich     weiblich     weiblich     weiblich     männlich    \n [386] weiblich     weiblich     männlich     männlich     männlich    \n [391] weiblich     männlich     weiblich     weiblich     weiblich    \n [396] weiblich     weiblich     männlich     weiblich     männlich    \n [401] weiblich     männlich     männlich     weiblich     weiblich    \n [406] weiblich     männlich     männlich     männlich     männlich    \n [411] weiblich     männlich     weiblich     männlich     männlich    \n [416] männlich     weiblich     weiblich     weiblich     weiblich    \n [421] männlich     männlich     weiblich     weiblich     weiblich    \n [426] männlich     weiblich     weiblich     weiblich     weiblich    \n [431] männlich     männlich     weiblich     männlich     weiblich    \n [436] männlich     männlich     weiblich     weiblich     männlich    \n [441] weiblich     männlich     männlich     männlich     männlich    \n [446] weiblich     weiblich     männlich     männlich     weiblich    \n [451] männlich     männlich     weiblich     männlich     männlich    \n [456] weiblich     weiblich     weiblich     weiblich     männlich    \n [461] weiblich     weiblich     weiblich     weiblich     männlich    \n [466] weiblich     weiblich     weiblich     männlich     weiblich    \n [471] männlich     weiblich     männlich     weiblich     weiblich    \n [476] weiblich     weiblich     weiblich     weiblich     weiblich    \n [481] weiblich     weiblich     weiblich     männlich     weiblich    \n [486] weiblich     weiblich     männlich     weiblich     weiblich    \n [491] weiblich     weiblich     männlich     weiblich     divers      \n [496] weiblich     weiblich     männlich     weiblich     weiblich    \n [501] weiblich     weiblich     männlich     weiblich     weiblich    \n [506] weiblich     männlich     weiblich     männlich     weiblich    \n [511] weiblich     männlich     männlich     weiblich     weiblich    \n [516] weiblich     männlich     weiblich     weiblich     männlich    \n [521] weiblich     weiblich     weiblich     weiblich     weiblich    \n [526] weiblich     weiblich     weiblich     männlich     weiblich    \n [531] männlich     weiblich     männlich     männlich     männlich    \n [536] männlich     weiblich     weiblich     weiblich     weiblich    \n [541] männlich     weiblich     männlich     weiblich     weiblich    \n [546] weiblich     männlich     männlich     &lt;NA&gt;         keine Angabe\n [551] männlich     weiblich     männlich     weiblich     männlich    \n [556] weiblich     weiblich     männlich     weiblich     weiblich    \n [561] männlich     weiblich     männlich     weiblich     männlich    \n [566] männlich     weiblich     männlich     weiblich     weiblich    \n [571] weiblich     männlich     männlich     weiblich     weiblich    \n [576] männlich     weiblich     weiblich     männlich     weiblich    \n [581] weiblich     weiblich     männlich     männlich     weiblich    \n [586] männlich     weiblich     männlich     weiblich     weiblich    \n [591] weiblich     weiblich     männlich     weiblich     männlich    \n [596] männlich     weiblich     weiblich     weiblich     männlich    \n [601] weiblich     weiblich     männlich     weiblich     weiblich    \n [606] weiblich     weiblich     weiblich     weiblich     weiblich    \n [611] männlich     weiblich     männlich     weiblich     männlich    \n [616] männlich     weiblich     weiblich     männlich     männlich    \n [621] weiblich     männlich     keine Angabe weiblich     männlich    \n [626] männlich     weiblich     männlich     männlich     männlich    \n [631] männlich     weiblich     weiblich     weiblich     männlich    \n [636] weiblich     weiblich     weiblich     weiblich     weiblich    \n [641] männlich     weiblich     männlich     weiblich     weiblich    \n [646] weiblich     weiblich     weiblich     weiblich     männlich    \n [651] männlich     weiblich     männlich     männlich     weiblich    \n [656] weiblich     weiblich     weiblich     weiblich     männlich    \n [661] weiblich     weiblich     weiblich     weiblich     weiblich    \n [666] männlich     männlich     weiblich     weiblich     männlich    \n [671] weiblich     weiblich     weiblich     weiblich     weiblich    \n [676] weiblich     weiblich     männlich     männlich     weiblich    \n [681] weiblich     männlich     weiblich     männlich     weiblich    \n [686] weiblich     weiblich     männlich     weiblich     männlich    \n [691] weiblich     weiblich     weiblich     weiblich     männlich    \n [696] weiblich     männlich     weiblich     weiblich     männlich    \n [701] weiblich     weiblich     weiblich     männlich     männlich    \n [706] weiblich     weiblich     männlich     männlich     männlich    \n [711] männlich     männlich     weiblich     männlich     weiblich    \n [716] weiblich     weiblich     männlich     männlich     männlich    \n [721] weiblich     weiblich     weiblich     männlich     männlich    \n [726] männlich     weiblich     weiblich     männlich     männlich    \n [731] männlich     weiblich     weiblich     weiblich     weiblich    \n [736] männlich     weiblich     weiblich     weiblich     weiblich    \n [741] männlich     weiblich     weiblich     weiblich     weiblich    \n [746] weiblich     männlich     &lt;NA&gt;         männlich     weiblich    \n [751] weiblich     weiblich     weiblich     weiblich     weiblich    \n [756] weiblich     männlich     weiblich     männlich     weiblich    \n [761] weiblich     männlich     männlich     männlich     weiblich    \n [766] weiblich     weiblich     weiblich     weiblich     weiblich    \n [771] weiblich     weiblich     männlich     männlich     weiblich    \n [776] männlich     weiblich     weiblich     männlich     männlich    \n [781] weiblich     weiblich     männlich     weiblich     männlich    \n [786] weiblich     divers       weiblich     weiblich     weiblich    \n [791] weiblich     weiblich     männlich     weiblich     männlich    \n [796] weiblich     weiblich     männlich     weiblich     männlich    \n [801] männlich     männlich     männlich     &lt;NA&gt;         weiblich    \n [806] keine Angabe männlich     männlich     männlich     männlich    \n [811] weiblich     weiblich     weiblich     weiblich     männlich    \n [816] männlich     männlich     männlich     männlich     weiblich    \n [821] weiblich     männlich     weiblich     weiblich     weiblich    \n [826] weiblich     männlich     weiblich     weiblich     männlich    \n [831] weiblich     weiblich     männlich     weiblich     männlich    \n [836] weiblich     weiblich     weiblich     männlich     weiblich    \n [841] weiblich     weiblich     weiblich     weiblich     keine Angabe\n [846] weiblich     weiblich     männlich     männlich     weiblich    \n [851] weiblich     weiblich     weiblich     männlich     keine Angabe\n [856] keine Angabe weiblich     männlich     weiblich     männlich    \n [861] männlich     weiblich     weiblich     männlich     weiblich    \n [866] weiblich     weiblich     männlich     weiblich     weiblich    \n [871] männlich     männlich     weiblich     männlich     männlich    \n [876] weiblich     weiblich     männlich     weiblich     weiblich    \n [881] männlich     weiblich     männlich     weiblich     männlich    \n [886] männlich     männlich     männlich     weiblich     männlich    \n [891] weiblich     weiblich     männlich     männlich     weiblich    \n [896] weiblich     weiblich     weiblich     weiblich     weiblich    \n [901] männlich     weiblich     weiblich     weiblich     männlich    \n [906] weiblich     weiblich     weiblich     weiblich     männlich    \n [911] weiblich     männlich     weiblich     weiblich     weiblich    \n [916] männlich     weiblich     weiblich     männlich     männlich    \n [921] männlich     männlich     männlich     weiblich     männlich    \n [926] männlich     weiblich     weiblich     weiblich     männlich    \n [931] männlich     weiblich     männlich     weiblich     männlich    \n [936] weiblich     weiblich     weiblich     weiblich     männlich    \n [941] männlich     weiblich     weiblich     weiblich     männlich    \n [946] männlich     keine Angabe weiblich     männlich     männlich    \n [951] weiblich     männlich     weiblich     weiblich     &lt;NA&gt;        \n [956] männlich     weiblich     weiblich     weiblich     männlich    \n [961] männlich     männlich     weiblich     weiblich     männlich    \n [966] weiblich     männlich     weiblich     männlich     männlich    \n [971] weiblich     männlich     männlich     männlich     männlich    \n [976] weiblich     weiblich     weiblich     weiblich     weiblich    \n [981] männlich     weiblich     weiblich     männlich     weiblich    \n [986] männlich     männlich     weiblich     männlich     männlich    \n [991] männlich     weiblich     weiblich     männlich     männlich    \n [996] männlich     weiblich     weiblich     weiblich     weiblich    \n[1001] &lt;NA&gt;         weiblich     weiblich     weiblich     weiblich    \n[1006] weiblich     weiblich     weiblich     männlich     männlich    \n[1011] weiblich     weiblich     männlich     weiblich     weiblich    \n[1016] weiblich     weiblich     männlich     männlich     weiblich    \n[1021] männlich     männlich     weiblich     weiblich     männlich    \n[1026] weiblich     männlich     männlich     männlich     männlich    \n[1031] männlich     weiblich     weiblich     männlich     männlich    \n[1036] weiblich     weiblich     weiblich     männlich     weiblich    \n[1041] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1046] männlich     weiblich     weiblich     weiblich     weiblich    \n[1051] männlich     männlich     männlich     männlich     männlich    \n[1056] weiblich     weiblich     männlich     weiblich     weiblich    \n[1061] männlich     weiblich     weiblich     männlich     männlich    \n[1066] weiblich     weiblich     weiblich     weiblich     männlich    \n[1071] männlich     männlich     weiblich     weiblich     weiblich    \n[1076] männlich     weiblich     weiblich     weiblich     männlich    \n[1081] weiblich     männlich     weiblich     weiblich     männlich    \n[1086] männlich     weiblich     männlich     männlich     weiblich    \n[1091] weiblich     männlich     weiblich     männlich     weiblich    \n[1096] &lt;NA&gt;         weiblich     weiblich     weiblich     weiblich    \n[1101] weiblich     männlich     weiblich     männlich     weiblich    \n[1106] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1111] männlich     männlich     weiblich     weiblich     weiblich    \n[1116] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1121] weiblich     männlich     weiblich     weiblich     männlich    \n[1126] weiblich     weiblich     männlich     weiblich     männlich    \n[1131] männlich     männlich     männlich     weiblich     männlich    \n[1136] männlich     weiblich     männlich     männlich     männlich    \n[1141] weiblich     männlich     männlich     weiblich     keine Angabe\n[1146] männlich     männlich     männlich     männlich     männlich    \n[1151] männlich     weiblich     weiblich     männlich     weiblich    \n[1156] männlich     weiblich     weiblich     weiblich     weiblich    \n[1161] weiblich     männlich     männlich     keine Angabe männlich    \n[1166] weiblich     männlich     weiblich     weiblich     männlich    \n[1171] weiblich     weiblich     männlich     männlich     männlich    \n[1176] männlich     weiblich     männlich     weiblich     weiblich    \n[1181] männlich     männlich     männlich     weiblich     weiblich    \n[1186] weiblich     weiblich     keine Angabe weiblich     männlich    \n[1191] männlich     weiblich     männlich     männlich     weiblich    \n[1196] männlich     männlich     männlich     männlich     männlich    \n[1201] weiblich     männlich     weiblich     männlich     keine Angabe\n[1206] weiblich     männlich     weiblich     weiblich     weiblich    \n[1211] männlich     weiblich     männlich     männlich     weiblich    \n[1216] weiblich     weiblich     männlich     weiblich     männlich    \n[1221] männlich     weiblich     weiblich     weiblich     männlich    \n[1226] weiblich     männlich     weiblich     männlich     weiblich    \n[1231] weiblich     männlich     männlich     männlich     weiblich    \n[1236] weiblich     männlich     weiblich     männlich     weiblich    \n[1241] männlich     weiblich     männlich     männlich     männlich    \n[1246] männlich     weiblich     weiblich     männlich     männlich    \n[1251] weiblich     weiblich     männlich     weiblich     männlich    \n[1256] weiblich     weiblich     weiblich     &lt;NA&gt;         weiblich    \n[1261] weiblich     weiblich     männlich     männlich     männlich    \n[1266] weiblich     männlich     männlich     männlich     weiblich    \n[1271] männlich     männlich     männlich     weiblich     weiblich    \n[1276] keine Angabe männlich     männlich     männlich     männlich    \n[1281] weiblich     männlich     weiblich     weiblich     männlich    \n[1286] männlich     weiblich     männlich     &lt;NA&gt;         weiblich    \n[1291] weiblich     männlich     weiblich     männlich     männlich    \n[1296] weiblich     männlich     weiblich     männlich     weiblich    \n[1301] männlich     männlich     weiblich     weiblich     männlich    \n[1306] weiblich     männlich     männlich     männlich     weiblich    \n[1311] weiblich     männlich     weiblich     männlich     weiblich    \n[1316] männlich     weiblich     weiblich     männlich     weiblich    \n[1321] weiblich     weiblich     männlich     weiblich     weiblich    \n[1326] männlich     weiblich     weiblich     männlich     weiblich    \n[1331] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1336] weiblich     weiblich     weiblich     weiblich     männlich    \n[1341] weiblich     weiblich     weiblich     männlich     männlich    \n[1346] weiblich     männlich     weiblich     männlich     männlich    \n[1351] weiblich     weiblich     männlich     männlich     männlich    \n[1356] weiblich     männlich     weiblich     männlich     männlich    \n[1361] weiblich     weiblich     weiblich     weiblich     männlich    \n[1366] männlich     weiblich     männlich     männlich     männlich    \n[1371] weiblich     weiblich     weiblich     weiblich     männlich    \n[1376] weiblich     männlich     männlich     weiblich     weiblich    \n[1381] männlich     männlich     weiblich     männlich     weiblich    \n[1386] männlich     männlich     keine Angabe weiblich     männlich    \n[1391] weiblich     weiblich     männlich     weiblich     männlich    \n[1396] weiblich     männlich     weiblich     weiblich     weiblich    \n[1401] männlich     &lt;NA&gt;         männlich     männlich     männlich    \n[1406] männlich     weiblich     weiblich     männlich     weiblich    \n[1411] weiblich     weiblich     männlich     männlich     männlich    \n[1416] männlich     männlich     männlich     weiblich     männlich    \n[1421] männlich     weiblich     weiblich     männlich     männlich    \n[1426] männlich     männlich     männlich     männlich     männlich    \n[1431] weiblich     männlich     weiblich     männlich     weiblich    \n[1436] weiblich     weiblich     weiblich     weiblich     männlich    \n[1441] weiblich     männlich     männlich     männlich     männlich    \n[1446] männlich     weiblich     weiblich     männlich     männlich    \n[1451] weiblich     männlich     männlich     weiblich     männlich    \n[1456] männlich     männlich     &lt;NA&gt;         weiblich     männlich    \n[1461] männlich     weiblich     weiblich     männlich     männlich    \n[1466] männlich     weiblich     weiblich     männlich     männlich    \n[1471] weiblich     keine Angabe männlich     weiblich     weiblich    \n[1476] weiblich     keine Angabe weiblich     weiblich     männlich    \n[1481] weiblich     weiblich     männlich     männlich     weiblich    \n[1486] männlich     weiblich     weiblich     männlich     männlich    \n[1491] weiblich     männlich     männlich     männlich     weiblich    \n[1496] weiblich     männlich     männlich     weiblich     männlich    \n[1501] weiblich     männlich     männlich     weiblich     männlich    \n[1506] männlich     männlich     männlich     weiblich     männlich    \n[1511] männlich     weiblich     weiblich     weiblich     männlich    \n[1516] männlich     männlich     männlich     weiblich     männlich    \n[1521] weiblich     weiblich     weiblich     männlich     männlich    \n[1526] männlich     männlich     weiblich     männlich     weiblich    \n[1531] weiblich     männlich     männlich     männlich     weiblich    \n[1536] weiblich     männlich     männlich     männlich     männlich    \n[1541] männlich     weiblich     männlich     männlich     männlich    \n[1546] weiblich     weiblich     männlich     männlich     männlich    \n[1551] männlich     weiblich     weiblich     weiblich     weiblich    \n[1556] männlich     weiblich     weiblich     weiblich     weiblich    \n[1561] männlich     männlich     weiblich     weiblich     weiblich    \n[1566] männlich     männlich     weiblich     weiblich     weiblich    \n[1571] männlich     männlich     männlich     männlich     weiblich    \n[1576] weiblich     weiblich     weiblich     weiblich     männlich    \n[1581] männlich     weiblich     männlich     männlich     weiblich    \n[1586] weiblich     &lt;NA&gt;         männlich     weiblich     weiblich    \n[1591] weiblich     männlich     männlich     weiblich     männlich    \n[1596] weiblich     männlich     weiblich     männlich     divers      \n[1601] weiblich     männlich     weiblich     männlich     weiblich    \n[1606] männlich     weiblich     weiblich     männlich     weiblich    \n[1611] weiblich     weiblich     weiblich     männlich     weiblich    \n[1616] männlich     weiblich     weiblich     weiblich     männlich    \n[1621] männlich     weiblich     männlich     männlich     männlich    \n[1626] weiblich     männlich     männlich     weiblich     männlich    \n[1631] weiblich     männlich     weiblich     männlich     männlich    \n[1636] weiblich     weiblich     weiblich     männlich     männlich    \n[1641] weiblich     männlich     weiblich     männlich     männlich    \n[1646] männlich     weiblich     weiblich     männlich     männlich    \n[1651] männlich     männlich     weiblich     weiblich     weiblich    \n[1656] männlich     weiblich     männlich     weiblich     männlich    \n[1661] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1666] weiblich     weiblich     weiblich     männlich     weiblich    \n[1671] männlich     weiblich     männlich     weiblich     weiblich    \n[1676] männlich     männlich     männlich     weiblich     männlich    \n[1681] männlich     männlich     männlich     weiblich     weiblich    \n[1686] männlich     männlich     männlich     weiblich     männlich    \n[1691] weiblich     männlich     männlich     männlich     männlich    \n[1696] männlich     weiblich     weiblich     männlich     männlich    \n[1701] männlich     männlich     männlich     weiblich     weiblich    \n[1706] männlich     weiblich     männlich     weiblich     männlich    \n[1711] männlich     weiblich     weiblich     männlich     weiblich    \n[1716] männlich     weiblich     männlich     männlich     männlich    \n[1721] keine Angabe männlich     männlich     weiblich     männlich    \n[1726] männlich     männlich     weiblich     keine Angabe männlich    \n[1731] männlich     weiblich     männlich     männlich     weiblich    \n[1736] männlich     männlich     männlich     männlich     weiblich    \n[1741] weiblich     männlich     männlich     weiblich     weiblich    \n[1746] weiblich     weiblich     männlich     weiblich     männlich    \n[1751] männlich     weiblich     weiblich     weiblich     weiblich    \n[1756] männlich     männlich     männlich     weiblich     weiblich    \n[1761] männlich     weiblich     weiblich     weiblich     männlich    \n[1766] männlich     männlich     weiblich     weiblich     männlich    \n[1771] männlich     weiblich     weiblich     männlich     weiblich    \n[1776] weiblich     männlich     weiblich     männlich     weiblich    \n[1781] weiblich     weiblich     keine Angabe weiblich     männlich    \n[1786] weiblich     männlich     männlich     männlich     männlich    \n[1791] männlich     männlich     weiblich     weiblich     weiblich    \n[1796] männlich     männlich     weiblich     männlich     männlich    \n[1801] weiblich     weiblich     männlich     männlich     männlich    \n[1806] weiblich     männlich     weiblich     weiblich     weiblich    \n[1811] männlich     weiblich     männlich     männlich     weiblich    \n[1816] weiblich     weiblich     weiblich     weiblich     weiblich    \n[1821] weiblich     männlich     weiblich     weiblich     männlich    \n[1826] weiblich     männlich     weiblich     männlich     männlich    \n[1831] weiblich     weiblich     weiblich     weiblich     männlich    \n[1836] männlich     weiblich     männlich     männlich     männlich    \n[1841] männlich     weiblich     männlich     weiblich     männlich    \n[1846] männlich    \nLevels: männlich weiblich divers keine Angabe\n\n\nIm nächsten Schritt übergeben wir diesen neuen Faktor mit |&gt; an die table()-Funktion, die keine weiteren Argumente benötigt.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und übergibt diesen an die table()-Funktion.\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table()\n\n\n    männlich     weiblich       divers keine Angabe \n         813          996            7           18 \n\n\nDiese Häufigkeitstabelle können wir nun an die prop.table()-Funktion übergeben, um eine Tabelle mit relativen Häufigkeiten zu bekommen.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und übergibt diesen an die table()-Funktion und erstellt dann eine Tabelle mit relativen Häufigkeiten\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table() |&gt;\n  prop.table()\n\n\n    männlich     weiblich       divers keine Angabe \n 0.443293348  0.543075245  0.003816794  0.009814613 \n\n\nAls letztes haben wir oben die Werte dieser Tabelle mit 100 multipliziert und das Ergebnis auf zwei Nachkommastellen gerundet. Wenn wir versuchen, diesen Schritt umzusetzen, sehen wir zwar, dass die Prozentwerte richtig angegeben werden, allerdings funktioniert das Runden nicht. Kurz gesagt liegt das daran, dass R es nicht schafft den Ausdruck prop.table()*100 weiterzuleiten.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und übergibt diesen an die table()-Funktion und erstellt dann eine Tabelle mit relativen Häufigkeiten, die in Prozentwerte umgerechnet werden; das Runden funktioniert nicht\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table() |&gt;\n  prop.table()*100 |&gt;\n  round(2)\n\n\n    männlich     weiblich       divers keine Angabe \n  44.3293348   54.3075245    0.3816794    0.9814613 \n\n\nWir können Abhilfe schaffen, indem wir das Ergebnis der prop.table()-Funktion direkt an die round()-Funktion weitergeben und erst deren Ergebnis runden. Wichtig ist dabei, dass wir erst auf 4 Nachkommastellen runden und diese dann mit 100 multiplizieren, sodass wir am Ende eine Zahl mit 4 Stellen (2 vor und 2 nach dem Komma) bekommen.\n\n# Wandelt die Geschlechtsabfrage in einen beschrifteten Faktor um und übergibt diesen an die table()-Funktion und erstellt dann eine Tabelle mit relativen Häufigkeiten, die in Prozentwerte umgerechnet werden; das Ergebnis wird gerundet\ndf_lokal$A602 |&gt;\n  factor(labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\")) |&gt;\n  table() |&gt;\n  prop.table() |&gt;\n  round(4)*100\n\n\n    männlich     weiblich       divers keine Angabe \n       44.33        54.31         0.38         0.98",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Objekte, Daten, Funktionen.html#footnotes",
    "href": "Objekte, Daten, Funktionen.html#footnotes",
    "title": "2  Objekte, Daten, Funktionen",
    "section": "",
    "text": "In machen Quellen werden Sie statt des Pfeils ein Gleichheitszeichen sehen. Im Prinzip sind die beiden äquivalent. Wir nutzen hier den Pfeil, werden aber später, wenn wir uns mit Funktionen befassen, auch das Gleicheitszeichen verwenden.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Objekte, Daten, Funktionen</span>"
    ]
  },
  {
    "objectID": "Pakete und Datentransformationen.html",
    "href": "Pakete und Datentransformationen.html",
    "title": "3  Pakete und Datentransformationen",
    "section": "",
    "text": "3.1 Pakete\nZwar kann R direkt nach der Installation schon relativ viel, aber gleichzeitig gibt es viele Aufgaben, die wir nur lösen können, indem wir R erweitern. Dazu nutzen wir sogenannte Pakete. Vereinfacht gesagt handelt es sich dabei um Sammlungen von Funktionen. Im Lauf des Kurses werden wir einige Pakete benötigen, die wir entsprechend nach und nach kennenlernen werden. Zunächst schauen wir uns an, wie wir Pakete installieren und laden können.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Pakete und Datentransformationen</span>"
    ]
  },
  {
    "objectID": "Pakete und Datentransformationen.html#pakete",
    "href": "Pakete und Datentransformationen.html#pakete",
    "title": "3  Pakete und Datentransformationen",
    "section": "",
    "text": "3.1.1 Pakete installieren\nUm ein Paket zu installieren, müssen Sie zunächst dessen Namen kennen. Dann haben Sie zwei Möglichkeiten:\n\nSie können die Funktion install.packages() nutzen. Als Argument nimmt die Funktion den Namen mindestens eines Pakets in Anführungszeichen, oder mehrere Pakete durch Kommata getrennt. Für den weiteren Verlauf des Kapitels werden wir das Paket tidyverse nutzen. Damit wir das Paket nicht jedes Mal aufs Neue installieren, wenn wir ein Skript ausführen, können wir die Funktion mit dem folgenden Befehl aufrufen.\n\n# Prüft, ob das Paket \"tidyverse\" installiert ist. Falls nicht, wird es installiert\nif(!require(tidyverse)){\n  install.packages(\"tidyverse\")\n} \n\nLade nötiges Paket: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nDie Funktionsweise ist für Sie nicht entscheidend, aber für den Fall, dass es Sie interessiert, wird sie hier noch kurz erklärt: Wir starten mit einem sogenannten if-Befehl, deren Aufbau immer gleich ist. In der Klammer steht eine Bedingung, die geprüft wird. Sofern sie zutrifft, wird der Teil in der in den geschwungenen Klammern ({}) ausgefführt. Die Bedingung in einem if-Befehl muss immer wahr oder falsch sein, bzw. TRUE oder FALSE zurückgeben. Wird TRUE zurückgegeben, gilt die Bedingung als erfüllt, andernfalls nicht. In diesem Fall wird die Bedingung !require(tidyverse) geprüft. require() ist eine Funktion, die versucht ein Paket zu laden. Falls es aber nicht installiert ist, gibt sie FALSE zurück. Durch das Ausrufezeichen, wird dieser Ausdruck negiert. Etwas das nicht FALSE ist, ist in der R-Logik TRUE. In der Summe bedeutet das also, dass wir erst prüfen, ob das Paket vorhanden ist und falls nicht, wird es installiert.\nAlternativ können Sie im Bereich unten rechts auf den Reiter Packages und dort auf Install klicken.\n\n\n\n\n\n\nAnschließend öffnet sich ein Fenster, in dem Sie den oder die Namen der gewünschten Pakete eintragen können.\n\n\n\n\n\n\n\n3.1.2 Pakete laden\nAuch zum Laden von Paketen haben Sie mehrere Möglichkeiten:\n\nSie können den Befehl von oben nutzen, da die require()-Funktion versucht, das angegebene Paket zu laden. Sofern das Paket bereits installiert ist, wird es einfach nur geladen.\nSie können auch die library()-Funktion verwenden. Auch hier müssen Sie nur den Namen des Pakets als Argument übergeben. Diesmal allerdings ohne Anführungszeichen. Der Unterschied zu require() ist, dass die Funktion eine Fehlermeldung zurückgibt, falls das Paket nicht vorhanden ist.\n\n# Lädt das Paket \"tidyverse\"\nlibrary(tidyverse)\n\nAlterantiv können Sie wieder auf den Reiter Packages unten rechts navigieren, den Namen des Pakets im Suchfeld eingeben und anschließend einen Haken im entsprechenden Feld setzen.\n\n\n\n\n\n\n\n\n3.1.3 Das tidyverse\nIn den beiden vorherigen Abschnitten haben wir das tidyverse-Paket installiert und geladen. Strenggenommen handelt es sich dabei nicht um ein einzelnes Paket, sondern gleich eine ganze Sammlung. Das sehen Sie auch, nachdem Sie das Paket geladen haben. In der Konsole wird uns gleich eine ganze Reihe an Paketen angezeigt, die geladen wurden:\n\n\n\n\n\nSchauen wir uns einmal kurz an, worum es sich bei diesen Paketen handelt:\n\ndplyr ist gewissermaßen das Herzstück des tidyverse. Das Pekt enthält zahlreiche Funktionen, die wir für die Datentransformation benötigen. Sie können damit z.B. neue Variablen berechnen, Datensätze filtern, einzelne Spalten selektieren und vieles mehr. Wir werden das Paket hauptsächlich nutzen, um Daten in ein Format zu bringen, mit dem wir weiterarbeiten können und, um Datensätze deskriptiv auszuwerten.\nforcats erleichtert die Arbeit mit kategorischen Variablen, also z.B. dem Geschlecht der Befragten aus dem letzten Kapitel.\nggplot2 ist ein Paket zum Erstellen von Grafiken. Wir werden es in den kommenden Wochen näher kennenlernen.\nlubridate enthält Funktionen, die das Arbeiten mit Zeit- und Datumsvariablen erleichtern. In diesem Kurs werden wir solchen Daten allerdings nicht begegnen.\npurrr ist eher etwas für fortgeschrittene Programmierer:innen. Es enthält Funktionen, die das Arbeiten anderen R Funktionen optimieren können. Keine Sorge: Wir bleiben in diesem Kurs bei den Basics und werden uns nicht damit befassen.\nreadr ist ein Paket zum Laden von Daten, zum Beispiel enthält es die read_csv()-Funktion als Alternative zur read.csv()-Funktion aus dem letzten Kapitel. Das mag redundant wirken, aber zeigt in erster Linie, dass es in R in der Regel viele verschiedene Möglichkeiten gibt, ein gegebenes Problem zu lösen. Der Grund, warum readr entwickelt wurde ist, dass die enthaltenen Funktionen oftmals schneller sind, als ihre in R enthaltenen Pendants. Allerdings zeigt sich dieser Geschwindigkeitsvorteil hauptsächlich bei sehr großen Datensätzen.\nstringr ist ein Paket, um strings zu manipulieren. Man kann damit z.B. prüfen, ob eine Zeichenfolge bestimmte Zeichen enthält, die wiederum entfernt oder geändert werden können.\ntibble nicht nur der Name des Pakets, sondern auch der Name des Objekttyps, den das Paket erzeugt. Im Prinzip ist die Kernfunktion tibble() eine moderne Version der data.frame()-Funktion aus dem letzten Kapitel.\ntidyr enthält Funktionen, mit denen wir Datensätze bzw. tibbles in ein bestimmtes Format bringen können, das schlicht tidy genannt wird. Dieses Format haben Sie im letzten Kapitel bereits kennengelernt, wenn auch nicht unter diesem Namen. Es bedeutet nicht mehr als die Idee, dass in einem gut strukturierten Datensatz jede Zeile einem Fall und jede Spalte einer Variable entspricht.\n\nDer Vorteil des tidyverse ist, dass Sie immer nur ein Paket laden müssen, um einen umfangreichen Wekrzeugkasten nutzen zu können. Gleichwohl kann das Paket am Anfang aufgrund seines Umfangs etwas abschreckend und unzugänglich wirken. Hier können sogenannte Cheatsheets, also Spickzettel, Abhilfe schaffen. Darauf werden die wichtigsten Funktionen der einzelnen Pakete vorgestellt und erklärt. Für die meisten tidyverse-Pakete finden Sie solche Cheatsheets auf der Webseite von posit, dem Unternehmen, das auch RStudio entwickelt: https://posit.co/resources/cheatsheets/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Pakete und Datentransformationen</span>"
    ]
  },
  {
    "objectID": "Pakete und Datentransformationen.html#datentransformationen",
    "href": "Pakete und Datentransformationen.html#datentransformationen",
    "title": "3  Pakete und Datentransformationen",
    "section": "3.2 Datentransformationen",
    "text": "3.2 Datentransformationen\nMit Hilfe des tidyverse und insbesondere den in dplyr enthaltenen Funktionen können wir Datensätze transformieren. Das ist etwas vereinfacht ausgedrückt, denn eigentlich verbirgt sich hinter der Transformation von Daten und Datensätzen eine Vielzahl von Dingen. Einige davon werden wir uns nun angucken. Ganz konkret das Umbenennen von Spalten, das Hinzufügen von neuen Spalten, das Selektieren von bestimmten Spalten und das Filtern von Fällen, also Zeilen.\n\n3.2.1 Spalten umbenennen\nUm eine oder mehrere Spalten umzubenennen, können wir die rename()-Funktion nutzen. Das Schema ist dabei relativ einfach: neuerName = alterName. In der Praxis sieht das so aus:\nZuerst lesen wir die Daten ein. Falls Sie das Skript aus dem letzten Kapitel nutzen, sollten Sie diesen Befehl schon im Skript haben und können ihn entsprechend ausführen.\n\n# Einlesen der Daten \n\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\nDamit der neue Name im Datensatz gespeichert wird, müssen wir das Ergebnis der rename()-Funktion in einem Objekt speichern. In solchen Fällen ist es häufig sinnvoll, das vorhadene Datensatzobjekt zu überschreiben. Mit der Pipe (|&gt;) übergeben wir den Datensatz an die rename()-Funktion.\n\n# Benennt die Spalte A101_01 in Themeninteresse_lokal um\n\ndf_lokal &lt;- df_lokal |&gt;\n  rename(Themeninteresse_lokal = A101_01)\n\n\n\n3.2.2 Neue Spalten hinzufügen\nEs gibt zwei Situationen, in denen es sinnvoll ist, einem Datensatz eine neue Spalte hinzuzufügen:\n\nWenn Sie eine neue Variable berechnen wollen oder\nwenn Sie eine bestehende Variable verändern wollen.\n\nDazu können wir die dplyr-Funktion mutate() nutzen. Als Argument übergeben wir der Funktion den Namen der neuen Spalte und deren Inhalt. Das Schema sieht so aus: mutate(nameDerNeuenSpalte = fester Wert, Berechnung oder Veränderung einer bestehenden Spalte). Schauen wir uns die Funktion einmal am Beispiel aus dem letzten Kapitel an. Dort haben wir die Spalte A602 in einen Faktor umgewandelt und eine Häufigkeitstabelle ausgegeben. Das geht auch mit der mutate()-Funktion Dieser sagen wir, dass wir eine neue Spalte namens geschlecht erstellen wollen. Diese ist gleich einem Faktor aus der Spalte A602, mit den entsprechenden Wertbeschriftungen.\n\n# Erstellt einen Faktor aus der Spalte A602 und speichert diesen in der neuen Spalte Geschlecht\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlecht = factor(A602, labels = c(\"männlich\", \"weiblich\", \"divers\", \"keine Angabe\")))\n\n# Häufigkeitstabelle der neuen Spalte\n\ntable(df_lokal$geschlecht)\n\n\n    männlich     weiblich       divers keine Angabe \n         813          996            7           18 \n\n\nOben haben Sie erfahren, dass man mit mutate() neue Spalten hinzufügen kann. Sie können aber auch bestehende Spalten verändern. Das sollten Sie allerdings nur in absoluten Ausnahmen machen! Eine davon ist, wenn Sie zum erstellen neuer Spalten mehrere Schritte benötigen. Zum Beispiel können wir mit der Antwort \"keine Angabe\" auf die Geschlechtsabfrage wenig anfangen. Für viele Analysen wäre es daher sinnvoll, wenn diese Werte als fehlende Werte codiert wären. In R nennen wir solche Werte NAs (für not available). Um diese Werte entsprechend als fehlend zu codieren, können wir in zwei Schritten vorgehen. Erst codieren wir den Wert 4 aus der Ausgangsspalte A602 als fehlend. Das geht mit der na_if()-Funktion aus dem dyplr-Paket. Dieser Funktion übergeben wir ein Objekt und den Wert, der in NA umgewandelt werden soll. Im zweiten Schritt können wir dann einen Faktor mit den drei Kategorien \"männlich\", \"weiblich\" und \"divers\" erstellen.\n\n# Erstellt eine Spalte aus der Geschlechtsabfrage. Erst wird der Wert \"keine Angabe\" als fehlend deklariertm dann wird ein Faktor mit den übrigen drei Kategorien erstellt\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlechtMitNAs = na_if(A602, 4)) |&gt;\n  mutate(geschlechtMitNAs = factor(geschlechtMitNAs, labels = c(\"männlich\", \"weiblich\", \"divers\")))\n\n# Häufigkeitstabelle der neuen Spalte\n\ntable(df_lokal$geschlechtMitNAs)\n\n\nmännlich weiblich   divers \n     813      996        7 \n\n\nSchauen wir uns noch ein weiteres Beispiel an. In der Spalte A601_01 ist das Geburtsjahr der Befragten angegeben, das in ein offenes Textfeld eingetragen werden sollte. Mit der unique()-Funktion können wir uns alle Werte anzeigen lassen, die mindestens einmal in der Spalte vorkommen. Anders als die table()-Funktion erhalten wir aber keine Häufigkeiten. unique() ist also praktisch, wenn wir nur wissen wollen, was für Werte eine Spalte eigentlich enthält.\n\n# Zeigt alle Werte on A601_01, die mindestens einmal vorkommen\n\nunique(df_lokal$A601_01)\n\n [1] \"1981\"         \"1957\"         \"1962\"         \"1997\"         \"1967\"        \n [6] \"1984\"         \"1961\"         \"1989\"         \"1978\"         \"1964\"        \n[11] \"1971\"         \"1993\"         \"1973\"         \"1991\"         \"Deutschland \"\n[16] \"2005\"         \"1972\"         \"1988\"         \"1965\"         \"1966\"        \n[21] \"1982\"         \"1958\"         \"1985\"         \"1953\"         \"1974\"        \n[26] \"1979\"         \"1963\"         \"1970\"         \"1959\"         \"1954\"        \n[31] \"1990\"         \"1975\"         \"1976\"         \"1960\"         \"1956\"        \n[36] \"1999\"         \"1968\"         \"1969\"         \"1987\"         \"2004\"        \n[41] \"1983\"         \"1980\"         \"2002\"         \"1977\"         \"1952\"        \n[46] \"1950\"         \"1995\"         \"01.11.1967\"   \"1996\"         \"1944\"        \n[51] \"1994\"         \"1986\"         \"1955\"         \"1948\"         \"1951\"        \n[56] \"2001\"         \"1942\"         \"1949\"         \"2000\"         \"1947\"        \n[61] \"1942 \"        \"1941\"         \"1939\"         \"w000\"         \"2003\"        \n[66] \"1998\"         \"1992\"         \"1946\"         \"1975 \"        NA            \n[71] \"1945\"         \"Deutschland\"  \"Keine Angabe\" \"1964 \"        \"1943\"        \n[76] \"1936\"         \"1938\"         \"2007\"         \"1957 \"        \"1935\"        \n[81] \"1972 \"        \"1940\"         \"1965 \"        \"1934\"         \"16.02.1957\"  \n[86] \"Datenschutz \" \"&lt;60\"          \"1933\"         \"24.10.1945\"   \"I 966\"       \n[91] \"1937\"         \"1961 \"       \n\n\nWie es aussieht, haben einige Befragte die Frage nicht ganz verstanden und unsinnige Werte (z.B. Deutschland) oder ihren genauen Geburtstag angegeben. Wieder andere haben ein Leerzeichen am Ende der Jahresangabe angehängt. All das führt dazu, dass die Spalte nicht als Zahl, sondern als string gespeichert ist. Das ist ziemlich unpraktisch!\nUm diese Spalte etwas aufzuräumen, müssen wir in mehreren Schritten vorgehen. Das Ziel ist, pro Person entweder eine Zahl mit vier Ziffern oder ein NA zu erhalten.\nWir fangen mit den Leerzeichen an. Diese können wir mit der str_trim()-Funktion aus dem stringr-Paket entfernen. Dazu übergeben wir der Funktion einfach die entsprechende Spalte. Das Ergebnis speichern wir in der neuen Spalte geburtsjahr.\n\n# Entfernt Leerzeichen am Anfang und Ende der strings und speichert das Ergebnis in der neuen Spalte \"geburtsjahr\"\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = str_trim(A601_01))\n\nunique(df_lokal$geburtsjahr)\n\n [1] \"1981\"         \"1957\"         \"1962\"         \"1997\"         \"1967\"        \n [6] \"1984\"         \"1961\"         \"1989\"         \"1978\"         \"1964\"        \n[11] \"1971\"         \"1993\"         \"1973\"         \"1991\"         \"Deutschland\" \n[16] \"2005\"         \"1972\"         \"1988\"         \"1965\"         \"1966\"        \n[21] \"1982\"         \"1958\"         \"1985\"         \"1953\"         \"1974\"        \n[26] \"1979\"         \"1963\"         \"1970\"         \"1959\"         \"1954\"        \n[31] \"1990\"         \"1975\"         \"1976\"         \"1960\"         \"1956\"        \n[36] \"1999\"         \"1968\"         \"1969\"         \"1987\"         \"2004\"        \n[41] \"1983\"         \"1980\"         \"2002\"         \"1977\"         \"1952\"        \n[46] \"1950\"         \"1995\"         \"01.11.1967\"   \"1996\"         \"1944\"        \n[51] \"1994\"         \"1986\"         \"1955\"         \"1948\"         \"1951\"        \n[56] \"2001\"         \"1942\"         \"1949\"         \"2000\"         \"1947\"        \n[61] \"1941\"         \"1939\"         \"w000\"         \"2003\"         \"1998\"        \n[66] \"1992\"         \"1946\"         NA             \"1945\"         \"Keine Angabe\"\n[71] \"1943\"         \"1936\"         \"1938\"         \"2007\"         \"1935\"        \n[76] \"1940\"         \"1934\"         \"16.02.1957\"   \"Datenschutz\"  \"&lt;60\"         \n[81] \"1933\"         \"24.10.1945\"   \"I 966\"        \"1937\"        \n\n\nAls nächstes können wir die Fälle behandeln, die ihr vollständiges Geburtsdatum angegeben haben. Dazu nutzen wir die str_sub()-Funktion, die es uns erlaubt, Teile von strings auf Basis ihrer Position zu extrahieren. Indem wir -4 angeben, sagen wir der Funktion, dass wir nur die letztn vier Stellen behalten wollen.\n\n# Entfernt alle Zeichen bis auf die letzten 4\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4))\n\nunique(df_lokal$geburtsjahr)\n\n [1] \"1981\" \"1957\" \"1962\" \"1997\" \"1967\" \"1984\" \"1961\" \"1989\" \"1978\" \"1964\"\n[11] \"1971\" \"1993\" \"1973\" \"1991\" \"land\" \"2005\" \"1972\" \"1988\" \"1965\" \"1966\"\n[21] \"1982\" \"1958\" \"1985\" \"1953\" \"1974\" \"1979\" \"1963\" \"1970\" \"1959\" \"1954\"\n[31] \"1990\" \"1975\" \"1976\" \"1960\" \"1956\" \"1999\" \"1968\" \"1969\" \"1987\" \"2004\"\n[41] \"1983\" \"1980\" \"2002\" \"1977\" \"1952\" \"1950\" \"1995\" \"1996\" \"1944\" \"1994\"\n[51] \"1986\" \"1955\" \"1948\" \"1951\" \"2001\" \"1942\" \"1949\" \"2000\" \"1947\" \"1941\"\n[61] \"1939\" \"w000\" \"2003\" \"1998\" \"1992\" \"1946\" NA     \"1945\" \"gabe\" \"1943\"\n[71] \"1936\" \"1938\" \"2007\" \"1935\" \"1940\" \"1934\" \"hutz\" \"&lt;60\"  \"1933\" \" 966\"\n[81] \"1937\"\n\n\nDiese Vorarbeit reicht, um fast alle problematischen Fälle mit einem weiteren Schritt zu bereinigen. Wir können nun die as.integer()-Funktion benutzen, um die Spalte in eine Zahl umzuwandeln. Alles was nicht umgewandelt werden kann, wird automatisch zu einem NA.\n\n# Wandelt geburtsjahr in eine Zahl um\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\nunique(df_lokal$geburtsjahr)\n\n [1] 1981 1957 1962 1997 1967 1984 1961 1989 1978 1964 1971 1993 1973 1991   NA\n[16] 2005 1972 1988 1965 1966 1982 1958 1985 1953 1974 1979 1963 1970 1959 1954\n[31] 1990 1975 1976 1960 1956 1999 1968 1969 1987 2004 1983 1980 2002 1977 1952\n[46] 1950 1995 1996 1944 1994 1986 1955 1948 1951 2001 1942 1949 2000 1947 1941\n[61] 1939 2003 1998 1992 1946 1945 1943 1936 1938 2007 1935 1940 1934 1933  966\n[76] 1937\n\n\nDas sieht schon deutlich besser aus! Nur ein einziger Fall bleibt problematisch: Eine Person hat den Wert 966. Da es recht unwahrscheinlich ist, dass eine so alte Person an der Befragung teilgenommen hat, müssen wir entscheiden, wie wir mit dem Wert umgehen. Wenn wir uns die vorherigen Ausgaben der unique()-Funktion ansehen, sehen wir, dass die Person ursprünglich \"I 966\" angegeben hatte. Wir könnten nun eher streng sein und den Wert als NA deklarieren, da die Eingabe unsinnig ist. Oder wir gehen davon aus, dass 1966 gemeint war. In dem Fall könnten wir den einzelnen Wert einfach umcodieren oder 1000 addieren. Das ist ein schönes Beispiel dafür, dass es bei der Datenaufbereitung nicht immer eindeutig richitge oder falsche Entscheidungen gibt. In diesem konkreten Fall wandeln wir die 966 in eine 1966 um. Dazu nutzen wir die ifelse()-Funktion, die immer drei Argumente benötigt:\n\nEine Bedingung, die geprüft werden soll.\nWas getan werden soll, falls die Bedingung zutrifft.\nUnd was getan werden soll, falls die Bedingung nicht zutrifft.\n\nUm nur den Wert 966 zu ändern, können wir als Bedingung erfragen, ob der aktuelle Wert kleiner als 1000 ist. Falls dem so ist, können wir 1000 addieren und ansonsten den alten Wert übernehmen. All das natürlich in einem mutate()-Aufruf.\n\n# Addiert 1000 zu allen Werten von geburtsjahr unter 1000\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr))\n\nunique(df_lokal$geburtsjahr)\n\n [1] 1981 1957 1962 1997 1967 1984 1961 1989 1978 1964 1971 1993 1973 1991   NA\n[16] 2005 1972 1988 1965 1966 1982 1958 1985 1953 1974 1979 1963 1970 1959 1954\n[31] 1990 1975 1976 1960 1956 1999 1968 1969 1987 2004 1983 1980 2002 1977 1952\n[46] 1950 1995 1996 1944 1994 1986 1955 1948 1951 2001 1942 1949 2000 1947 1941\n[61] 1939 2003 1998 1992 1946 1945 1943 1936 1938 2007 1935 1940 1934 1933 1937\n\n\nUm jetzt aus dem Geburtsjahr das Alter zu berechnen, können wir wieder mutate() nutzen, um eine neue Variable zu berechnen. Die Befragung wurde 2022 durchgeführt, also können wir davon den Wert aus geburtsjahr subtrahieren. Damit bekommen wir zwar strenggenommen nicht das Alter zum Zeitpunkt der Befragung, sondern zum Jahresende, aber genauer liegen die Daten nicht vor, sodass wir damit leben müssen.\n\n# Berechnet das Alter der Befragten\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\n\n\n3.2.3 Spalten auswählen\nManchmal enthalten Datensätze Spalten, die wir nicht benötigen. Um Speicherplatz zu sparen oder insgesamt effizienteren Code zu haben, können wir einzelne Spalten selektieren. Dazu nutzen wir die dplyr-Funktion select(). Sie können der Funktion einfach die Namen derjenige Spalten übergeben, die Sie behalten wollen. Wenn wir beispielsweise nur Alter und Geschlecht behalten wollen, sieht das wie folgt aus:\n\n# Erstell einen Datensatz der nur aus Alter und Geschlecht der Befragten besteht\n\ndf_lokal_alterUndGeschlecht &lt;- df_lokal |&gt;\n  select(alter, geschlechtMitNAs)\n\nAlternativ können Sie auch mit einem Minuszeichen einzelne Spalten ausschließen. Wenn wir z.B. die Zwischenschritte unserer Datentransformationen oben entfernen möchten, geht das deutlich leichter über den Ausschluss einiger weniger Spalten als den Einschluss aller anderen. Dabei können wir wieder mal die c()-Funktion nutzen, um gleich mehrere Spalten auf einmal loszuwerden:\n\n# Schließt die Zwischenschritte aus der Transformation aus dem Datensatz aus\n\ndf_lokal_transformiert &lt;- df_lokal |&gt;\n  select(-c(A602, geschlecht, A601_01, geburtsjahr))\n\n\n\n3.2.4 Zeilen nach Inhalt filtern\nIn anderen Fällen kann es sinnvoll sein, bestimmte Fälle - also Zeilen - aus dem Datensatz auszuschließen oder umgekehrt: nur bestimmte Fälle zu behalten. Dazu können wir die filter()-Funktion benutzen. Als Argument übergeben wir hier eine oder mehrere Bedingungen, die erfüllt sein müssen, damit ein Fall behalten wird. Beispielsweise können wir einen Datensatz erstellen, in dem nur Befragten enthalten sind, die jünger als 60 sind:\n\n# Entfernt Befragte 60+\n\ndf_lokal_u60 &lt;- df_lokal |&gt;\n  filter(alter &lt; 60)\n\nWir können auch die is.na()-Funktion nutzen (bzw. dere Negation mit !), um Befragte aszuschließen, die ihr Geschlecht nicht angegeben haben.\n\n# Entfernt Befragte ohne Angaben zum Geschlecht\n\ndf_lokla_geschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(geschlechtMitNAs))\n\nManchmal kann es auch sinnvoll sein, zwei Bedingungen zu kombinieren. Das geht mit &:\n\n# Entfernt Befragte die unter 60 und nicht männlich sind\n\ndf_lokal_alteMaenner &lt;- df_lokal |&gt;\n  filter(geschlechtMitNAs == \"männlich\" & alter &gt;= 60)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Pakete und Datentransformationen</span>"
    ]
  },
  {
    "objectID": "Skalenniveaus und deskriptive Datenanalyse.html",
    "href": "Skalenniveaus und deskriptive Datenanalyse.html",
    "title": "4  Skalenniveaus und deskriptive Datenanalyse",
    "section": "",
    "text": "4.1 Skalenniveaus und zentrale Lagemaße",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Skalenniveaus und deskriptive Datenanalyse</span>"
    ]
  },
  {
    "objectID": "Skalenniveaus und deskriptive Datenanalyse.html#deskiptive-datenanalyse",
    "href": "Skalenniveaus und deskriptive Datenanalyse.html#deskiptive-datenanalyse",
    "title": "4  Skalenniveaus und deskriptive Datenanalyse",
    "section": "4.2 Deskiptive Datenanalyse",
    "text": "4.2 Deskiptive Datenanalyse\nIn diesem Abschnitt werden wir uns anschauen, wie wir die verschiedenen Lagemaße aus dem Video in R berechnen können. Außerdem lernen Sie, wie Sie Daten in Abhängigkeit ihres Skalenniveaus visualisieren können.\n\n4.2.1 Modus\nR hat nach der Installation keine Funktion, die den Modus (oder die Modi) einer Verteilung ermittelt. Wir können aber das Paket DescTools installieren, die eine solche Funktion enthält.\n\n# Installiert das Paket \"DescTools\", falls es noch nicht installiert ist und lädt es anschließend. Andernfalls wird es nur geladen.\n\nif(!require(DescTools)){\n  install.packages(\"DescTools\")\n  library(DescTools)\n  }\n\nLade nötiges Paket: DescTools\n\n\nWarning: Paket 'DescTools' wurde unter R Version 4.4.2 erstellt\n\n\nAnschließend laden wir wieder den Datensatz und wandeln die Geschlechtsabfrage um. Den Code kennen Sie schon aus dem letzten Kapitel. Da für dieses Kapitel ein neues Skript sinnvoll ist, führen wir auch den Code noch mal aus.\n\n# Lädt das tidyverse\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Einlesen der Daten \n\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Erstellt eine Spalte aus der Geschlechtsabfrage. Erst wird der Wert \"keine Angabe\" als fehlend deklariertm dann wird ein Faktor mit den übrigen drei Kategorien erstellt\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlechtMitNAs = na_if(A602, 4)) |&gt;\n  mutate(geschlechtMitNAs = factor(geschlechtMitNAs, labels = c(\"männlich\", \"weiblich\", \"divers\")))\n\nAnschließend können wir die Mode()-Funktion aus dem DescTools-Paket verwenden. Um damit den Modus zu berechnen, müssen wir die Funktion innerhalb der dplyr-Funktion summarise() aufrufen. Diese verdichtet Datensätze. Schauen wir uns einmal an, was passiert, wenn wir Mode() einfach entsprechended ausführen:\n\n#Versucht den Modus der Spalte geschlechtMitNAs zu berechnen\n\nmodus_geschlecht &lt;- df_lokal |&gt;\n  summarise(Modus = Mode(geschlechtMitNAs))\n\nmodus_geschlecht\n\n  Modus\n1    NA\n\n\nWie Sie sehen, gibt die Funktion ein NA zurück. Das ist Rs Art uns zu sagen, dass eine Berechnung nicht durchgeführt werden kann, weil die Daten fehlende Werte enthalten. Wir können das Problem beheben, indem wir der Mode()-Funktion das Argument na.rm = TRUE übergeben. na.rm steht für NA remove. Mit dem Wert TRUE sagen wir also, dass fehlende Werte vor der Berechnung entfernt werden sollen.\n\n#Berechnet den Modus der Spalte geschlechtMitNAs \n\nmodus_geschlecht &lt;- df_lokal |&gt;\n  summarise(Modus = Mode(geschlechtMitNAs, na.rm = TRUE))\n\nmodus_geschlecht\n\n     Modus\n1 weiblich\n\n\nNun sehen wir, dass mit 996 Fällen der Wert weiblich am häufigsten vorkommt.\nSchauen wir uns als nächstes an, wie Sie nominale Daten bzw. den Modus visualisieren können. Im letzten Kapitel wurde in Kürze das tidyverse vorgestellt und auf das Paket ggplot2 verwiesen, mit dem wir Plots erstellen können.\nIm Folgenden werden Schritt für Schritt ein einfaches Balkendiagramm erstellen und es nach und nach verbessern. Wir fangen damit an, dass wir das tidyverse laden. Wir erstellen dann ein neues Objekt für unseren Plot. Dazu geben wir unseren Datensatz mit der Pipe an die Funktion ggplot() weiter. Das ist die Hauptfunktion des Pakets. Üblicherweise wird innerhalb dieser Funktion die Funktion aes() (für aesthetics) aufgerugen, in der wir je nach Diagramm angeben, welche Spalten auf der x- und y-Achse dargestellt werden soll. Für ein Balkendiagramm benötigen wir nur die x-Achse, geben also x = geschlechtMitNAs an. Damit sagen wir erstmal nur, welche Spalte wir darstellen wollen, aber noch nichts darüber, was für eine Darstellung es werden soll. Um die Art des Diagramms festzulegen, gibt es in ggplot2 unzählige Funktionen, die alle mit geom_ beginnen (für geometry). Hinter dem Unterstrich folgt dann der (englische) Name des Diagrammtyps. In unserem Fall eines Balkendiagramms, heißt die entsprechende Funktion geom_bar(). Anders als sonst, verbinden wir die Funktionen in ggplot2 nicht über die Pipe, sondern ein Pluszeichen. In der Summe sieht der Code dann so aus:\n\n# Erstellt ein einfaches Balkendiagramm der Geschlechtsabfrage\n\nplotGeschlecht &lt;- df_lokal |&gt;\n  ggplot(aes(x = geschlechtMitNAs))+\n  geom_bar()\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nDas ist - nun ja - sagen wir mal, es ist nicht sonderlich hübsch. Folgende Dinge fallen auf:\n\nEs gibt einen Balken für NAs, dabei enthalten diese ja per definitionem keine Informationen.\nDie Angabe absoluter Häufigkeiten ist etwas problematisch; besser wären relative Häufigkeiten.\nDie Werte der einzelnen Kategorien können wir aktuell nur schätzen.\nDer Hintergrund und die Farbe der Balken sind nicht sonderlich ansehnlich.\nDie Beschriftungen der Achsen (geschlechtMitNAs und count) sind nicht gerade selbsterklärend.\n\nDiese Liste können wir nun einfach abarbeiten. Manchmal ist es sinnvoll, die Daten noch ein bisschen aufzubereiten, bevor wir sie an ggplot() übergeben. Dafür deklarieren wir ein neues Objekt, das die Daten enthalten soll. Als erstes können wir dann mit der filter()-Funktion, die Sie im letzten Kapitel kennengelernt haben, die NAs entfernen. Anschließend nutzen wir die group_by()-Funktion aus dplyr. Diese Funktion sorgt dafür, dass die nachfolgenden Funktionen nicht auf den gesamten Datensatz angewendet werden, sondern auf die jeweiligen Gruppen (männlich, weiblich, divers). Anschließend nutzen wir wieder die summarise()-Funktion. Dort können wir die Prozentwerte der einzelnen Gruppen mit der folgenden Formel berechnen: n()/nrow(df_lokal)*100. n() gibt die Anzahl der Fälle zurück. Durch das Aufrufen von group_by() sind es hier die Fälle pro Ausprägung von geschlechtMitNAs. Diesen Wert teilen wir durch nrow(df_lokal). Diese Funktion gibt die Anzahl der Zeilen im kompletten Datensatz zurück. Das Ergebnis multiplizieren wir mit 100, um einen Prozentwert zu erhalten. Als letztes nutzen wir mutate(), um die Prozentwerte auf zwei Nachkommastellen zu runden. Das Ergebnis sehen Sie unten:\n\n# Erstellt einen reduzierten Datensatz, der die relativen Häufigkeiten der Ausprägungen von geschlechtMitNAs enthält\n\ndf_plot_geschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(geschlechtMitNAs)) |&gt;\n  group_by(geschlechtMitNAs) |&gt;\n  summarise(prozent = n()/nrow(df_lokal)*100) |&gt;\n  mutate(prozent = round(prozent, 2))\n\ndf_plot_geschlecht\n\n# A tibble: 3 × 2\n  geschlechtMitNAs prozent\n  &lt;fct&gt;              &lt;dbl&gt;\n1 männlich           44.0 \n2 weiblich           54.0 \n3 divers              0.38\n\n\nWenn wir diesen Datensatz an ggplot() übergeben und versuchen, ein Balkendiagramm zu erstellen, haben wir zwar keinen Balken für NA mehr, dafür ein neues Problem: Alle Balken sind gleich hoch.\n\n# Versucht, ein Balkendiagramm der Geschlechtsabfrage ohne NAs zu erstellen\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs))+\n  geom_bar()\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nUm dieses Problem zu beheben, können wir angeben, dass die y-Achse den Wert aus der Spalte prozent darstellen soll. Zusätzlich müssen wir beim Aufrufen von geom_bar() das Argument stat = \"identity\" angeben. Damit sagen wir der Funktion, dass sie nichts berechnen muss, sondern wir schon die finalen Werte als y-Wert angegeben haben.\n\n# Erstellt ein Balkendiagramm der relativen Häufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\")\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nAls nächstes wollen wir die Werte beschriften. Dazu fügen wir unserem Plot eine neue geom-Funktion hinzu, nämlich geom_text(). Dieser Funktion übergeben wir auch wieder aes(), um zu bestimmen, was angezeigt werden soll. Das Argument für Beschriftungen lautet label. Als Wert können wir die Spalte prozent angeben. Die Standardeinstellung ist, dass der Wert an seine Position auf der y-Achse geschrieben wird. Das ist etwas unpraktisch, da dort ja auch die Balken aufhören. Indem wir geom_text() das Argument vjust (für vertical justification) und den Wert -0,5 (in R reicht -.5) übergeben, können wir die Beschriftung leicht nach oben verschieben.\n\n# Erstellt ein beschriftetes Balkendiagramm der relativen Häufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\")+\n  geom_text((aes(label = prozent)), vjust = -.5)\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nAls nächstes passen wir die Farben etwas an. Gleich vorab: ggplot2 bietet nahezu unendlich viele Möglichkeiten, das Aussehen von Diagrammen anzupassen. Hier machen wir es uns relativ einfach und nutzen vorhandene Funktionen. So wie es viele geom_Funktionen gibt, gibt es auch einige theme_ Funktionen. Hier ergänzen wir theme_minimal() zu unserem Diagramm. Damit wird zwar der Hintergrund, nicht aber die Farbe der Balken angepasst. Das können wir tun, indem wir der geom_bar()-Funktion das Argument fill und eine Farbe übergeben. Diese müssen auf Englisch angegeben werden. Hier verwenden wir ein helles grau.\n\n# Erstellt ein beschriftetes Balkendiagramm der relativen Häufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\", fill = \"lightgrey\")+\n  geom_text((aes(label = prozent)), vjust = -.5)+\n  theme_minimal()\n\nplotGeschlecht\n\n\n\n\n\n\n\n\nAls letztes ändern wir die Achsenbeschriftungen. Dazu fügen wir die labs()-Funktion hinzu. Mit den Argumenten x und y können wir die Beschriftung anpassen.\n\n# Erstellt ein beschriftetes Balkendiagramm der relativen Häufigkeiten der Geschlechtsabfrage ohne NAs\n\nplotGeschlecht &lt;- df_plot_geschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = prozent))+\n  geom_bar(stat = \"identity\", fill = \"lightgrey\")+\n  geom_text((aes(label = prozent)), vjust = -.5)+\n  theme_minimal()+\n  labs(x = \"Geschlecht\", y = \"relative Häufigkeit in Prozent\")\n\nplotGeschlecht\n\n\n\n\n\n\n\n\n\n\n4.2.2 Median\nAnders als beim Modus gibt es für den Median eine R-Funktion, die wir ohne Weiteres nutzen können: die median()-Funktion. Auch hier müssen wir darauf achten, na.rm = TRUE anzugeben, damit der Median berechnet werden kann. Im folgenden Beispiel berechnen wr den Median der Spalte A203_06. In der Spalte ist codiert, wie häufig die Befragten Lokalzeitungen lesen (von 1 = “nie” bis 6 = “mehrmals täglich”).\n\n# Benenntdie Spalte A203_06 in lokalzeitung um\ndf_lokal &lt;- df_lokal |&gt;\n rename(lokalzeitung = A203_06) \n\n# Berechnet den Median der Lokalzeiungsnutzung\nmedian_lokalzeitung &lt;- df_lokal |&gt;\n  summarise(median = median(lokalzeitung, na.rm = TRUE))\n\nmedian_lokalzeitung\n\n  median\n1      4\n\n\nDer Median ist 4, was einer Nutzung mehrmals pro Woche entspricht. Es gibt viele verschiedene Möglichkeiten, den Median bzw. die Verteilung von ordinalen Daten zu visualisieren. Bei wenigen Ausprägungen, so wie im Fall der Nutzung von Lokalzeitungen, können wir ähnlich vorgehen wie beim Modus oben. Dazu müssen wir die Spalte in einen Faktor umwandeln, bevor wir sie an ggplot() übergeben. Anschließend gehen wir ähnlich vor wie oben, allerdings bleiben wir der einfachheithalber bei absoluten Häufigkeiten. Eine relevante Ergänzung nehmen wir aber vor: Mit der geom_vline()-Funktion (für vertical line) und dem Argument xintercept = 4, können wir eine Linie hinzufügen, die den Median anzeigt.\n\n# Wandelt die Nutzung von Lokalzeitungen in einen Faktor um und plottet die Daten als Balkendiagramm\nbalkenPlot_lokalzeitung &lt;- df_lokal |&gt;\n  mutate(lokalzeitungFaktor = factor(lokalzeitung, labels = c(\"nie\", \"weniger als ein Mal im Monat\",\n                                                              \"mehrmals im Monat\", \"mehrmals in der Woche\",\n                                                              \"täglich\", \"mehrmals täglich\"))) |&gt;\n  filter(!is.na(lokalzeitungFaktor)) |&gt;\n  ggplot(aes(x = lokalzeitungFaktor))+\n  geom_bar(fill = \"lightgrey\")+\n  theme_minimal()+\n  labs(x = \"Nutzung von Lokalzeitungen\", y = \"Häufigkeit\")+\n  geom_vline(xintercept = 4, linetype = \"dashed\")\n\nbalkenPlot_lokalzeitung\n\n\n\n\n\n\n\n\nDas ist schon sehr nah an einer akzeptablen Darstellung, aber die Wertbeschriftungen sehen furchtbar aus! Hier müssen wir etwas Hand anlegen und Zeilenumbrüche einfügen. Die Beschriftungen können wir mit der Funktion scale_x_discrete() und darin mit dem labels-Argument anpassen. Um einen Zeilenumbruch hinzuzufügen, können wir an einer beliebigen Stelle in einem string \\n ergänzen. Diese Funktion können wir mit einem + unserem bisherigen Objekt balkenPlot_lokalzeitung hinzufügen:\n\n# Verändert die Beschriftungen der Balken\n\nbalkenPlot_lokalzeitung &lt;- balkenPlot_lokalzeitung+\n  scale_x_discrete(labels=c(\"nie\" = \"nie\", \"weniger als ein Mal im Monat\" = \"weniger als\\n ein Mal im Monat\",\n                              \"mehrmals im Monat\" = \"mehrmals\\n im Monat\", \"mehrmals in der Woche\" = \n                              \"mehrmals\\n in der Woche\", \"täglich\" = \"täglich\",\n                              \"mehrmals täglich\" = \"merhmals\\n täglich\"))\n\nbalkenPlot_lokalzeitung\n\n\n\n\n\n\n\n\nEine andere häufige Visualisierung von ordinalen Daten ist der sogenannte Boxplot, der mit der Funktion geom_boxplot() erstellt wird. Beachten Sie im Beispiel unten, dass wir die Spalte lokalzeitung im Aufruf von ggplot() bzw. darin aes() als y-Wert definieren. Wir könnten auch den x-Wert wählen, dann würde der Boxplot auf der Seite liegen.\n\nboxplot_lokalzeitung &lt;- df_lokal |&gt;\n  filter(!is.na(lokalzeitung)) |&gt;\n  ggplot(aes(y = lokalzeitung))+\n  geom_boxplot()+\n  theme_minimal()+\n  labs(y = \"Häufigkeit der Lokalzeitungsnutzung\")\n\nboxplot_lokalzeitung\n\n\n\n\n\n\n\n\nWas Sie hier sehen ist erstmal nicht sonderlich hübsch, sollte aber dennoch kurz erklärt werden: Die dicke schwarze Linie beim Wert 4 zeigt den Median. Die eingekasteten Bereiche darüber und darunter zeigen das 75. bzw. das. 25. Quartil. Oder einfach gesagt: 25 % der Befragten haben den Wert 2 oder weniger angegeben und weitere 25 % den Wert 5 oder mehr. Die Linien nach unten und oben gehen bis zum Minimum bzw. Maximum.\nFolgende Probleme hat die Darstellung:\n\nDer Boxplot ist sehr breit. Das sieht furchtbar aus!\nDie y-Achse ist nur spärlich beschriftet.\nDie x-Achse hat eine Beschriftung, die überhaupt nicht nachvollziehbar ist.\nDas Koordinatensystem hat senkrechte Linien, die keinen Sinn ergeben, da wir ja eigentlich gar nichts auf der x-Achse abbilden.\n\nFangen wir mit den ersten beiden Problemen an. Wir sehen auf der Grafik oben, dass der auf der x-Achse der Bereich von x = -0,4 bis x = 0,4 (was auch immer diese Werte bedeuten mögen!) dargestellt ist und der Boxplot genau diesen Bereich einnimmt. Wir können die Funktion xlim() nutzen, um den dargestellten Bereich zu erweitern. Dazu müssen wir einfach nur zwei Werte angeben, z.B. -1 und 1.\nUm die y-Achse etwas schöner zu machen, können wir eine ähnliche Funktion nutzen, wie im Balkendiagramm oben: scale_y_continuous(). Mit dem Argument breaks können wir angeben, welche Werte beschriftet sein sollen. Hier können wir 1:6 angeben, um alle ganzen Zahlen zwischen 1 und 6 anzeigen zu lassen.\n\nboxplot_lokalzeitung &lt;- boxplot_lokalzeitung+  \n  xlim(-1,1)+\n  scale_y_continuous(breaks = 1:6)\n\n\nboxplot_lokalzeitung\n\n\n\n\n\n\n\n\nDas sieht schon etwas besser aus. Wir haben nun aber ein neues Problem: Auf der y-Achse werden nun waagerechte Linien zwischen den ganzen Zahlen angezeigt, dabei konnte die Variable diese Werte gar nicht annhemen.\nDieses Problem können wir gemeinsam mit den übrigen Punkte von oben in einem Rutsch erledigen, indem wir die theme()-Funktion nutzen. Diese Funktion kann zugegebenermaßen etwas abschreckend sein. Sie können damit die Darstellung aller einzelnen Elemente eines Plots anpassen oder - und das ist für uns hier aber auch generell häufig entscheidend - sie entfernen! Das Schema ist immer gleich: Sie geben ein Element an und schreiben hinter ein Gleichheitszeichen, wie es dargestellt werden soll. Geben Sie dort element_blank() an, wird das Element entfernt. Das nutzen wir hier um die folgenden Elemente zu entfernen:\n\nDie Beschriftung der x-Achse –&gt; das Element heißt axis.text.x\nDie vertikalen Linien im Koordinatensystem –&gt; die Elemente heißen panel.grid.major.x und panel.grid.minor.x\nDie horizontalen Linien zwischen den ganzen Zahlen –&gt; das Element heißt panel.grid.minor.y\n\n\nboxplot_lokalzeitung &lt;- boxplot_lokalzeitung+\n  theme(axis.text.x = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\nboxplot_lokalzeitung\n\n\n\n\n\n\n\n\nDeutlich häufiger werden Sie Boxplots begegnen (oder selbst erstellen), wenn es um die Darstellung mehrerer Gruppen geht. Im folgenden Beispiel sehen Sie einen Boxplot für die Nutzung von Lokalzeitungen nach Geschlecht der Befragten. Im wesentlichen ist er sehr ähnlich wie der Plot oben, allerdings müssen wir diesmal keine Elemente entfernen. Vor allem aber müssen wir im Aufruf von ggplot() bzw. darin aes() angeben, dass das Geschlecht der Befragten auf der x-Achse dargestellt werden soll.\n\nboxplot_lokalzeitung_geschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(lokalzeitung)) |&gt;\n  filter(!is.na(geschlechtMitNAs)) |&gt;\n  ggplot(aes(y = lokalzeitung, x = geschlechtMitNAs))+\n  geom_boxplot()+\n  theme_minimal()+\n  scale_y_continuous(breaks = 1:6)+\n  labs(y = \"Häufigkeit der Lokalzeitungsnutzung\", x = \"Geschlecht\")\n\nboxplot_lokalzeitung_geschlecht\n\n\n\n\n\n\n\n\nDas Ergebnis sieht schon sehr ordentlich aus. Der einsame Punkt in der Spalte divers steht für einen Ausreißer: Eine Person liest deutlich höufiger Lokalzeitungen als andere Menschen, die sich nicht-binär identifizieren. In erster Linie liegt das an der sehr geringen Fallzahl in der Gruppe (vgl. das Balkendiagramm von oben). Um das sichtbar zu machen, können wir die Rohdaten anzeigen lassen. Das geht grundsätzlich mit geom_point(), hat aber den Nachteil, dass dann alle Datenpunkte an derselben Stelle dargestellt werden:\n\nboxplot_lokalzeitung_geschlecht+\n  geom_point()\n\n\n\n\n\n\n\n\nDas hilft uns nicht wirklich weiter. Eine bessere Möglichkeit ist geom_jitter(). Damit werden die Rohdaten etwas gestreut geplottet. Durch das Argument alpha = .25 können wir die Punkte zusätzlich etwas transparent machen.\n\nboxplot_lokalzeitung_geschlecht &lt;- boxplot_lokalzeitung_geschlecht+\n  geom_jitter(alpha = .25)\n\nboxplot_lokalzeitung_geschlecht\n\n\n\n\n\n\n\n\n\n\n4.2.3 Mittelwert und Standardabweichung\nFür Mitelwert und Standardabweichung gibt es ebenfalls zwei R-Funktionen, die wir direkt nutzen können: mean() und sd(). Auch hier müssen wir darauf achten, dass wir na.rm = TRUE angeben.\nIm folgenden Beispiel berechnen wir zunächst das Alter der Befragten mit dem Code aus dem letzten Kapitel. Anschließend nutzen wir summarse(), um den Datensatz auf Mittelwert und Standardabweichung des Alters zu reduzieren. Innerhalb von summarise() berechnen wir entsprechen mit mean() den Mittelwert und mit sd() die Standardabweichung. Beides runden wir mit round() auf zwei Nachkommastellen.\n\n# Berechnet das Alter der Befragten\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geburtsjahr = str_trim(A601_01)) |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4)) |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr)) |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\n# Berechnet Mittelwert und Standardabweichung des Alters\n\ndf_alter &lt;- df_lokal |&gt;\n  summarise(MWAlter = round(mean(alter, na.rm = TRUE), 2),\n            SDAlter = round(sd(alter, na.rm = TRUE), 2))\n\ndf_alter\n\n  MWAlter SDAlter\n1   49.66   15.31\n\n\nWir sehen, dass die Befragten im Mittel 49,66 also fast 50 Jahre als waren, bei einer Standardabweichung von 15,31 Jahren. Im Video oben haben Sie erfahren, dass bei einer Normalverteilung ca. 68 % aller Werte innerhalb der Region Mittelwert - 1 Standardabweichung bis Mittelwert + 1 Standardabweichung liegen. Hier wäre das entsprechend der Bereich von 34,35 bis 64.97 Jahren, zumindest sofern die Variable normalverteilt ist. Um das zu prüfen und genereall um metrische Daten zu visualisieren, können wir ein sogenanntes Histogramm zeichnen. Dazu nutzen wir geom_histogramm(). Im Prinzip handelt es sich dabei um eine Art Balkendiagramm für metrische Daten, bei der einzelne Ausprägungen zusammengefasst werden,\n\nhistogramm_alter &lt;- df_lokal |&gt;\n  filter(!is.na(alter)) |&gt;\n  ggplot(aes(x = alter))+\n  geom_histogram(fill = \"lightgrey\", bins = 40)+\n  theme_minimal()+\n  labs(x = \"Alter der Befragten\", y = \"Häufigkeit\")\n  \n\nhistogramm_alter\n\n\n\n\n\n\n\n\nDem Histogramm können wir entnehmen, dass die Daten annähnernd normalverteilt sind. Das linke Ende der Verteilung ist etwas steiler. Das ist zu erwarten, denn üblicherweise gibt es ein Mindestalter zur Teilnahme an Befragungen. Wir sehen auch, dass Menschen um die 60 Jahre und älter relativ stark vertreten sind. Gemessen an der Bevölkerung ist auch das nicht sonderlich. Für die meisten statistischen Zweck könnten Sie bei so einer Verteilung aber davon ausgehen, dass Sie zumindest nah genug an einer Normalverteilung dran sind.\nWährend uns das Histogramm einen guten Überblick über die Verteilung als Ganze gibt, ist es manchmal sinnvoll, Mittelwert und Standardabweichung direkt darzustellen. Das gilt insbesondere dann, wenn Sie mehrere Gruppen vergleichen wollen. Im folgenden Beispiel stelle wir das Durchschnittsalter (also den Mittelwert) der Befragten nach Geschlecht dar. Dazu wollen wir die Streuung um den Mittelwert der jeweiligen Gruppen darstellen. Hier machen wir das, indem wir die Standardabweichung ebenfalls darstellen. In wissenschaftlichen Arbeiten werden Sie auch immer mal Darstellungen begegnen, in denen andere Maße genutzt werden: entweder der Standardfehler oder sogenannte Konfidenzintervalle. Die Begriffe werden wir noch kennenlernen, ignorieren sie aber in diesem Kapitel noch.\nFür unser Beispiel berechnen wir als erstes Mittelwert und Standardabweichung der jeweiligen Gruppen. Alles, was wir dafür brauchen, haben wir schon kennengelernt: Wir nutzen filter() um fehlende Werte auszuschließen, nutzen group_by(), um die Daten zu Gruppieren und rufen dann mean() und sd() innerhalb von summarise() auf.\n\n# Berechnet Mittelwert und Standardabweichung nach Geschecht\ndf_lokal_alterUndGeschlecht &lt;- df_lokal |&gt;\n  filter(!is.na(geschlechtMitNAs)) |&gt;\n  filter(!is.na(alter)) |&gt;\n  group_by(geschlechtMitNAs) |&gt;\n  summarise(MWAlter = mean(alter),\n            SDAlter = sd(alter))\n\nUm die Gruppenmittelwerte mit jeweiliger Standardabweichug abzubilden, nutzen wir zwei neue geom_ Funktionen: geom_point() für die Mittelwerte und geom_errorbar() für die Standardabweichungen. Aber fangen wir obne an: zunächst legen wir in ggplot() und aes() fest, dass wir das Alter auf der y-Achse und das Geschlecht auf der x-Achse darstellen wollen. geom_point() sorgt dafür, dass die Gruppenmittelwerte jeweils durch einen Punkt dargestellt werden. geom_errorbar() zeichnet Balken um diese Punkte. Dazu müssen wir wieder in aes() angeben, wo diese Balken anfangen und aufhören sollen. Den Startpunkt legen wir mit ymin=MWAlter-SDAlter und den Endpunkt mit ymax=MWAlter+SDAlter fest.\n\n# Plottet die Gruppenmittelwerte und Standardabweichungen\nalter_nach_geschlecht &lt;- df_lokal_alterUndGeschlecht |&gt;\n  ggplot(aes(x = geschlechtMitNAs, y = MWAlter))+\n  geom_point()+\n  geom_errorbar(aes(ymin=MWAlter-SDAlter, ymax=MWAlter+SDAlter))+\n  labs(x = \"Geschlecht\", y = \"Alter\")+\n  theme_minimal()\n\nalter_nach_geschlecht\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrafiken speichern\n\n\n\nWenn Sie einen Plot speichern wollen, können Sie die ggsave()-Funktion verwenden. Folgende Argumente sollten Sie der Funktion übergeben:\n\nfilename = Den Namen, den die Datei tragen soll (in Anführungszeichen).\nplot = Den Namen des Objekts, das Sie speichern wollen.\nwidth = Die gewünschte Breite der Grafik.\nheight = Die gewünschte Höhe der Grafik.\nunits = Die Maßeinheit in der Breite und Höhe angegeben werden: “mm”, “cm”, “px” oder “in” für millimeter centimeter, pixel oder inch.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Skalenniveaus und deskriptive Datenanalyse</span>"
    ]
  },
  {
    "objectID": "Hypothesen und Testtheorie.html",
    "href": "Hypothesen und Testtheorie.html",
    "title": "5  Hypothesen und Testtheorie",
    "section": "",
    "text": "5.1 Hypothesen\nGanz allgemein gesprochen, verstehen wir unter einer Hypothese eine allgemeine Aussage über einen vermuteten Zusammenhang zwischen empirischen oder logischen Sachverhalten. In unserem Kontext gelten drei Anforderungen an Hypothesen:\nGrundsätzlich können Sie immer eine Hypothese aufstellen, wenn Sie eine ganz konkrete Annahme haben. Allerdings entspricht es guter wissenschaftlicher Praxis, dass Sie Ihre Hypothesen aus dem aktuellen Forschungsstand Ihres Themas, d.h. aktuellen Theorien und verwandten empirischen Befunden, ableiten. Beispielsweise entspricht die Hypothese “Am Freitag schmeckt das Essen in der Mensa der Uni Erfurt schlechter als an den anderen Wochentagen” den oben genannanten Annforderungen. Allerdings handelt es sich dabei um nicht viel mehr als einen auf meiner Wahrnehmung beruhenden flüchtigen Gedanken.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesen und Testtheorie</span>"
    ]
  },
  {
    "objectID": "Hypothesen und Testtheorie.html#hypothesen",
    "href": "Hypothesen und Testtheorie.html#hypothesen",
    "title": "5  Hypothesen und Testtheorie",
    "section": "",
    "text": "Sie dürfen keine Einzelfälle beschreiben.\nSie müssen die Struktur eines sinnvollen Konditionalsatzes aufweisen (z.B. wenn-dann, je-desto). Diese ist logisch notwendig, muss aber nicht zwingend expliziert formuliert sein.\nSie müssen falsifizierbar sein.\n\n\n\n\n\n\n\nFalsifizierbarkeit\n\n\n\nFalsifizierbarkeit bedeutet im Kern nichts anderes, als dass wir in der Lage sein müssen, die Hypothese zu widerlegen. In der Forschungspraxis bedeutet das konkret, dass wir in der Lage sein müssen, Daten zu erheben, anhand derer wir die Hypothese testen können.\n\n\n\n\n5.1.1 Arten von Hypothesen\nIn den nachfolgenden Abschnitten werden wir uns anschauen, wie verschiedene Hypothesen differenziert werden können.\n\n5.1.1.1 Null- und Alternativhypothese\nEinen ersten Unterschied, den Sie kennen sollten, ist der zwischen Null- und Alternativhypothese. Manchmal werden die beiden auch als H0 und H1 bezeichnet. Letztere ist immer das, was Sie inhaltlich eigentlich annehmen. Die Nullhypothese besagt dagegen, dass Ihre Annahme nicht zutrifft. Die Nullhypothese ist deshalb wichtig, weil die statistischen Verfahren, die Sie in dieser Veranstaltung lernen werden, nicht die Alternativ-, sondern die Nullhypothese testen. Streng genommen gelten die oben genannten Kriterien also in erster Linie für die Nullhypothese. Das gilt insbesondere für die Falsifizierbarkeit!\nStellen wir uns einmal vor, dass Sie annehmen, dass jüngere Menschen mehr Zeit mit der Nutzung sozialer Medien verbringen als ältere Menschen. Eine mögliche Formulierung der Alternativhypothese lautet:\n\nH1: Es besteht ein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\nDagegen lautet die Nullhypothese:\n\nH0: Es besteht kein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\n\n\n5.1.1.2 Gerichtete und ungerichtete Hypothesen\nEin weiterer wichtiger Aspekt, nach dem Sie Hypothesen unterscheiden können, ist, ob diese gerichtet oder ungerichtet sind. Gerichtet sind Hypothesen immer dann, wenn Sie eine Vermutung über die Richtung eines Zusammenhangs haben. Ungerichtet bedeutet dagegen, dass Sie einfach nur annehmen, dass es einen Zusammenhang gibt, ohne zu vermuten, wie genau dieser ausfällt. Nehmen wir noch einmal das Beispiel von oben. Im Text haben wir gesagt, dass Sie vermuten, dass jüngere Menschen mehr Zeit mit der Nutzung verbringen als ältere. Das ist ein Beispiel für eine gerichtete Hypothese, da wir eine Vermutung darüber haben, welche Personen mehr bzw. weniger Zeit mit der Nutzung verbringen. Die Formulierung der H1 im Beispiel oben ist dagegen ungerichtet, da nur gesagt wird, dass ein Zusammenhang besteht. Formulieren wir die Hypothese also um:\n\nH1: Jüngere Menschen verbringen mehr mit der Nutzung sozialer Netzwerke als ältere Menschen.\n\nEntsprechend ändert sich auch die H0:\n\nH0: Jüngere Menschen verbringen nicht mehr mit der Nutzung sozialer Netzwerke als ältere Menschen.\n\nBeachten Sie, dass diese Nullhypothese nicht nur dann falsifiziert wird, wenn es keinen Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke gibt, sondern auch, falls es zwar einen Zusammenhang gibt, dieser aber in die entgegengesetzte Richtung läuft. Also Menschen mehr Zeit mit der Nutzung verbringen, je älter sie sind.\n\n\n5.1.1.3 Hypothesen über Zusammenhänge und Unterschiede\nDie meisten Hypothesen, die Sie während Ihres Studiums aufstellen und testen werden, befassen sich entweder mit Zusammenhängen, so wie im bisherigen Beispiel, oder mit Unterschieden zwischen (mindestens) zwei Gruppen. Solche Hypothesen sind immer dann sinnvoll, wenn Sie entweder an Differenzen zwischen natürlich auftretenden Gruppen interessiert sind (z.B. Studierende vs. Azubis, Arbeitnehmerinnen und Arbeitnehmer vs. Selbstständige, Menschen aus Europa vs. den USA) oder wenn Sie im Rahmen eines Experiments die Unterschiede zwischen einer Experimental- und einer Kontrollgruppe untersuchen. Oder anders gesagt: Hypothesen über Unterschiede sind immer dann sinnvoll, wenn Ihre Hypothese eine Aussage über Gruppen enthält, die Sie mit einer nominalen Variable messen können.\nSchauen wir uns mal ein Beispiel für eine Hypothese über Unterschiede an. Es gelten dieselben Kriterien wie oben:\n\nH1: Menschen im Ruhestand und Menschen, die nicht im Ruhestand sind, schauen unterschiedlich oft lineares Fernsehen.\n\nDiese Hypothese beschreibt einen vermuteten Unterschied zwischen Rentnerinnen und Rentnern und allen anderen Menschen. Gleichzeitig ist es eine ungerichtete Hypothese, da sie keine Annahme darüber enthält, welche der beiden Gruppen häufiger (bzw. seltener) lineares Fernsehen schaut. Die zugehörige H0 lautet dementsprechend:\n\nH0: Menschen im Ruhestand und Menschen, die nicht im Ruhestand sind, schauen gleich oft lineares Fernsehen als Menschen.\n\nWürden wir stattdessen davon ausgehen, dass Rentnerinnen und Rentner häufiger klassisches Fernsehen schauen (z.B. weil sie einfach mehr Zeit haben), könnten wir die folgende gerichtete Alternativhypothese mit zugehöriger Nullhypothese aufstellen.\n\nH1: Menschen im Ruhestand schauen öfter lineares Fernsehen als Menschen, die nicht im Ruhestand sind.\n\n\nH0: Menschen im Ruhestand schauen nicht öfter lineares Fernsehen als Menschen, die nicht im Ruhestand sind.\n\n\n\n\n5.1.2 Statistische Hypothesen\nBisher haben wir uns in erster Linie mit inhaltlichen Aspekten von Hypothesen beschäftigt. Als Nächstes werfen wir einen Blick darauf, welche statistischen Annahmen hinter den Hypothesen stecken.\nIm Fall von Hypothesen über Zusammenhänge wird in der Regel ein Maß berechnet, das etwas über die Stärke eines Zusammenhangs aussagt, z. B. einen sogenannten Korrelationskoeffizienten (dazu im übernächsten Kapitel mehr). Bei ungerichteten Hypothesen lautet die Nullhypothese immer, dass dieses Maß genau den Wert 0 annimmt. Schauen wir uns das am Beispiel von oben an. Inhaltlich haben wir dort die folgende Alternativ- bzw. Nullhypothese aufgestellt:\n\nH1: Es besteht ein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\n\nH0: Es besteht kein Zusammenhang zwischen dem Alter und der Nutzung sozialer Netzwerke.\n\nDie zugehörigen statistischen Hypothesen sehen Sie untenstehend. r ist dabei ein Platzhalter für das Zusammenhangsmaß:\n\nstatistische H1: \\(r_{Alter,~Nutzung~sozialer~Medien} \\neq 0\\)\n\n\nstatistische H0: \\(r_{Alter,~Nutzung~sozialer~Medien} = 0\\)\n\nWie oben angedeutet, verhält es sich bei gerichteten Hypothesen etwas anders, da die Nullhypothese nur aussagt, dass die Richtung nicht zutrifft. Dort hatten wir die folgenden Hypothesen aufgestellt:\n\nH1: Jüngere Menschen verbringen mehr Zeit mit der Nutzung sozialer Netzwerke als ältere Menschen.\n\n\nH0: Jüngere Menschen verbringen nicht mehr mit der Nutzung sozialer Netzwerke als ältere Menschen.\n\nIn diesem Fall gehen wir von einem negativen Zusammenhang aus. Das bedeutet nichts anderes, als dass kleinere Messwerte in der einen Variable (das Alter) mit höheren Werten in der anderen Variable (die Nutzung sozialer Medien) einhergehen. Würden wir das Gegenteil vermuten, also dass eher ältere Menschen mehr Zeit mit der Nutzung sozialer Medien verbringen, würden wir einen positiven Zusammenhang annehmen (hohe Werte gehen mit hohen Werten einher). Daraus folgt, dass die Nullhypothese nicht aussagt, dass es keinen Zusammenhang gibt, sondern, dass es entweder keinen oder einen positiven Zusammenhang gibt. Anders gesagt: keinen negativen Zusammenhang. Die statistischen Hypothesen lauten also wie folgt:\n\nstatistische H1: \\(r_{Alter,~Nutzung~sozialer~Medien} &lt; 0\\)\n\n\nstatistische H0: \\(r_{Alter,~Nutzung~sozialer~Medien} \\ge 0\\)\n\nIm Fall von Hypothesen über Unterschiede verhält es sich im Prinzip ähnlich. Allerdings müssen wir hier definieren, was genau wir eigentlich mit einem Gruppenunterschied meinen. In der Regel ist das der Mittelwert. Wir gehen also davon aus, dass der Mittelwert der einen Gruppe größer oder kleiner ist als der Mittelwert der anderen Gruppe. Für unsere ungerichtete Hypothese von oben sieht das entsprechend so aus, wobei M eine Abkürzung für Mittelwert ist:\n\nstatistische H1: \\(M_{Fernsehnutzung,~Ruhestand} \\neq M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\n\nstatistische H0: \\(M_{Fernsehnutzung,~Ruhestand} = M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\nDie gerichtete Version dieser Hypothese lautet dagegen wie folgt:\n\nstatistische H1: \\(M_{Fernsehnutzung,~Ruhestand} &gt; M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\n\nstatistische H0: \\(M_{Fernsehnutzung,~Ruhestand} \\le M_{Fernsehnutzung,~kein~Ruhestand}\\)\n\nDie Grundlagen der statistischen Hypothesen sind wichtig, weil sie das abbilden, was Sie mit statistischen Verfahren eigentlich testen! Allerdings ist eher unüblich, statistische Hypothesen in Abschlussarbeiten oder gar wissenschaftlichen Veröffentlichungen zu schreiben. Selbst die Nullhypothese werden Sie dort in der Regel nicht antreffen. Stattdessen reicht es in der Regel, die Alternativhypothese aufzuschreiben. Sofern diese anständig formuliert ist, impliziert sie sowohl die statistische als auch die Nullhypothese.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesen und Testtheorie</span>"
    ]
  },
  {
    "objectID": "Hypothesen und Testtheorie.html#testtheorie",
    "href": "Hypothesen und Testtheorie.html#testtheorie",
    "title": "5  Hypothesen und Testtheorie",
    "section": "5.2 Testtheorie",
    "text": "5.2 Testtheorie\n\n5.2.1 p-Werte\nIm Lauf der kommenden Wochen werden wir verschiedene Verfahren kennenlernen, mit denen Sie Hypothesen testen können. Die Idee dahinter ist aber immer dieselbe: Unsere Daten bilden (in der Regel) nur eine Stichprobe der Grundgesamtheit ab. Das Ziel eines Hypothesentests liegt darin, zu prüfen, ob die von uns beobachteten Zusammenhänge bzw. Unterschiede auch in der Grundgesamtheit zu erwarten sind. Die Verfahren werden unter dem Begriff Inferenzstatistik zusammengefasst und enthalten jeweils einen sogenannten Signifikanztest. Damit prüfen wir, ob wir H0 verwerfen müssen, H1 wird also immer nur indirekt getestet. Die Entscheidung darüber, ob H0 verworfen wird, basiert auf sogenannten p-Werten, die von den Signifikanztests berechnet werden.\nWas nun folgt, ist eine etwas sperrige Definition (Spoiler: Davon gibt es in der Statistik leider sehr viele!):\n\n\n\n\n\n\np-Wert\n\n\n\nDer p-Wert gibt an, wie wahrscheinlich es ist, die beobachteten Daten oder noch extremere Daten, zu beobachten, falls die Nullhypothese zutrifft.\n\n\nSchauen wir uns diese Definition mal im Detail an: Der p-Wert gibt eine Wahrscheinlichkeit an (das p steht für “probability”) und liegt daher immer zwischen 0 (sehr, sehr unwahrscheinlich) und 1 (extrem wahrscheinlich). Der Definition können wir entnehmen, dass diese Wahrscheinlichkeit aussagt, wie wahrscheinlich die von uns beobachteten Daten sind, falls die Nullhypothese zutrifft. Wenn diese Wahrscheinlichkeit sehr gering ist, üblicherweise kleiner als 5% (der berechnete p-Wert also kleiner als 0,05 ist), sagen wir, dass ein Ergebnis statistisch signifikant ist. Wenn Sie also einmal einen statistischen Test berechnen und einen entsprechend kleinen p-Wert sehen, können Sie sich relativ sicher sein, dass die Nullhypothese verworfen werden kann, also nicht zutrifft. Sie wurde dann falsifiziert. Das bedeutet zwar nicht automatisch, dass unsere Alternativhypothese zutrifft, aber mangels besserer Informationen können wir vorerst so tun, als wäre dies der Fall.\n\n\n5.2.2 Fehlschlüsse\nWarum aber diese 5 %? Diese Zahl ergibt sich aus der Logik, die dieser Art von Statistik zugrunde liegt. Die Idee ist, dass wir als Forscherinnen und Forscher versuchen, langfristig nur in 5% der Fälle fälschlicherweise davon ausgehen wollen, dass es einen Effekt (also einen Unterschied oder einen Zusammenhang) gibt, obwohl dem nicht der Fall ist. Diese Art von Fehlschluss nennen wir auch Alpha-Fehler oder Fehler 1. Art. Die 5 % sind dabei reine Konvention!\nDiese Fehler kommen zustande, weil p-Werte gleichverteilt sind, wenn die H0 zutrifft. Wenn es also keinen Unterschied oder Zusammenhang gibt, werden wir trotzdem in 5 % der Fälle ein statistisch signifikantes Ergebnis bekommen. Stellen wir uns einmal vor, wir würden eine der Hypothesen oben 10.000 Mal testen und die berechneten p-Werte aufschreiben und anschließend grafisch darstellen. Das Ergebnis könnte so aussehen:\n\n\n\n\n\n\n\n\n\nWie Sie sehen, sind die p-Werte gleichverteilt. Das heißt, Werte zwischen 0 und 0,05 sind genauso häufig wie Werte zwischen 0,95 und 1 oder 0,73 und 0,78. Da wir gesagt haben, dass Werte zwischen 0 und 0,5 als statistisch signifikant gelten, würden wir also in ca. 5 % der Fälle einen Fehlschluss ziehen.\n\n\n\n\n\n\n\n\n\nGenauso, wie wir fälschlicherweise zu dem Schluss gelangen können, dass es einen Effekt gibt, obwohl dies nicht der Fall ist, können wir einen realen Effekt nicht finden und entsprechend darauf schließen, dass es ihn nicht gibt (bzw. dass H0 zutrifft). Wir sprechen dann von einem Beta-Fehler oder auch Fehler 2. Art. Diese Art von Fehler kann zwar grundsätzlich verschiedene Ursachen haben, allerdings hängt die Wahrscheinlichkeit, einen solchen Fehler zu begehen, in erster Linie mit der Stichprobengröße zusammen. Es gilt: Je größer die Stichprobe, desto höher ist die Wahrscheinlichkeit, einen Effekt zu finden, sofern dieser tatsächlich existiert. Man spricht auch von der statistischen Power eines Tests.\nAuch hier gibt es wieder eine Konvention: Studien (bzw. die darin enthaltenen Tests) sollten mindestens 80% Power haben, also einen in der Realität existierenden Effekt in 4 von 5 Fällen identifizieren können. Online werden Sie für die Verfahren, die wir in den kommenden Wochen kennenlernen werden, oftmals Faustregeln zur Stichprobnengröße finden, um diese Power zu erreichen. Z.B.ca. 30 Personen pro Gruppe, wenn ein t-Test gerechnet werden soll (was das ist, werden wir noch lernen!). Solche Faustregeln sind meistens relativ alt, also aus einer Zeit, in der es sehr schwer und kostspielig war, Forschung mit Menschen zu betreiben. Sie sollten daher besser vermieden werden. Zwar gibt es Verfahren, mit denen bestimmt werden kann, wie groß Ihre Stichprobe sein muss, um auf 80% Power zu kommen, aber diese werden wir uns in dieser Veranstaltung nicht anschauen. Wenn Sie im Rahmen eines Forschungsprojektes im Studium eine Stichprobe rekrutieren sollen, sprechen Sie daher am besten mit Ihrem Betreuer oder Ihrer Betreuerin, um zu klären, wie groß die Stichprobe sein sollte und was für Sie in Ihrem Forschungskontext realistisch ist!",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesen und Testtheorie</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen nominalen und ordinalen Variablen.html",
    "href": "Zusammenhänge zwischen nominalen und ordinalen Variablen.html",
    "title": "6  Zusammenhänge zwischen nominalen und ordinalen Variablen: Kreuztabellen",
    "section": "",
    "text": "6.1 Statistische Grundlagen",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Kreuztabellen</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen nominalen und ordinalen Variablen.html#deskription-und-visulisierung-der-daten",
    "href": "Zusammenhänge zwischen nominalen und ordinalen Variablen.html#deskription-und-visulisierung-der-daten",
    "title": "6  Zusammenhänge zwischen nominalen und ordinalen Variablen: Kreuztabellen",
    "section": "6.2 Deskription und Visulisierung der Daten",
    "text": "6.2 Deskription und Visulisierung der Daten\nBevor wir starten, müssen wir ein paar Vorkrehrungen treffen. Konkret laden wir das tidyverse laden danach das Paket effectsize, das wir später bei der statistischen Analyse benötigen werden. Anschließend lesen wir die Daten ein. Außerdem nutzen wir die options()-Funktion. Damit können wir die Einstellungen von R ändern. Hier nutzen wir das Argument scipen mit dem Wert 999. Im Prinzip sorgen wir damit nur dafür, dass sehr kleine Zahlen so angezeigt werden, wie Sie es erwarten würden. Das werden wir später bei den satistischen Analysen benötigen.\n\n# Lädt das tidyverse\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Lädt bzw. installiert und lädt das Paket \"effectsize\"\nif(!require(effectsize)){\n  install.packages(\"effectsize\")\n  library(effectsize)\n}\n\nLade nötiges Paket: effectsize\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\n\nSchauen wir uns nun einmal eine Kreuztabelle an. Anschließend visualisieren wir die Daten. Wir nehmen dazu die Spalte Bula, die angibt, aus welchem Bundesland die Befragten stammen und die Spalte A502_01, die angibt, ob die Menschen Mitglied in einem Sportverein sind. Um eine einfache Kreuztabelle zu erstellen, können wir die table()-Funktion nutzen, der wir die beiden Spalten übergeben. Vorher wandeln wir A502_01 in einen Faktor um, sodass wir etwas besser damit arbeiten können.\n\n# Wandelt die Spalte A502_01 in einen Faktor mit den Stufen \"nein\" und \"ja\" um.\ndf_lokal &lt;- df_lokal |&gt;\n    mutate(Sportverein = factor(A502_01, labels = c(\"nein\", \"ja\")))\n\n# Erstellt eine einfache 2x2 Tabelle, die wir \"tabelleSportNachBundesland\" nennen\n# select() wählt die Spalten aus, die dann an table() weitergereicht werden\ntabelleSportNachBundesland &lt;- df_lokal |&gt;\n  select(Bula, Sportverein) |&gt;\n  table() \n\ntabelleSportNachBundesland\n\n     Sportverein\nBula  nein  ja\n  RLP  649 385\n  TH   636 172\n\n\nFür sich genommen sagt uns diese Tabelle noch nicht allzu viel. Wir sehen, dass Befragte aus beiden Bundesländern ähnlich oft angegeben haben, nicht Mitglied eines Sportvereins zu sein, allerdings gab in Rheinland-Pfalz ein paar mehr Menschen, die in Vereinen aktiv sind.\nIm nächsten Schritt visualisieren wir diese Daten. Wir gehen dabei ähnlich vor wie bei den Balkendiagrammen mit relativen Häufigkeiten in Kapitel 4. Das heißt, wir erstellen einen reduzierten Datensatz. Dazu nutzen wir erst filter() und rufen darin !is.na() auf. Dabei müssen wir darauf achten, dass wir die Funktion für beide Variablen aufrufen und mit einem & verbingen. Anschließend nutzen wir group_by() und dann summarise(). Das Ergebnis ist ein Datensatz mit vier Zeilen, von denen jede eine Zelle aus der Tabelle oben darstellt.\n\n# Erstellt einen reduzierten Datensatz, der die relativen Häufigkeiten der Ausprägungen enthält\ndf_plot_kreuztabelle &lt;- df_lokal |&gt;\n  filter(!is.na(Sportverein) & !is.na(Bula)) |&gt;\n  group_by(Bula, Sportverein) |&gt;\n  summarise(Anzahl = n())\n\n`summarise()` has grouped output by 'Bula'. You can override using the\n`.groups` argument.\n\ndf_plot_kreuztabelle\n\n# A tibble: 4 × 3\n# Groups:   Bula [2]\n  Bula  Sportverein Anzahl\n  &lt;chr&gt; &lt;fct&gt;        &lt;int&gt;\n1 RLP   nein           649\n2 RLP   ja             385\n3 TH    nein           636\n4 TH    ja             172\n\n\nDiesen Datensatz können wir jetzt für die Visualisierung nutzen. Auch hier gehen wir im Prinzip wie in Kapitel 4 vor. Allerdings mit einem wichtigen Unterschied: Um die vier Zellen aus der Tabelle abbilden zu können, reichen einfache, nebeneinander stehende Balken nicht mehr aus. Zwar könnten wir theoretisch vier Balken zeichnen, allerdings wäre das nicht sonderlich übersichtlich. Stattdessen bietet sich ein sogenanntes Stapeldiagramm an.\nDie gute Nachricht ist, dass ein Stapediagramm sehr ähnlich erstellt wird, wie die Balkendiagramme, die Sie bereits kennen. Beim Aufruf von ggplot() und darin deraes()-Funktion übergeben wir eine Spalte (hier Bundesland) für die x-Achse und eine andere (Anzahl) für die y-Achse. Zusätzlich nutzen wir das fill-Argument und geben dort die Spalte Sportverein an. Damit sagen wir ggplot, dass diese Spalte genutzt werden soll, um die Balken einzufärben. Das heißt, die Ausprägungen “ja” und “nein” erhalten andere Farben. Diese können wir in scale_fill_manual festlegen. In diesem Beispiel geben wir außerdem in geom_bar position = \"fill\" an. Dadurch werden die Werte in relative Häufigkeiten umgewandelt und beide Balken sind gleich hoch.\n\nplot_kreuztabelle &lt;- df_plot_kreuztabelle |&gt;\n  ggplot(aes(x = Bula, y = Anzahl, fill = Sportverein))+\n    geom_bar(position = \"fill\", stat = \"identity\")+\n    theme_minimal()+\n    scale_fill_manual(values = c(\"#F5C000\", \"#0035F5\"))+\n    labs(x = \"Bundesland\", y = \"relative Häufigkeit\", fill = \"Mitglied\\nim Sportverein\")\n\nplot_kreuztabelle\n\n\n\n\n\n\n\n\nDie Visualisierung der Daten macht deutlich, dass in Thüringen prozentual weniger Befragte Mitglied in einem Sportverein sind als in Rheinland-Pfalz. Das legt nahe, dass die beiden Variablen zusammenhängen. Als nächstes prüfen wir mit einem Signifikanztest, ob dies tatsächlich der Fall ist.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Kreuztabellen</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen nominalen und ordinalen Variablen.html#signifikanztests-für-kreuztabellen-in-r-berechnen",
    "href": "Zusammenhänge zwischen nominalen und ordinalen Variablen.html#signifikanztests-für-kreuztabellen-in-r-berechnen",
    "title": "6  Zusammenhänge zwischen nominalen und ordinalen Variablen: Kreuztabellen",
    "section": "6.3 Signifikanztests für Kreuztabellen in R berechnen",
    "text": "6.3 Signifikanztests für Kreuztabellen in R berechnen\nUm zu testen, ob die beiden Variablen zusammenhängen oder unabhängig voneinander sind, nutzen wir, wie oben im Video erläutert, den Chi²-Test, den wir mit der chisq.test()-Funktion ausführen können. Dieser Funktion können wir unsere Tabelle von oben (tabelleSportNachBundesland) übergeben. Die Funktion gibt eine Liste zurück, die wir in einem Objekt speichern sollten. Indem wir das Objekt danach aufrufen, wird uns das Ergebnis angezeigt.\n\n# Berechnet einen Chi²-Test und speichert das Ergebnis in einer Liste namens \"kt_test\"\nkt_test &lt;- chisq.test(tabelleSportNachBundesland)\n\nkt_test\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tabelleSportNachBundesland\nX-squared = 53.925, df = 1, p-value = 0.0000000000002083\n\n\nDas Ergebnis enthält drei Informationen:\n\nDen Chi²-Wert (hier 53,925). Hierbei handelt es sich um die songeannte Teststatistik des Chi²-Tests. Wie im Video erklärt, wird er aus der Abweichung zwischen beobachteten und erwarteten Werten berechnet.\nDie Anzahl der sogenannten Freiheitsgrade (df für degrees of freedom; hier 1). Freihtsgrade sind wieder eines der Konzepte in der Statistik, die leider nicht wirklich intuitiv sind. Unten finden Sie eine Definition.\nDer p-Wert (hier 0,0000000000002083). Wie im lezten Kapitel beschrieben, sprechen wir ab p-Werten von 0,05 von statistischer Signifikanz. Üblicherweise wird nur angegeben, ob ein p-Wert größer als 0,05, also nicht-signifikant, kleiner als 0,05, kleiner als 0,01 oder kleiner als 0,001ist. Hier würden wir also lediglich, dass p &lt; 0,001 und entsrepchend festhalten, dass der Zusammenhang zwischen dem Bundesland, aus dem die Befragten stammen, und ihrer Mitgliedschaft in einem Sportverein signifikant ist. Übrigens: Dadurch, hätten wir oben nicht options(scipen = 999) angegeben, würde der p-Wert hier als 2.083e-13 ausgegeben werden. Das steht für die Zahl 2,083, vor die 13 Nullen geschrieben werden.\n\nMit diesen drei Werten können wir den Test wie folgt verschriftlichen:\n\nEin Chi²-Test zeigt, dass ein signifikanter Zusammenahang zwischen dem Bundesland, aus dem die Befragten stammen, und ihrer Mitgliedschaft in einem Sportverein besteht (Chi²(1) = 53,925; p &lt; 0,001).\n\n\n\n\n\n\n\nFreiheitsgrade\n\n\n\nStark simplifiziert sagen sie etwas darüber aus, wie viele Informationen in die Schätzung eines Parameters (hier Chi²) eingeflossen sind. Etwas genauer: Sie geben an, wie viele Werte wir frei variieren können, um auf das tatsächliche Ergebnis zu kommen. Stellen Sie sich z.B. vor, Sie haben 3 Zahlen und wissen nur, dass deren Mittelwert 5 ist. Daraus können Sie schließen, dass die Summe 15 sein muss (denn: 3 x 5 = 15). Nun gibt es aber unendlich viele Möglichkeiten, drei Zahlen auszusuchen, deren Summe genau 15 ist. Die erste Zahl könnte z.B. eine 3 sein und die zweite eine 11. Nun muss die letzte Zahl eine 1 sein, um auf die Summe 15 bzw. den Mittelwert 5 zu kommen. Da wir uns die ersten beiden Zahlen völlig frei aussuchen durften, die dritte dann aber fest vorgegeben war, hat dieser Mittelwert 2 Freiheitsgrade. Die Freiheitsgrade des Chi²-Tests ergeben sich immer aus der Anzahl der Ausprägungen der beiden Variablen: Von beiden wird 1 subtrahiert, dann werden diese Werte miteinander multipliziert. Hier also (2-1) * (2-1) = 1\n\n\nAls nächsten benötigen wir noch die Effektstärke Cramers V. Das effectsize-Paket, das wir oben installiert haben, enthält eine Funktion dazu (cramers_v), der wir unsere Tabelle übergeben müssen. Zusätzlich geben wir als weiteres Argument alternative = \"two.sided\" an. Damit sagen wir der Funktion, dass wir bevor wir mit unseren Berechnungen angefangen haben keine gerichtete Hypothese hatten.\n\n# Berechnet die Effektstärke \"Cramers V\"\ncramersVSportBundesand &lt;- cramers_v(tabelleSportNachBundesland, alternative = \"two.sided\")\n\ncramersVSportBundesand\n\nCramer's V (adj.) |       95% CI\n--------------------------------\n0.17              | [0.12, 0.22]\n\n\nDas Ergebnis der Funktion besteht aus zwei Teilen: Erstens dem Wert von Cramers V (hier 0,17). Gemäß den Angaben im Video können wir also von einem schwachen Zusammenhang sprechen. Zweitens gibt uns die Funktion einen Bereich von 0,12 bis 0,22 aus, den sogenannte 95% Konfidenzintervall (CI Englisch für confidence interval). Hier haben wir es, mal wieder, mit einem dieser unintuitiven Konzepte der Statistik zu tun.\n\n\n\n\n\n\nKonfidenzintervalle\n\n\n\nKonfidenzintervalle sind ein Maß, das Auskunft darüber gibt, wie viel Unischerheit mit einer Schätzung (hier z.B. die Schätzung von Cramers V) verbunden ist. Sie basieren auf einer Kernidee der Statistik, nämlich dass jede Schätzung auf einer Stichprobe basiert und wir langfristig nur Sicherheit gewinnen können, indem wir immer wieder verschiedene Stichproben ziehen und bestimmte Parameter (z.B. einen Mittelwert oder eben eine Effektstärke wie Cramers V) schätzen. Die Definition lautet daher, dass langfristig 95% aller berechneten Konfidenzintervalle den geschätzten Parameter enthalten.\n\n\nMit dem Ergebnis der cramers_v()-Funktion können wir die Verschriftlichung unseres Ergebnisses von oben erweitern:\n\nEin Chi²-Test zeigt, dass ein schwacher signifikanter Zusammenahang zwischen dem Bundesland, aus dem die Befragten stammen, und ihrer Mitgliedschaft in einem Sportverein besteht (Chi²(1) = 53,925; p &lt; 0,001; Cramers V = 0,17; 95%KI = [0,12; 0,22]).\n\nFür die Darstellung des Chi²-Tests in einem Forschungsbericht reicht dieser Satz im Prinzip aus. Allerdings ist es für Leserinnen und Leser wissenschaftlicher Texte immer leichter, eine Berechnung nachzuvollziehen, wenn Sie deskriptive Angaben machen. Im Fall von Kreuztabellen bietet sich dafür, wer hätte es gedacht, eine Tabelle an.\nDie beobachteten Werte können wir der Tabelle entnehmen, die wir ganz am Anfang erstellt haben (tabelleSportNachBundesland). Wie im Video besprochen sind diese Werte nur bedingt aussagekräftig, sodass wir auch relative Häufigkeiten angeben sollten. Diese können wir relativ einfach in dem Objekt berechnen, dass wir oben für das Stapeldiagramm angelegt haben (df_plot_kreuztabelle). Als ersten nutzen wir group_by(), um die Daten anch Bundesland zu gruppieren. Anschließend können wir die absoluten Häufigkeiten pro Zelle (gespeichert in Anzahl) durch die Gesamtsumme aller Befragten aus einem Bundesland teilen (sum(Anzahl)). Die erwarteten Werte sind dagegen wieder einfacher, denn sie sind Teil der Liste, die uns die chisq.test()-Funktion zurückgegeben hat. Wir können Sie aufrufen, indem wir das entsprechende Listenelement ansprechen: kt_test$expected.\n\n# Beobachtete Werte\ntabelleSportNachBundesland\n\n     Sportverein\nBula  nein  ja\n  RLP  649 385\n  TH   636 172\n\n# Berechnet beobachtete Werte in %\ndf_plot_kreuztabelle &lt;- df_plot_kreuztabelle |&gt;\n  group_by(Bula) |&gt;\n  mutate(Prozent = round((Anzahl / sum(Anzahl))*100,2))\n\ndf_plot_kreuztabelle$Prozent\n\n[1] 62.77 37.23 78.71 21.29\n\n# Erwartete Werte\nkt_test$expected\n\n     Sportverein\nBula      nein       ja\n  RLP 721.3301 312.6699\n  TH  563.6699 244.3301\n\n\nDiese Werte können wir dann in eine Tabelle übertragen:\n\n\n\n\n\n\n\n\n\nBundesland\nkein Mitglied im Sportverein\nMitglied im Sportverein\nGesamt\n\n\n\n\nRheinland-Pfalz\n\n\n\n\n\nBeobachtet\n649\n385\n1034\n\n\nBeobachtet in %\n62,77 %\n37,23 %\n\n\n\nErwartet\n721,33\n312,67\n\n\n\nThüringen\n\n\n\n\n\nBeobachtet\n636\n172\n808\n\n\nBeobachtet in %\n78,71 %\n21,29 %\n\n\n\nErwartet\n563,67\n244,33",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Kreuztabellen</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html",
    "href": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html",
    "title": "7  Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "",
    "text": "7.1 Statistische Grundlagen",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#deskription-und-visulisierung-der-daten",
    "href": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#deskription-und-visulisierung-der-daten",
    "title": "7  Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "7.2 Deskription und Visulisierung der Daten",
    "text": "7.2 Deskription und Visulisierung der Daten\nWir starten wie im letzten Kapitel damit, unsere R-Umgebung vorzubereiten, indem wir das tidyverse laden, den Datensatz einlesen und die Optionen so ändern, dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n\n# Lädt das tidyverse\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\n\nEine gute Möglichkeit, den Zusammenhang zwischen zwei metrischen Variablen grafisch darzustellen, ist durch ein sogenanntes Streudiagramm bzw. eine Punktewolke. Dabei wird eine Variable auf der x- und die andere auf der y-Achse dargestellt. Schauen wir uns das einmal am Besipel der Spalten A202_01 und A202_02 an, in denen das Interesse an Nachrichten über lokale bzw. nationale Geschehnisse abgefragt wurde.1 Zunächst benennen wir beiden Spalten um. Anschließend rufen wir ggplot() auf, geben dort innerhalb von aes() an, welche Variable wir auf der x- bzw. y-Achse darstellen wollen. Dann müssen wir nur noch geom_point() ergänzen. Mit theme_minimal() und labs() verschönern wir unseren Plot gleich noch ein wenig.\n\n# Benennt die Spalten A202_01 und A202_02 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(interesseLokal = A202_01,\n         interesseDE = A202_02)\n\n# Erstellt ein Streudiagramm der beiden Spalten\nstreudiagrammInt &lt;- df_lokal |&gt;\n  ggplot(aes(x = interesseLokal, y = interesseDE))+\n  geom_point()+\n  theme_minimal()+\n  labs(x = \"Interesse an lokalen Geschehnissen\", y = \"Interesse an nationalen Geschehnissen\")\n\nstreudiagrammInt\n\n\n\n\n\n\n\n\nDas sieht gar nicht schlecht aus. Wir sehen allerdings, dass relativ viele Befragte die Skala vollständig ausgreizt haben und den jeweiligen Maximalwert (101) angegeben haben. Daran können wir auch ein Verhalten von geom_point() erhnen, das tendenziell problematisch ist. Und zwar werden identische Datenpunkte einfach übereinander gelegt. Wenn also zwei Personen die exakt gleichen Antworten gegeben haben, zeigt geom_point() nur einen Punkt an.\nSchauen wir uns das mal am Beispiel der Spalten A208_01 und A208_03 an. In beiden Spalten wurden Aspekte der politischen Selbstwirksamkeit abgefragt, jeweils bezogen auf den eigenen Wohnort. Die konkreten Formulierungen lauteten:\n\nA208_01: Wichtige Fragen der Lokalpolitik kann ich gut verstehen und einschätzen.\nA208_03: Ich traue mir zu, mich an einem Gespräch über Fragen der Lokalpolitik aktiv zu beteiligen.\n\nSchauen wir uns einmal ein Streudiagramm dieser beiden Variablen an. Da die Items Teil einer größeren Abfrage waren und üblicherweise nicht einzeln ausgwertet werden würden, sind die Beschriftungen hier sehr pragmatisch gewählt.\n\n# Benennt die Spalten A208_01 und A208_03 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(polSelbstw1 = A208_01,\n         polSelbstw3 = A208_03)\n\n# Erstellt ein Streudiagramm der beiden Spalten\n\nstreudiagrammSelbstw &lt;- df_lokal |&gt;\n  ggplot(aes(x = polSelbstw1, y = polSelbstw3))+\n  geom_point()+\n  theme_minimal()+\n  labs(x = \"lokale politische Selbstwirksamkeit Item 1\", y = \"lokale politische Selbstwirksamkeit Item 3\")\n\nstreudiagrammSelbstw\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nHier wird das Problem an geom_point() deutlich. Die Grafik verrät uns herzlich wenig. Wir haben nach wie vor keinerlei Vorstellung davon, wie stark der Zusammenhang sein könnte. Wir erfahren lediglich, dass jede mögliche Wertekombination im Datensatz enthalten ist. Es gibt also z.B. Leute, die auf eins der Items mit 1 (= “stimme überhaupt nicht zu”) und auf das andere mit 5 (= “stimme sehr zu”) geantwortet haben.\nIn solchen Fällen ist es sinnvoll, die Alternative geom_jitter() zu nutzen. Jitter ist Englisch für zittern und genau das tut die Funktion: Sie verschiebt die einzelen Punkte minimal nach oben, unten, rechts und links (lässt sie also zittern), sodass wir besser erkennen können, wie die Daten verteilt sind. Um das umzusetzen, müssen wir nur geom_point() durch geom_jitter() ersetzen.\n\n# Erstellt ein Streudiagramm der beiden Spalten mit geom_jitter()\n\nstreudiagrammSelbstw &lt;- df_lokal |&gt;\n  ggplot(aes(x = polSelbstw1, y = polSelbstw3))+\n  geom_jitter()+\n  theme_minimal()+\n  labs(x = \"lokale politische Selbstwirksamkeit Item 1\", y = \"lokale politische Selbstwirksamkeit Item 3\")\n\nstreudiagrammSelbstw\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWir sehen nun relativ eindeutig, dass es einen Zusammenhang zwischen den beiden Variablen zu geben scheint.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#korrelationen-berechnen",
    "href": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#korrelationen-berechnen",
    "title": "7  Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "7.3 Korrelationen berechnen",
    "text": "7.3 Korrelationen berechnen\n\n7.3.1 Pearson Korrelationen\nPearson Korrelationen, also normale Korrelationen zwischen zwei metrischen Variablen, können wir mit der cor.test()-Funktion berechnen, der wir mit den Argumenten xund y zwei Variablen übergeben müssen. Die Funktion gibt uns dann eine Liste zurück. Das Element estimate enthält den Korrelationskoeffizienten. Den dazugehörigen p-Wert können wir über das Element p.value abrufen. Beides speichern wir hier in einem neuen Objekt, indem wir cor.test() innerhalb von summarise() aufrufen. Der Übersicht halber runden wir die jeweiligen Ergebnisse auf 3 Nachkommastellen.\n\n# Erstellt ein neues Objekt in dem der Korrelationskoeffizient und der zugehörigen p-Wert für die Korelation zwischen interesseLokal und interesseDE gespeichert wird.\nkorrelationInt &lt;- df_lokal |&gt;\n  summarise(Korrelation = round(cor.test(x = interesseLokal, \n                                         y = interesseDE)$estimate, 3),\n            pWert = round(cor.test(x = interesseLokal, \n                                   y = interesseDE)$p.value, 3))\n\nkorrelationInt\n\n  Korrelation pWert\n1       0.422     0\n\n\nDie Korrelation beträgt demnach 0,422. Wir können also von einer mäßigen Korrelation sprechen. Der gerundete p-Wert wird als 0 angegeben. Da p-Werte aber immer zwischen 0 und 1 liegen müssen und nie genau 0 (oder 1) sein können, können wir dem entnehmen, dass die Abweichung von 0 erst nach der dritten Nachkommastelle kommt2. Entsprechend würden wir den p-Wert als &lt;0,001 angeben. Bevor wir die Ergebnisse verschriftlichen können, sollten wir noch die Mittelwerte und Standardabweichungen der beiden Variablen berechnen, die immer zusätzlich angegeben werden sollten.\n\n# Berechnet Mittelwert und Standardabweichung der Variablen interesseLokal und interesseDE\n\nMWsInteresse &lt;- df_lokal |&gt;\n  summarise(MWIntLokal = round(mean(interesseLokal, na.rm = TRUE), 2),\n            SDIntLokal = round(sd(interesseLokal, na.rm = TRUE), 2),\n            MWIntDE = round(mean(interesseDE, na.rm = TRUE), 2),\n            SDIntDE = round(sd(interesseDE, na.rm = TRUE), 2))\n\nMWsInteresse\n\n  MWIntLokal SDIntLokal MWIntDE SDIntDE\n1      81.83      20.34   80.73   20.91\n\n\nDamit haben wir alle notwendigen Informationen, um die Ergebnisse zu verschriftlichen:\n\nDurch eine Korrelation wurde geprüft, ob ein Zusammenhang zwischen dem Interesse an lokalen Geschehnissen (M = 81,83; SD = 20,34) und dem Interesse an nationalen Geschehnissen (M = 80,73; SD = 20,91) besteht. Das Ergebnis zeigt, dass ein mäßig starker, signifikanter Zusammenhang besteht (r = 0,422; p &lt; 0,001).\n\n\n\n7.3.2 Rangkorrelationen\nBei der Korrelation, die wir gerade berechnet haben, handelt es sich um eine normale Korrelation zwischen zwei metrischen Variablen. Wie im Video besprochen, können wir auch sogeannte Rangkorrelationen berechnen, wenn mindestens eine der beiden Variablen ordinal skaliert ist. Dazu müssen wir der cor.test()-Funktion lediglich das zusätzliche Argument method mit dem Wert \"spearman\" übergeben.\n\n# Benennt die Spalten A604 und A605 um \n\ndf_lokal &lt;- df_lokal |&gt;\n  rename(Wohndauer = A604,\n         Ortsgroeße = A605)\n\n\n# Erstellt ein neues Objekt in dem der Rangkorrelationskoeffizient und der zugehörigen p-Wert für die Korelation zwischen Wohndauer und Ortsgroeße gespeichert wird.\n\n\nkorrelationOrt &lt;- df_lokal |&gt;\n  summarise(Korrelation = round(cor.test(x = Wohndauer, \n                                         y = Ortsgroeße, \n                                         method = \"spearman\")$estimate, 3),\n            pWert = round(cor.test(x = interesseLokal, \n                                   y = interesseDE,\n                                   method = \"spearman\")$p.value, 3))\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `Korrelation = round(...)`.\nCaused by warning in `cor.test.default()`:\n! Kann exakten p-Wert bei Bindungen nicht berechnen\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nkorrelationOrt\n\n  Korrelation pWert\n1      -0.089     0\n\n\nWenn wir den Befehl ausführen, gibt R eine Warnung aus. Der Kern der Botschaft lautet: Kann exakten p-Wert bei Bindungen nicht berechnen. Damit weist R uns lediglich darauf hin, dass der berechnete p-Wert nur eine Schätzung und keine genaue Berechnung ist. Sie können die Warnung entweder ignorieren, oder dem Aufruf von cor.test() das Argument exact = FALSE hinzufügen. Beachten Sie, dass das nur nötig ist, wenn Sie eine Spearman-Korrelation berechnen.\nBevor wir die Ergebnisse berichten können, müssen wir wieder deskriptive Werte berechnen. Anders als im Beispiel oben, entscheiden wir uns diesmal für den Median, da es sich um ordinale Variablen handelt.\n\n# Berechnet den Median, der Variablen Wohndauer und Ortsgroeße\n\nmedianDauerGroeße &lt;- df_lokal |&gt;\n  summarise(medianDauer = median(Wohndauer, na.rm = TRUE),\n            medianGroeße = median(Ortsgroeße, na.rm = TRUE))\n\nmedianDauerGroeße\n\n  medianDauer medianGroeße\n1           6            3\n\n\nNun haben wir alle relevanten Informationen, um das Ergebnis zu verschriftlichen.\n\nDurch eine Rangkorrelation wurde geprüft, ob ein Zusammenhang zwischen der Wohndauer (Median = 6; “mehr als 20 Jahre”) und der Größe des Wohnorts (Median = 3; Kleinstadt) besteht. Die beiden Variablen hängen signifikant, aber sehr schwach, negativ zusammen (r = -0,089; p &lt; 0,001).\n\n\n\n7.3.3 Korrelationskoeffizienten visualisieren\nOben haben wir uns bereits angeschaut, wie wir ein einfaches Streudiagramm von zwei Variablen erstellen können. Wenn wir eine Korrelation berechnen, ist es oft sinnvoll, diese auch grafisch darzustellen. Dazu können wir unser Diagramm von oben durch geom_smooth() mit dem Argument method = \"lm\" ergänzen. Diese Funktion zeichnet eine Linie ein. Durch method = \"lm\" geben wir an, dass wir eine Gerade zeichnen wollen, die der Korrelation entspricht. Um diese Linie herum wird ein grauer Bereich eingezeichnet. Hierbei handelt es sich um das Konfidenzintervall, das wir im letzten Kapitel kennengelernt haben.\n\n# Erstellt ein Streudiagramm der beiden Variablen interesseLokal und interesseDE mit eingezeichneter Korrelationsgerade\n\nstreudiagrammInt &lt;- df_lokal |&gt;\n  ggplot(aes(x = interesseLokal, y = interesseDE))+\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  theme_minimal()+\n  labs(x = \"Interesse an lokalen Geschehnissen\", y = \"Interesse an nationalen Geschehnissen\")\n\nstreudiagrammInt\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#korrelationen-erkennen-und-einschätzen",
    "href": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#korrelationen-erkennen-und-einschätzen",
    "title": "7  Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "7.4 Korrelationen erkennen und einschätzen",
    "text": "7.4 Korrelationen erkennen und einschätzen\nKorrelationen wie wir sie in diesem Kapitel kennengelernt haben anhand von Daten zu erkennen, ist gar nicht so einfach. Gleichzeitig können sehr kleine p-Werte dazu verleiten, die tatsächliche Bedeutung eines Zusammenhangs zu überschätzen. Beispielsweise hat eine Auswertung von Meta-Analysen in der Kommunikationswissenschaft ergeben, dass die durchschnittliche Effektstärke im Fach gerade einmal r = 0,21 beträgt (Rains et al., 2018). Grafisch dargestellt sieht eine solche Korrelation etwa so aus:\n\n\n\n\n\n\n\n\n\nDie beiden fiktiven Variablen hängen zwar zusammen, aber wirklich leicht zu erkennen ist das optisch nicht. Zusammenhänge zu erkennen und Gefühlt dafür zu bekommen, wie verschieden starke Korrelationen eigentlich aussehen ist vor allem Übungssache. Wenn Sie Lust haben, können Sie mit dem kleinen Spiel unten etwas üben.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#footnotes",
    "href": "Zusammenhänge zwischen ordinalen und metrischen Variablen.html#footnotes",
    "title": "7  Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen",
    "section": "",
    "text": "Auf die Datentransformation aus der Präsenzübung verzichten wir an dieser Stelle.↩︎\nIn diesem konkreten Fall folgt die erste Ziffer, die nicht Null ist an Stelle 81. Der p-Wert lautet: 0,000000000000000000000000000000000000000000000000000000000000000000000000000000008204762↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Zusammenhänge zwischen nominalen und ordinalen Variablen: Korrelationen</span>"
    ]
  },
  {
    "objectID": "Regressionen I.html",
    "href": "Regressionen I.html",
    "title": "8  Regressionen I",
    "section": "",
    "text": "8.1 Statistische Grundlagen",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionen I</span>"
    ]
  },
  {
    "objectID": "Regressionen I.html#vorbereitung",
    "href": "Regressionen I.html#vorbereitung",
    "title": "8  Regressionen I",
    "section": "8.2 Vorbereitung",
    "text": "8.2 Vorbereitung\nWir starten wider damit, unsere R-Umgebung vorzubereiten, indem wir das tidyverse und das Paket effectsize laden, den Datensatz einlesen und die Optionen so ändern, dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n\n# Lädt das tidyverse\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Lädt effectsize\nlibrary(effectsize)\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\n\nAußerdem sollten wir die Variablen, mit denen wir Arbeiten umbenennen und ggf. transformieren.\nIm folgenden Beispiel werden wir drei Variablen brauchen, die Sie alle schon kennen: Die Spalten A202_01 und A202_02 enthalten das Interesse an lokalen und nationalen Geschehnissen. Die Spalte A601_01 das Geburtsjahr. Zunächst benennen wir die Spalten um.\n\n# Benennt die Spalten A202_01 und A202_02 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(interesseLokal = A202_01,\n         interesseDE = A202_02,\n         geburtsjahr = A601_01)\n\nAls nächstes transformieren wir die Spalten interesseLokal und interesseDE so, dass sie nicht mehr Werte von 1 bis 101 enthalten, sondern von 0 bis 1.\n\n# Transformiert die Spalten so, dass sie Werte von 0 bis 1 statt 1 bis 101 enthalten.\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(interesseLokalRec = (interesseLokal-1)/100,\n         interesseDERec = (interesseDE-1)/100)\n\nAbschließend transformieren wir das Geburtsjahr in das Alter um. Der Vorgang ist relativ komplex, Sie kennen ihn aber bereits aus Kapitel 3.\n\n# Transfomiert das Geburtsjahr zum Alter. Siehe Kapitel 3 für Details\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(alter = str_trim(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4)) |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr)) |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\n\nAnschließend können wir mit der Berechnung der Regression beginnen.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionen I</span>"
    ]
  },
  {
    "objectID": "Regressionen I.html#regressionen-berechnen",
    "href": "Regressionen I.html#regressionen-berechnen",
    "title": "8  Regressionen I",
    "section": "8.3 Regressionen berechnen",
    "text": "8.3 Regressionen berechnen\nUm Regressionen zu berechnen nutzen wir die lm()-Funktion. lm steht dabei für lineares Modell. Der Funktion müssen wir eine Formel übergeben, die immer nach demselben Schema aufgebut ist: links steht die abhängige Varibale, darauf folgt eine Tilde (~). Rechts von dieser stehen dann alle unabhängigen Varibalen. Die Tilde können Sie mit der Tastenkombinstion  +  schreiben. Das Ergebnis dieser Funktion sollten Sie immer in ein Objekt schreiben.\nWichtig ist, dass Sie der lm()-Funktion immer den Datensatz durch das data-Argument übergeben.\n\n8.3.1 Einfache lineare Regression\nSchauen wir uns zunächst an, wie wir eine einfache Regression mit einer unabhängigen Variable berechnen können.\nKonkret versuchen wir, das Interesse an lokalen Geschehnissen mit dem Alter der Befragten zu erklären. Bevor wir die Regression berechnen, schauen wir uns die Korrelation der beiden Variablen an. Das ist nicht immer zwingend notwendig, aber häufig sinnvoll.\n\n# Berechnet die Korrelation vom Interesse an lokalen Geschehnissen und dem Alter der Befragten\nkorrIntAlter &lt;- df_lokal |&gt;\n  summarise(Korrelation = round(cor.test(x = interesseLokalRec, \n                                         y = alter)$estimate, 3),\n            pWert = round(cor.test(x = interesseLokalRec, \n                                   y = alter)$p.value, 3))\n\nkorrIntAlter\n\n  Korrelation pWert\n1       0.204     0\n\n\nDie Korrelation ist schwach (r = 0,204) und signifikant (p &lt; 0,001).\nAls nächstes berechnen wir die Regression. Als Formel übergeben wir der Funktion interesseLokalRec ~ alter.\n\n# Berechnet eine Regression mit dem Interesse an lokalen Geschehnissen als AV und dem Alter als UV\nlmInteresseLokal &lt;- lm(interesseLokalRec ~ alter, data = df_lokal)\n\nMit der summary()-Funktion können wir nun das Ergebnis betrachten:\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteresseLokal)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter, data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.87735 -0.08972  0.04675  0.14720  0.28495 \n\nCoefficients:\n             Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept) 0.6744726  0.0158084  42.666 &lt;0.0000000000000002 ***\nalter       0.0027050  0.0003042   8.892 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1988 on 1821 degrees of freedom\n  (23 Beobachtungen als fehlend gelöscht)\nMultiple R-squared:  0.04161,   Adjusted R-squared:  0.04108 \nF-statistic: 79.06 on 1 and 1821 DF,  p-value: &lt; 0.00000000000000022\n\n\nGehen wir das Ergebnis einmal der Reihe nach durch. Ganz oben in der Ausgabe sehen sie die Überschrift Call:. Darunter sagt R uns, was wir genau berechnet haben.\nAls nächstes sehen wir die Residuals, also die Schätzfehler. Konkret sagt uns R etwas über die Verteilung. Für heute ignorieren wir diesen Teil.\nDanach wird es unter der Überschrift Coefficients spannend. Hier erfahren wir etwas über die Koeffizienten. Der erste, die sogenannte Regressionskonstante oder Intercept gibt an, welchen Wert die abhängige Variable dem Modell nach hat, wenn die unabhängige Variable den Wert 0 hat. Beachten Sie, dass das in unserem konkreten Fall wenig Sinn ergibt. Weder haben wir Personen im Alter von 0 Jahren befragt, noch ist es vorstellbar, dass das irgendwie möglich ist. Relevanter ist dagegen der Koeffizient für das Alter der Befragten. In der Spalte Estimate sehen Sie den Regressionskoeffizienten B. Auf den ersten Blick sieht dieser Wert sehr klein aus (B = 0,002), aber bedenken Sie, dass die abhängige Variable (Interesse an lokalen Geschehnissen) nur von 0 bis 1 geht. In der zweiten Spalte steht der dazugehörige Standardfehler (hier: 0.0003). Darauf folgt der t-Wert. Hierbei handet es sich um eine Teststatistik, die für den Signifikanztest berechnet wird. Das Prinzip kennen Sie schon vom Chi²-Test, nur dass hier eine andere Statistik berechnet wird. Der t-Wert wird uns hier als 8,892 angegeben. Als letztes sehen Sie den p-Wert. Hier sehen wir direkt, dass der Wert kleiner als 0,001 und somit signifikant ist.\nDie nächsten paar Zeilen können wir überspringen. Relevant wird es erst wieder bei der Angabe von R². Hier sehen wir zwei Werte: Multiple R-squared und Adjusted R-squared. Der erste Wert wurde im Video nur als R² bezeichnet. Und wir dort besprochen entspricht er genau der Korrelation unserer beiden Varibalen zum Quadrat:\n\n# Mutipliziert den oben berechneten Korrelationskoeefizienten mit sich selbst:\nkorrIntAlter$Korrelation * korrIntAlter$Korrelation\n\n[1] 0.041616\n\n\nDie unabhängige Variable erklärt also ungefähr 4 Prozent der Varianz der abhängigen Variable. Bei Adjusted R-suqred handelt es sich um den korrigierten R² Wert, den Sie nur angeben müssen, wenn Sie mehr als einen Prädiktor (also mehr als eine unabhängige Variable) nutzen.\nIn der letzten Zeile finden Sie einen Test des Gesamtmodells. Zunächst steht dort die F-Statistic. Ähnlich wie Chi² und oben t, handelt es sich hierbei um eine weitere Teststatistik, diesmal eben für das Gesamtmodell. Der zugehörige Wert ist hier 79,06. Dahinter stehen die zugehörigen Freiheitsgerade (DF für degrees of freedom; 1 und 1821), die etwas über die Anzahl der Prädiktoren und die Stichprobengröße sagen. Schließlich sehen Sie einen Weiteren p-Wert (&lt; 0,001), der uns verrät, dass das Gesamtmodell signifikant ist.\nDamit haben wir schon fast alle relevanten Infos, um das Ergebnis zu verschriftlichen. Was fehlt, ist nur der standardisierte Koeffizient beta für das Alter. Diesen können wir mit der standardize_parameters()-Funktion aus dem effectsize-Paket anzeigen lassen. Dieser Funktion übergeben wir das Objekt, in das wir oben das Ergebnis der Regression gespeichert habe:\n\n# Zeigt den standardisierten Koeffizienten beta für das Alter an. \nstandardize_parameters(lmInteresseLokal)\n\n# Standardization method: refit\n\nParameter   | Std. Coef. |        95% CI\n----------------------------------------\n(Intercept) |  -1.98e-16 | [-0.04, 0.04]\nalter       |       0.20 | [ 0.16, 0.25]\n\n\nIn der Spalte Std. Coef. (für standardized Coefficient) zeigt R uns den standardisierten Koeffizienten beta an, der hier 0,20 beträgt. Wie im Video angesprochen handelt es sich dabei genau um die Korrelation zwischen den beiden Variablen. Aber beachten Sie, dass das nur bei einfachen Regressionen der Fall ist. Zusätzlich gibt uns die Funktion ein Konfidenzintervall aus\nTragen wir die Ergebnisse also einmal zusammen: Das Alter hat einen signifikanten, aber schwachen positiven Effekt auf das Interesse an lokalen Geschehnissen. Ältere Menschen tendieren also eher dazu, sich dafür zu interessieren. Außerdem ist das Gesamtmodell signifikant, erklärt aber nur etwa 4 Prozent der Varianz. Etwas formaler können wir die Ergebniss so verschriftlichen:\n\nDurch eine Regression wurde geprüft, ob das Alter der Befragten (M = 49,66; SD = 15,31) einen Einfluss auf ihr Interesse an lokalen Geschhnissen hat (M = 0,81; SD = 0,20). Das Modell war insgesamt signifikant (F(1, 1821) = 79,06; p &lt; 0,001), konnte aber nur etwa 4 Prozent der Varianz erklären (R² = 0,042). Der Effekt des Alters war signifikant, aber schwach (beta = 0,20; p &lt; 0,001).\n\n\n\n8.3.2 Multiplie Regression\nDas Vorgehen bei multiplen Regressionen ist quasi identisch. Um weitere Prädiktoren hinzuzufügen, können wir unsere Formel ganz einfach erweitern. Schauen wir es uns hier einmal an, indem wir der Regression von oben das Interesse an Geschehnissen in Deutschland als Prädiktor hinzufügen:\n\n# Erweitert die Regression von oben um das Interesse an Geschehnissen in Deutschland\nlmInteresseLokalErweitert &lt;- lm(interesseLokalRec ~ alter + interesseDERec, data = df_lokal)\n\nSchauen wir uns das Ergebnis an:\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteresseLokalErweitert)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter + interesseDERec, data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.89259 -0.08302  0.04036  0.10736  0.51708 \n\nCoefficients:\n                Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)    0.4243107  0.0198217  21.406 &lt; 0.0000000000000002 ***\nalter          0.0015028  0.0002866   5.244          0.000000176 ***\ninteresseDERec 0.3886329  0.0209870  18.518 &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1824 on 1820 degrees of freedom\n  (23 Beobachtungen als fehlend gelöscht)\nMultiple R-squared:  0.1936,    Adjusted R-squared:  0.1927 \nF-statistic: 218.4 on 2 and 1820 DF,  p-value: &lt; 0.00000000000000022\n\n\nVerglichen mit dem Ergebnis von oben sollten Ihnen hier einige Dinge auffallen:\n\nDas (korrigierte) R² ist deutlich höher! Das ist auch nachvollziehbar, schließlich haben wir schon im letzten Kapitel gesehen, dass das Interesse an Geschehnissen in Deutschland und das Interesse an lokalen Geschehnissen mäßig stark korrelieren.\nEntsprechend hat sich auch der Test des Gesamtmodells leicht geändert (anderer F-Wert, andere Freiheitsgrade).\nDer Effekt des Alters ist etwas schwächer als im ersten Modell.\nDer Effekt des Interesses an Geschehnissen in Deutschland deutlich stärker als der des Alters. Aber: Beachten Sie, dass wir bisher nur die unstandardisierten Koeffizienten betrachtet haben!\n\nAußerdem sollten Sie eine wichtige Sache beachten: Die Interpretation der Koeffizienten ändert sich in der multiplen Regression leicht! Im Video haben wir gesagt, dass die Effekte jeweils so interpretiert werden können, dass die Effekte der anderen Variablen “rausgerechnet” werden. Ganz konkret ist es so, dass die Effekte jeweils angeben, wie stark der Einfluss einer Variable ist, wenn alle anderen Variablen den Wert 0 annehmen. Wie oben schon, haben wir hier allerdings das Problem, dass der Wert 0 nicht immer sinnvoll ist, z.B. beim Alter. Dieses Problem haben die standardisierten Koeffizienten nicht.\nSchauen wir die uns also noch an:\n\n# Zeigt den standardisierten Koeffizienten beta für die beiden Prädiktoren an\nstandardize_parameters(lmInteresseLokalErweitert)\n\n# Standardization method: refit\n\nParameter      | Std. Coef. |        95% CI\n-------------------------------------------\n(Intercept)    |  -2.65e-16 | [-0.04, 0.04]\nalter          |       0.11 | [ 0.07, 0.16]\ninteresseDERec |       0.40 | [ 0.36, 0.44]\n\n\nFür die Berechnung der standardisierten Koeffizienten, werden die Varibalen selbst standardisiert. Das bedeutet, dass sie so transformiert werden, dass sie den Mittelwert 0 und die Standardabweichung 1 haben. Das heißt, der Effekt einer Varibale entspricht nun nicht mehr dem Effekt, wenn alle anderen Varibalen den Wert 0 haben, sondern wenn diese Variablen ihren Mittelwert annehmen.\nSchauen wir uns nun aber die eigentlichen Effekte an. Wie wir oben schon erahnen konnten, ist der Effekt des Alters etwas schwächer. Er wird nun nur noch als 0,11 angegeben. Der Effekt des Interesses an Geschehnissen in Deutschland beträgt dagegen 0,40. Er ist also mäßig stark. Beachten Sie, dass die beta-Werte nun nicht mehr der einfachen Korrelation zwischen den jeweiligen Variablen entsprechen.\nVerschriftlichen wir die Ergebnisse noch einmal:\n\nDurch eine Regression wurde geprüft, ob das Alter der Befragten (M = 49,66; SD = 15,31) und das Interesse an Geschehnissen in Deutschland (M = 0,80; SD = 0,21) einen Einfluss auf ihr Interesse an lokalen Geschhnissen haben (M = 0,81; SD = 0,20). Das Modell war insgesamt signifikant (F(2, 1820) = 218,4; p &lt; 0,001) und konnte etwa 19,3 Prozent der Varianz erklären (R² = 0,193). Der Effekt des Alters war signifikant, aber schwach (beta = 0,11; p &lt; 0,001). Dagegen hatte das Interesse an Geschehnissen in Deutschland einen mäßigen Effekt (beta = 0,40; p &lt; 0,001).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regressionen I</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html",
    "href": "Regressionen II.html",
    "title": "9  Regressionen II",
    "section": "",
    "text": "9.1 Vorbereitung\nWir starten wider damit, unsere R-Umgebung vorzubereiten, indem wir das tidyverse und das Paket effectsize laden, den Datensatz einlesen und die Optionen so ändern, dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n# Lädt das tidyverse\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Lädt effectsize\nlibrary(effectsize)\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\nWir verwenden wieder einige Spalten, die Sie mittlerweile kennen. Auf die entsprechenden Transformationen gehen wir daher nicht erneut ein. Die einzige Änderung zu vorherigen Versionen dieser Transformationen ist, dass wir beim Geschlecht auch den Wert “divers” als fehlend deklarieren. Das liegt ganz einfach daran, dass wir nur sehr wenige Fälle in dieser Gruppe haben und die Interpretation dadurch für dieses Beispiel unnötig kompliziert wird.\n# Benennt die Spalten A202_01 und A202_02 um\ndf_lokal &lt;- df_lokal |&gt;  \n  rename(interesseLokal = A202_01,\n         interesseDE = A202_02,\n         geburtsjahr = A601_01)\n\n\n# Transformiert die Spalten so, dass sie Werte von 0 bis 1 statt 1 bis 101 enthalten.\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(interesseLokalRec = (interesseLokal-1)/100,\n         interesseDERec = (interesseDE-1)/100)\n\n\n# Transfomiert das Geburtsjahr zum Alter. Siehe Kapitel 3 für Details\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(alter = str_trim(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = str_sub(geburtsjahr, -4)) |&gt;\n  mutate(geburtsjahr = as.integer(geburtsjahr)) |&gt;\n  mutate(geburtsjahr = ifelse(geburtsjahr &lt; 1000, geburtsjahr+1000, geburtsjahr)) |&gt;\n  mutate(alter = 2022 - geburtsjahr)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `geburtsjahr = as.integer(geburtsjahr)`.\nCaused by warning:\n! NAs durch Umwandlung erzeugt\n\n# Erstellt eine neue Spalte aus der Geschlechtsabfrage. Erst werden die Werte \"keine Angabe\" und \"divers\" als fehlend deklariertm dann wird ein Faktor mit den übrigen  Kategorien erstellt\n\ndf_lokal &lt;- df_lokal |&gt;\n  mutate(geschlecht = ifelse(A602 == 3 | A602 == 4, NA, A602)) |&gt;\n  mutate(geschlecht = factor(geschlecht, labels = c(\"männlich\", \"weiblich\")))",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html#multiple-regressionen-mit-nominalem-prädiktor",
    "href": "Regressionen II.html#multiple-regressionen-mit-nominalem-prädiktor",
    "title": "9  Regressionen II",
    "section": "9.2 Multiple Regressionen mit nominalem Prädiktor",
    "text": "9.2 Multiple Regressionen mit nominalem Prädiktor\nGrundsätzlich können wir nominale Prädiktoren ganz normal dem Regressionsmodell hinzufügen, wie wir es auch bei den metrischen Prädiktoren gemacht haben. Schauen wir uns das einmal an, indem wir die Regression aus dem letzten Kapitel um das Geschlecht als UV erweitern:\n\n# Berechnet eine Regression mit dem Interesse an lokalen Geschehnissen als AV und dem Alter, dem Interesse an Geschehnissen in Deutschland und dem Geschlecht als UVs\nlmInteresseLokal &lt;- lm(interesseLokalRec ~ alter + interesseDERec + geschlecht, data = df_lokal)\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteresseLokal)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter + interesseDERec + geschlecht, \n    data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.89442 -0.07994  0.03707  0.10846  0.50426 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)        0.4019646  0.0209543  19.183 &lt; 0.0000000000000002 ***\nalter              0.0016333  0.0002896   5.639         0.0000000198 ***\ninteresseDERec     0.3880690  0.0210399  18.444 &lt; 0.0000000000000002 ***\ngeschlechtweiblich 0.0300721  0.0086718   3.468             0.000537 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1811 on 1791 degrees of freedom\n  (51 Beobachtungen als fehlend gelöscht)\nMultiple R-squared:  0.199, Adjusted R-squared:  0.1977 \nF-statistic: 148.4 on 3 and 1791 DF,  p-value: &lt; 0.00000000000000022\n\n\nWie Sie sehen, haben wir nun eine neue Zeile in der Tabelle über die Effekte, die mit geschlechtweiblich betitelt ist. Die Zeile gibt an, inwiefern sich die abhängige Variable (also das Interesse an loklaen Geschehnissen) ändert, wenn eine befragte Person nicht männlich, sondern weiblich ist. D.h., der positive Effekt in der Zeile geschlechtweiblich bedeutet, dass Frauen ein höheres Interesse an lokalen Geschehnissen haben als Männer.\nAußerdem ändert sich beim Einschluss von kategorialen Prädiktoren die Interpretation der Regressionskontante (Intercept). Im letzten Kapitel haben wir gelernt, dass dieser Wert dem durchschnittlichen Wert der abhängigen Variable entspricht, wenn alle unabhängigen Variablen den Wert 0 annehmen. Das ist grundsätzlich auch weiterhin der Fall, allerdings müssen wir nun beachten, dass dieser Wert nur noch dem Durchschnitt der Männer in der Stichprobe entspricht. Man sagt auch, dass es sich bei der Ausprägung männlich um die Referenzkategorie der Variable geschlecht handelt. Am einfachsten erkennen Sie das daran, dass oben in der Tabelle für die Effektstärke die andere Ausprägung (also “weiblich”) aufgeführt sind.\nWerfen wir als nächstes einen Blick auf die standardisierten Effektstärken:\n\n# Zeigt den standardisierten Koeffizienten beta für die  Prädiktoren an\nstandardize_parameters(lmInteresseLokal)\n\n# Standardization method: refit\n\nParameter             | Std. Coef. |         95% CI\n---------------------------------------------------\n(Intercept)           |      -0.08 | [-0.14, -0.02]\nalter                 |       0.12 | [ 0.08,  0.17]\ninteresseDERec        |       0.40 | [ 0.36,  0.44]\ngeschlecht [weiblich] |       0.15 | [ 0.06,  0.23]\n\n\nWir sehen einerseits, dass sich die Effektstärken des Alters und des Interesses an Geschehnissen in Deutschland im Vergleich zum Modell aus dem letzten Kapitel leicht geändert haben. Andererseits sehen wir nun auch eine Zeile für den Effekt der Variable geschlecht. Im Video im letzten Kapitel hatten wir festgehalten, dass standardisierte Effekte nur für metrische Prädiktoren sinnvoll angegeben werden können, da sie angeben, um wie viele Standardabweichungen sich die abhängige Variable ändert, wenn sich die entsprechende unabhängige Variable um eine Standardabweichung erhöht. Was bedeutet dieser Effekt also nun? Für nominale Variablen gibt die Funktion weiterhin aus, wie sich die abhängige Variable verändert, wenn sich die nominale Variable um eine Einheit erhöht bzw. verändert (also z.B. weiblich statt männlich). Der Unterschied zur Tabelle der Koeffiziente aus der summary()-Funktion besteht darin, dass die Veränderung hier jetzt nicht mehr einer Veränderung in den Rohdaten entspricht, sondern in Standardabweichungen ausgedrückt wird. Oder anders gesagt: verglichen mit Männern haben Frauen ein um 0,15 Standardabweichungen höheres Interesse an lokalen Geschehnissen.\nBeachten Sie, dass Sie beim Berichten von diesem Effekten ein bisschen Vorsicht walten lassen müssen. Wenn Sie ansonsten nur nicht-standardisierte Effekte berichten, haben Sie zwar kein Problem mit nominalen Prädiktoren, aber möglicherweise sind Ihre Ergebnisse dann etwas schwerer verständlich. Wenn Sie aber alle Effekte von metrischen Variablen in standardisierter Form ausdrücken, sollten Sie Ihren Leserinnen und Lesern unmissverständlich klar machen, dass sich die standardisierung bei den Effekten von nominalen Prädiktoren nur auf die abhängige Variable bezieht.\n\n\n\n\n\n\nOrdinale Prädiktoren\n\n\n\nGrundsätzlich können Sie ordinale Prädiktoren genauso behandeln wie nominale Prädiktoren. Sollte die ordinale Variable aber viele Ausprägungen haben (z.B. über 10 verschiedene Einkommensgruppen), wird die Interpretation der Ergebnisse schnell sehr komplex. In solchen Fällen kann es sinnvoll sein, entweder die Anzahl der Ausprägungen zu reduzieren (z.B. zu geringen, mittleren und hohen Einkommen) oder die Variable als quasi-metrisch zu behandeln. Sein Sie hierbei aber sehr vorsichtig bei der Interpretation!",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html#interaktionseffekte",
    "href": "Regressionen II.html#interaktionseffekte",
    "title": "9  Regressionen II",
    "section": "9.3 Interaktionseffekte",
    "text": "9.3 Interaktionseffekte\n\n9.3.1 Was sind Interaktionseffekte?\nOben im Kapitel haben wir bereits erfahren, dass Interaktionseffekt im Prinzip nichts anderes bedeutet, als dass der Effekt einer Variable von einer anderen abhängig ist. Stellen Sie sich z.B. vor, dass Sie herausfinden möchten, ob das Schauen eines Films mit Alterfreigabe FSK 16 einen Effekt auf die Stimmung von unter 16-Jährigen am nächsten Tag hat. Um den elterlichen Einfluss zu kontrollieren, erheben Sie auch, ob die Eltern im Anschluss an den Film mit ihren Kindern über das Gesehene gesprochen haben. Ein klassischer Interaktionseffekt würde dann vorliegen, wenn Sie zwar einen negativen Effekt des Films auf die Stimmung finden, aber nur in den Fällen, in denen kein Anschlussgespräch stattgefunden hat, wohingegen Kinder, die mit ihren Eltern über den Film gesprochen haben, entweder eine unveränderte oder sogar bessere Stimmung am nächsten Tag aufweisen.\nMathematisch funktionieren Interaktionseffekte so, dass das Produkt der beiden Variablen in das Modell aufgenommen wird.\n\n\n9.3.2 Interaktionseffekte berechnen\nUm einen Interaktionseffekt von zwei Variablen zu berechnen, müssen wir nur die Gleichung in unserem Aufruf der lm()-Funktion etwas anpassen. Statt zwei Prädiktoren mit einem + zu verbinden, können wir sie mit einem * verbinden. Das Resultat sehen Sie hier:\n\n# Berechnet eine Regression mit dem Interesse an lokalen Geschehnissen als AV und dem Alter, dem Interesse an Geschehnissen in Deutschland und dem Geschlecht als UVs. Dabei wird ein Interaktionseffekt zwischen Alter und Geschlecht angenommen.\nlmInteraktion &lt;- lm(interesseLokalRec ~ alter*geschlecht + interesseDERec, data = df_lokal)\n\n# Zeigt die Ergebnisse der Regression an\nsummary(lmInteraktion)\n\n\nCall:\nlm(formula = interesseLokalRec ~ alter * geschlecht + interesseDERec, \n    data = df_lokal)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.89015 -0.08269  0.03840  0.10593  0.49950 \n\nCoefficients:\n                           Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)               0.3654555  0.0263466  13.871 &lt; 0.0000000000000002 ***\nalter                     0.0023459  0.0004257   5.510         0.0000000411 ***\ngeschlechtweiblich        0.0948118  0.0296693   3.196              0.00142 ** \ninteresseDERec            0.3874885  0.0210168  18.437 &lt; 0.0000000000000002 ***\nalter:geschlechtweiblich -0.0012933  0.0005669  -2.281              0.02264 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1809 on 1790 degrees of freedom\n  (51 Beobachtungen als fehlend gelöscht)\nMultiple R-squared:  0.2014,    Adjusted R-squared:  0.1996 \nF-statistic: 112.8 on 4 and 1790 DF,  p-value: &lt; 0.00000000000000022\n\n\nIn der Tabelle aus der summary()-Funktion sehen wir jetzt, dass die Effekte des Alters und des Geschlechts (weiblich vs. männlich) weiterhin positiv sind. Diese beiden Effekte werden auch als Haupteffekte der beiden Variablen bezeichnet. Wichtig ist, dass diese Effekte in Anwesenheit einer signifikanten Interpretation mit äußester Vorsicht interpretiert werden sollten! Schließlich wissen Sie dann schon, dass die Effekte von der jeweils anderen Variable abhängig sind.\nDie neue Zeile ganz unten (alter:geschlechtweiblich) zeigt den Interaktionseffekt an, der negativ und signifikant ist. Das bedeutet, Frauen haben zwar insgesamt ein höheres Interesse an lokalen Geschehnissen als Männer und ältere Menschen haben ein höheres Interesse als jüngere Menschen, aber je älter die Frauen werden, desto geringer ist ihr Interesse im Vergleich zu älteren Männern.\nZugegebenermaßen ist diese Interpretation nicht ganz offensichtlich. Bei der Einordnung hilft, sich ins Gedächtnis zu rufen, dass die Effekte immer aussagen, wie sich die abhängige Variable verändert, wenn wir die Werte der unabhängigen Variablen einzeln ändern. Also konkret: der positive Effekt des Alters sagt aus, dass ältere Menschen ein überdurchscnittliches Interesse an lokalen Geschehnissen haben, wenn alle anderen Variablen konstant gehalten werden. Gleiches gilt für Frauen vs. Männer. Der Interaktionseffekt sagt nun aus, wie sich das Interesse verändert, wenn eine Person weiblich statt männlich ist und älter statt jünger. Wir ändern also beide Variablen gleichzeitig und halten nur noch das Interesse an Geschehnissen in Deutschland konstant.\nDer Vollständigkeit halber lassen wir uns auch noch die standardisierten Effektstärken anzeigen:\n\n# Zeigt den standardisierten Koeffizienten beta für die Prädiktoren an\nstandardize_parameters(lmInteraktion)\n\n# Standardization method: refit\n\nParameter                     | Std. Coef. |         95% CI\n-----------------------------------------------------------\n(Intercept)                   |      -0.09 | [-0.15, -0.03]\nalter                         |       0.18 | [ 0.11,  0.24]\ngeschlecht [weiblich]         |       0.15 | [ 0.07,  0.24]\ninteresseDERec                |       0.40 | [ 0.36,  0.44]\nalter × geschlecht [weiblich] |      -0.10 | [-0.18, -0.01]\n\n\n\n\n9.3.3 Interaktionseffekte visualisieren\nEine einfache Möglichkeit, Interaktionseffekte zu verstehen ist, sie zu visualisieren. Dazu nutzen wir die Funktion interact_plot() aus dem Paket interactions, das wir zunächst noch installieren müssen.\nDie Funktion erstellt basierend auf ggplot() eine Grafik, nimmt uns dabei aber viel manuelle Arbeit ab. Der Nachteil ist, dass wir etwas weniger Möglichkeiten haben, die Grafik individuell anzupassen.\nGrundsätzlich reicht es, der Funktion einige wenige Argumente zu übergeben:\n\nDas Modell, das wir zuvor mit lm() geschätzt haben.\nDen Prädiktor, den wir auf der x-Achse darstellen wollen. Das Argument heißt pred. Hier nehmen wir das Alter.\nDen Moderator, den wir im Argument modx angeben. Hier also das Geschlecht.\n\nAußerdem geben wir einige weitere Argumente an, durch die das Resultat noch etwas besser wird:\n\nDurch interval = TRUE können wir Konfidenzintervalle einzeichnen, wodurch die mit der Schätzung verbundene Unsicherheit visualisiert wird.\nMit x.label und y.label können wir die Achsen manuell beschriften.\nMit legend.main können wir den Titel der Legende anpassen.\n\n\n# Versucht das Paket \"interactions\" zu laden. Falls es nicht installiert ist, wird es erst installiert und dann geladen\nif(!require(interactions)){\n  install.packages(\"interactions\")\n  library(interactions)\n}\n\nLade nötiges Paket: interactions\n\n\nWarning: Paket 'interactions' wurde unter R Version 4.4.2 erstellt\n\n# Erstellt das Objekt \"plotInteraktion\", in dem die Interaktion visualisiert wird\nplotInteraktion &lt;- interact_plot(lmInteraktion, pred = alter, modx = geschlecht, interval = TRUE, x.label = \"Alter\", y.label = \"Interesse an lokalen Geschehnissen\", legend.main = \"Geschlecht\")\n\n# Zeigt die Grafik an\nplotInteraktion\n\n\n\n\n\n\n\n\nDie Grafik zeigt nun relativ eindeutig, dass jüngere Frauen ein deutlich höheres Interesse haben als jüngere Männer. Dafür ist der Effekt für Männer dann stäker, sprich, die Gerade ist deutlich steiler. Daraus resltiert dann, dass ältere Männer ein etwas höheres Interesse an lokalen Geschehnissen haben, wobei sich die beiden Gruppen im hohen Alter nur noch geringfügig unterscheiden.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "Regressionen II.html#voraussetzungen",
    "href": "Regressionen II.html#voraussetzungen",
    "title": "9  Regressionen II",
    "section": "9.4 Voraussetzungen",
    "text": "9.4 Voraussetzungen\nIn diesem Teil wird es zwsichendurch ziemlich komplex, daher vorab das für Sie Wichtigste: Die meisten Voraussetzungen von Regressionen können wir in den meisten Fällen ignorieren! Lesen Sie die ersten beiden Aufmerksam durch, auch Nummer 3 ist noch gut zu wissen. Alles danach sollten Sie auch lesen, aber machen Sie sich keine Sorgen, wenn Sie dabei nicht mehr ganz mitkommen. Fragen dürfen Sie natürlich trotzdem immer!\n\n9.4.1 Welche Voruassetzungen haben Regressionen?\nSchauen wir uns abschließend an, welche Voraussetzungen die Regressionsanalyse hat. Vorweg: Dieser Teil kann etwas abschreckend sein, aber die gute Nachricht ist, dass es in vielen Fällen reicht, die Voraussetzungen im Hinterkopf zu haben. Und noch ein Disclaimer: Dieser Teil basiert in weiten Teilen auf Kapitel 11.1 auf einem Lehrbuch von Gelman, Hill und Vethari, das online verfügbar ist.\nDie zwei wichtigsten Voraussetzungen haben relativ wenig mit der eigentlichen Statistik zu tun:\n\nDie Daten müssen valide sein. Der Begriff ist Ihnen wahrscheinlich schon aus dem Studium bekannt. Wir verstehen darunter die Frage, ob die Daten (bzw. die Datenerhebung) wirklich das Messen, was sie messen sollen. Im Kontext von Regressionen (und den anderen Verfahren, die wir noch kennenlernen werden!) bedeutet es aber auch, dass unser Modell als Ganzes eine gute Repräsentation des zu untersuchenden Sachverhalts sein sollte. Ganz konkret sollten z.B. alle relevanten Prädiktoren berücksichtigt werden. Das ist in der Praxis gar nicht immer so einfach, allein schon deshalb, weil oftmals vor der Datenerhebung gar nicht klar ist, welche Konstrukte relevat sein könnten. Aber es ist immer gut, diese Frage im Hinterkopf zu haben und ggf. bei der Interpretation der Ergebnisse zu berücksichtigen.\nImmer, wenn wir eine Regression berechnen, versuchen wir basierend auf Daten einer Stichprobe Schlüsse über eine Grundgesamtheit zu ziehen. Damit diese Schlüsse zulässig sind, müssen unsere Daten repräsentativ sein. Wichtig ist, dass für die Regression nicht die Stichprobe selbst ein repräsentatives Abbild der Grundgesamtheit sein muss, sondern vielmehr die gemessene Verteilung der abhängigen Variable, die in Abhängigkeit der aller unabhänggen Variablen der Grundgesamtheit entsprechen muss. Wenn wir beispielsweise die Größe von Befragten durch ihr Geschlecht und ihre Ernährungsgewohnheiten während der Kindheit erklären wollen, wäre es völlig in Ordnung, wenn Frauen oder vegan ernährte Kinder überrepräsentiert wären. Allerdings hätten wir ein Problem, wenn überdurchschnittlich viele große Menschen in unserer Stichprobe enthalten wären. Ein Problem, dass wir in diesem Kontext immer mal wieder haben ist, dass es schwer bis unmöglich sein kann, die Grundgesamtheit überhaupt zu bestimmen. Das ist z.B. immer dann der Fall, wenn Sie Ihre Stichprobe über persönliche Kontakte und/oder soziale Medien rekrutieren. Allen Ergebnissen, die Sie berechnen, liegt dann die Annahme zu Grunde, dass die gemessenen Daten auf die Grundgesamtheit, an der Sie interessiert sind, übertragbar sind.\n\nDaneben gibt es einige Voraussetzungen, die auch im strengeren Sinne statistischer Natur sind.\n\nRegressionsmodell müssen linear sein. Darüber haben wir bereits im Kontext von Korrelationen gesprochen. Sollten Sie z.B. einmal einen solchen Zusammenhang sehen, können Sie relativ leicht erkennen, dass es sich nicht um einen linearen Zusammenhang handelt. In diesem Fall würden wir eher von einem quadratischen Zusammenhang sprechen. In solchen Fällen haben Sie zwei Möglichkeiten: Entweder Sie transformieren eine der Variablen (üblicherweise die unabhängige Variable) oder sie wählene ein anderes Verfahren (das Sie in dieser Veranstaltung allerdings nicht lernen).\n\n\n\n\n\n\n\n\n\n\n\nDie Effekte in Regressionsmodellen müssen additiv sein. Das heißt, wir gehen davon aus, dass die abhängige Variable am besten dadurch erklärt werden kann, dass wir die unabhängigen Variablen addieren, also nach dem Schema: y = x + z. Das ist eine durchaus starke Annahme. Genauso gut wäre es schließlich denkbar, dass die abhängige Variable das Ergebnis des Produkts von zwei Variablen ist, also: y = x*z. In der Realität kann das schwer zu erkennen sein, aber zum Glück können wir es relativ leicht berücksichtigen. Schließlich haben wir oben festgestellt, dass eine Interaktion nichts anderes ist, als das Produkt von zwei Prädiktoren.\nDie Schätzfehler (oder Residuen) müssen unabhängig voneinander sein. Das bedeutet, dass die Abweichung eines gemessenen Wertes vom in der Regression geschätzen Wert in einem Fall (also z.B. einem ausgefüllten Befragungsbogen) keinen Einfluss auf die Abweichung in einem anderen Fall (also einem anderen ausgefüllten Fragebogen) haben darf. In den aller meisten Fällen können Sie davon ausgehen, dass diese Voraussetzung erfüllt ist. In anderen Fällen ist es dagegen sehr offensichtlich, dass dies nicht der Fall ist, z.B. wenn Sie dieselben Personen immer wieder befragen und davon ausgehen müssen, dass die Antworten aus der ersten Befragungswelle und die Antworten aus der zweiten Welle nicht unabhängig voneinander sind. In anderen Fällen entsteht eine Abhängigkeit durch das Erhebungssetting. Wenn Sie beispielsweise mehrere Schulklassen untersuchen, ist es gut möglich, dass die Daten aus den jeweiligen Klassen nicht unabhängig voneinander sind, etwa weil die zuständige Lehrkraft einen Einfluss ausübt. In solchen Fällen sollten Sie keine Regression anwenden.\nDie Schätzfehler sollten eine gleichmäßige Streuung aufweisen. Das bedeutet, dass die durchschnittliche Abweichung der gemessenen Werte von den im Modell geschätzten Werten unabhängig davon sein sollte, welchen Wert ein Prädiktor hat. Im Bild unten sehen Sie, wie das aussehen könnte: Je kleiner die Werte von x, ddesto näher liegen sie, im Durchschnitt, an der Linie. Die höheren Werte sind dagegen deutlich weiter um die Linie herum gestreut. Man spricht in so einem Fall auch von Heteroskedastizität. Die gute Nachricht ist, dass Sie sich nicht wirklich um Heteroskedastizität sorgen müssen, sofern Sie nur daran interessiert sind, gemessene Daten zu erklären und nicht das Ziel haben, Werte zu prognostizieren bzw. vorherzusagen.\n\n\n\n\n\n\n\n\n\n\n\nDie Schätzfehler sollten normalverteilt sein. In der Ausgabe der summary()-Funktion haben wir im letzten Kapitel kurz über die Zusammenfassung der Residuen gesprochen. Wie Sie dort sehen, werden Minimal- und Maximalwerte sowie Quartile und der Median dort abgebildet. Was dort leider nicht steht, sind Mittewert und Standardabweichung der Schätzfehler, die wir aber händisch berechnen könnten (aber zum Glück nur sehr selten müssen!). Was wir aber grundsätzlich aus der Angabe lernen ist, dass diese Schätzfehler irgendwie verteilt sind. Und diese Verteilung sollte normal sein, also durch eine Glockenkurve beschrieben werden können. Diese Voraussetzung wird in manchen Lehrbüchern und Online-Ressourcen fälschlicherweise angegeben als Normalverteilung der abhängigen Variable. Das ist nicht der Fall! Die Regression stellt keinerlei Anforderungen daran, wie diese Variable verteilt sein muss. Und es wird noch besser: Wie im Fall der Heteroskedastizität ist diese Voraussetzung nicht wirklich relevant, wenn Sie nur erhobene Daten erklären wollen und keine Vorhresagen basierend auf Ihrem Modell treffen wollen!\nDie unabhängigen Varialen sollten nicht (zu stark) korrelieren. Man spricht hier auch von einer möglichst geringen Kollinearität oder auch Multikollinearität. Liegt diese vor, also korrelieren die Prädiktoren stark miteinander, ist die Schätzung der Effektstärken mit mehr Unsicherheit verbunden, d.h., die Standardfehler und darauf basierend die Konfidenzintervalle werden größer. Das ergibt auch irgendwie Sinn, wenn man mal darüber nachdenkt: Eine Korrelation bedeutet am Ende nichts anderes, als dass zwei Variablen dieselben Informationen enthalten. Je mehr Sie über die eine wissen, desto mehr wissen Sie bei einer starken Korrelation auch über die andere. Wenn Sie nun hergehen wollen und basierend auf zwei stark korrelierenden Variablen eine abhängige Variable erklären wollen, gibt es schlicht keine Möglichkeit, mit Sicherheit zu sagen, welche der beiden Variablen für einen etwaigen Effekt verantwortlich ist. Die Schätzung enthält also viel Unsicherheit. Das muss aber nicht unbedingt ein Problem sein, sondern ist ein völlig legitimes Forschungsergebnis! Im Spezialfall von Interaktionseffekten würden wir sogar mit einer hohen Kollinearität rechnen und brauchen uns darum keine Sorgen zu machen. Nur in sehr seltenen Fällen kann es vorkommen, dass eine Regression aufgrund sehr starker Multikollinearität nicht geschätzt werden kann. In solchen Fällen müssten Sie dann eine der Variablen aus dem Modell ausschließen.\n\n\n\n9.4.2 Überprüfen der Voraussetzungen\nWie oben angedeutet, reicht es in den allermeisten Fällen, die Voraussetzungen im Hinterkopf zu haben. Falls Sie doch einmal in die Situation geraten, einzelne Voraussetzungen überprüfen zu wollen, können Sie dafür das performance-Paket nutzen.\n\n# Versucht das Paket \"performance\" zu laden. Falls es nicht installiert ist, wird es erst installiert und dann geladen\nif(!require(performance)){\n  install.packages(\"performance\")\n  library(performance)\n}\n\nLade nötiges Paket: performance\n\n\nDieses Paket enthält eine Vielzahl von Funktionen, mit denen Sie Regressionsmodelle überprüfen können. Das Schema ist dabei immer gleich: Sie müssen der entsprechenden Funktion lediglich berechnete Modell übergeben. Oftmals bietet es sich an, dabei visuell vorzugehen und die Funktionen innerhalb von plot() aufzurufen. Hier einige Beispiele. Fangen mit der Heteroskedastizität an:\n\n# Überprüft, ob Heteroskedastizität vorliegt und stellt das Ergebnis visuell dar\n\nplot(check_heteroscedasticity(lmInteraktion))\n\n\n\n\n\n\n\n\nHier sehen wir die Streuung der Schätzfehler. Freundlicherweise sagt uns die Funktion, wie das Ergebnis aussehen sollte. So erkennen wir gleich, dass wir die Voraussetzung nicht erfüllen. Aber da wir keine Vorhersagen treffen wollen, ist das nicht so schlimm.\nWeiter geht es mit der Normalverteilung der Residuen:\n\n# Überprüft, ob die Residuen normalverteilt sind und stellt das Ergebnis dar\n\nplot(check_normality(lmInteraktion))\n\nFor confidence bands, please install `qqplotr`.\n\n\n\n\n\n\n\n\n\nZum selben Resultat gelangen wir hier. Die Funktion sagt uns, dass die Punkte der Linie folgen sollten, was allerdings nicht der Fall ist. Aber da wir keine Vorhersagen treffen wollen, ist auch das kein Problem.\nWerfen wir abschließend einen Blick auf die (Multi-)Kollinearität:\n\n# Überprüft, ob Kollinearität vorliegt und stellt das Ergebnis visuell dar\nplot(check_collinearity(lmInteraktion))\n\nModel has interaction terms. VIFs might be inflated.\n  You may check multicollinearity among predictors of a model without\n  interaction terms.\n\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\n\nHier wird der sogannte Variance Inflation Faktor, kurz VIF, abgebildet. Er gibt an, wie stark die Korrelation zwischen den Prädiktoren ist. Werte über 10 gelten als problematisch (aber siehe oben!). Das ist hier für das Alter und die Interaktion aus Alter und Geschlecht der Fall. Nur: Es ist ja vollkommen logisch, dass die beiden Variablen stark korrelieren, denn die Interaktion ist nichs anderes als Alter*Geschlecht (wobei männlich = 0 und weiblich = 1)! Alles alles in bester Ordnung.\nSie können auch die check_model()-Funktion verwenden, in der die drei Tests oben plus einige weitere durchgeführt und dargestellt werden. Das Ergebnis wird aber schnell unübersichtlich, daher machen wir es hier nicht.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regressionen II</span>"
    ]
  },
  {
    "objectID": "t-Test.html",
    "href": "t-Test.html",
    "title": "10  t-Test",
    "section": "",
    "text": "10.1 Vorbereitung\nAUch für den t-Test benötigen wir das ‘tidyverse’ und das Paket ‘effectsize’. Außerdem lesen wir den Datensatz ein und ändern die Optionen so , dass kleine Zahlen in einem uns gewohnten Format angezeigt werden.\n# Lädt das tidyverse\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Lädt effectsize\nlibrary(effectsize)\n\n# Liest die Daten ein\ndf_lokal &lt;- read.csv(\"Daten/lokalkommunikation.csv\")\n\n# Stellt ein, dass sehr kleine Zahlen normal dargestellt werden\noptions(scipen = 999)\nAußerdem werden wir in diesem Kapitel mit den Spalten A501_01 bis A501_04 arbeiten. In den entsprechenden Fragen sollten die Befragten angeben, wie stark ihre Bindung zu ihrem Wohnort ist (z.B. “Ich fühle mich als Teil meines Wohnorts”), wobei der Wert 1 für geringen Zustimmung zu den Aussagen steht und der Wert 5 für hohe Zustimmung.\nDa diese vier Variablen alle dasselbe Konstrukt abfragen, berechnen wir zunächst pro Person einen Mittelwert aus den vier Spalten. Dazu nutzen wir zunächst die Funktion rowwise() aus dem dplyr-Paket. Damit sagen wir R, dass die nachfolgenden Zeilen jeweils für jede einzelne Zeile im Datensatz ausgeführt werden sollen. Anschließend nutzen wir mutate() und darin mean(), um den Mittelwert zu berechnen. Wichtig ist, dass wir abschließend die ungroup()-Funktion nutzen, da R ansosnten versucht, auch den nachfolgenden Code, der sich auf den Datensatz bezieht, versucht pro Zeile durchzuführen.\n# berechnet pro Person einen Mittelwert der Spalten A501_01 bis A501_04\ndf_lokal &lt;- df_lokal |&gt;\n  rowwise() |&gt;\n  mutate(lokaleBindung = mean(c(A501_01, A501_02, A501_03, A501_04), na.rm = TRUE)) |&gt;\n  ungroup()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>t-Test</span>"
    ]
  },
  {
    "objectID": "t-Test.html#t-test-durchführen",
    "href": "t-Test.html#t-test-durchführen",
    "title": "10  t-Test",
    "section": "10.2 t-Test durchführen",
    "text": "10.2 t-Test durchführen\nUm einen t-Test durchzuführen benötigen wir die t.test()-Funktion. Damit können wir alle drei Varianten des t-Tests rechnen, die wir im Video kennengelernt haben.\n\n10.2.1 Einstichproben t-Test\nWie im Video besprochen berechnen wir einen t-Test für eine Stichprobe immer dann, wenn wir wissen möchten, ob sich der von uns gemessene Mittelwert von einem a priori definierten Wert unterscheidet. Wenn wir z.B. wüssten, dass die Menschen in Thüringen und Rheinland-Pfalz sich im Durchschnitt nicht sehr an ihren Wohnort gebunden fühlen (also z.B. der Wert 2 dem Mittelwert der Grundgesamtheit entspricht), könnten wir mit dieser Variante des t-Tests prüfe, ob das auch auf unsere Stichprobe zutrifft.\nUm diesen Test durchzuführen, übergeben wir der t.test()-Funktion zunächst die Daten. Hier also die Spalte engagement. Wichtig ist, dass wir in diesem Beispiel keine Pipe (|&gt;) nutzen und anders als bei der Regression sagen wir der t.test()-Funktion auch nicht, welchen Datensatz wir benutzen. Wir müssen also mit Hilfe des Dollarzeiens erst den Datensatz und dann die Spalte angeben, so wie wir es in Kapitel 2 kennengelernt haben. Außerdem nutzen wir das Argument mu. Damit können wir den Wert angeben, gegen den wir unseren Stichprobenmittelwert testen wollen.\n\n# berechnet einen einstichproben t-Test\ntTest1sample &lt;- t.test(df_lokal$lokaleBindung, mu = 2)\n\n# zeigt die Ergebnisse an\ntTest1sample\n\n\n    One Sample t-test\n\ndata:  df_lokal$lokaleBindung\nt = 83.155, df = 1840, p-value &lt; 0.00000000000000022\nalternative hypothesis: true mean is not equal to 2\n95 percent confidence interval:\n 3.889405 3.980683\nsample estimates:\nmean of x \n 3.935044 \n\n\nSchauen wir uns das Ergebnis an. Oben werden uns der t-Wert, also die Teststatistik, die Freiheitsgrade (df) und der p-Wert des Tests angezeigt. Darunter erinnert uns R daran, welche Hypothese wir getestet haben. Darunter befindet sich wiederum ein 95%-Konfidenzintervall. Die Darstellung ist hier etwas unglücklich denn erst danach, also ganz unten, steht der Stichprobenmittelwert auf den sich das Konfidenzintervall bezieht.\nWir halten fest: Wir haben die Alternativhypothese getestet, dass sich der Stichprobenmittelwert vom Wert 2 unterscheidet. Das Ergebnis lautet: t(1840) = 83,155; p &lt; 0,001. Das bedeutet, dass wir die Nullhypothese (Stichprobenmittelwert = 2) verwerfen müssen und die Alternativhypothese annehmen können.\n\n\n10.2.2 t-Test für gepaarte Stichproben\nDer t-Test für gepaarte Stichproben funktioniert im Grunde sehr ähnlich. Statt das mu-Argument zu nutzen, übergeben wir diesmal aber zwei Spalten aus einem Datensatz. Dazu nutzen wir das Argument paired = TRUE. Da der Datensatz mit dem wir arbeiten eine einfache Querschnittsbefragung darstellt, in dem es keine Paare gibt, können wir leider kein Beispiel rechnen. Wie der Code aussehen würde, sehen Sie aber unten:\n\n#### BEISPIELCODE, DER NICHT AUSGEFÜHRT WERDEN KANN! ####\n# tTestPaare &lt;- t.test(df$Spalte1, df$Spalte2, paired = TRUE)\n\n\n\n10.2.3 t-Test für unabhängige Stichproben\nDer t-Test für unabhängige Stichproben sieht der Regression sehr ähnlich. Das heißt, wir geben auch hier eine “Formel” ein, bei der die abhängige Variable links von einer Tilde (~) steht und die unabhängige Variable rechts davon. Für das Beispiel nehmen wir wieder die lokale Bindung (df_lokal$lokaleBindung) als AV und dazu das Bundesland aus dem die Befragten stammen (df_lokal$Bula) als UV.\n\n# berechnet einen t-Test für unabhängige Stichproben\ntTestIndSample &lt;- t.test(df_lokal$lokaleBindung ~ df_lokal$Bula)\n\n# zeigt das Ergebnis an\ntTestIndSample\n\n\n    Welch Two Sample t-test\n\ndata:  df_lokal$lokaleBindung by df_lokal$Bula\nt = -3.2835, df = 1767.9, p-value = 0.001045\nalternative hypothesis: true difference in means between group RLP and group TH is not equal to 0\n95 percent confidence interval:\n -0.2439230 -0.0614935\nsample estimates:\nmean in group RLP  mean in group TH \n         3.868022          4.020730 \n\n\nSchauen wir uns auch hier die Ergebnisse an. Oben stehen wieder die Teststatistik t sowie die dazugehörigen Freiheitsgrad und der p-Wert. Hier lautet unser Ergebnis also: t(1767,9) = -3,28; p = 0,001.\nWeiter unten sehen wir dann wieder ein Konfidenzintervall. Es bezieht sich hier auf die Differenz zwischen den beiden Gruppenmittelwerten. Diese stehen dann direkt darunter. Wie wir sehen, fühlen sich die Menschen aus Rheinland-Pfalz etwas weniger lokal zugehörig (M = 3.87) als die Menschen aus Thüringen (M = 4,02).\nFür diesen Test berechnen wir nun Cohens d. Für die beiden Tests oben geht das grundsätzlich aber auch. Wir nutzen dafür ie cohens_d()-Funktion aus dem Paket effectsize, der wir das Objekt übergeben, in dem wir das Ergebnis des Tests gespeichert haben (hier also tTestIndSample). Außerdem übergeben wir der Funktion das Argument pooled_sd = FALSE. Darauf werden wir gleich noch mal kurz eingehen.\n\ncohens_d(tTestIndSample, pooled_sd = FALSE)\n\nCohen's d |         95% CI\n--------------------------\n-0.15     | [-0.25, -0.06]\n\n- Estimated using un-pooled SD.\n\n\nCohens d wird hier mit dem Wert -0,15 ausgegeben.D.h., der Mittelwert der Menschen aus Rheinland-Pfalz liegt um 0,15 Standardabweichungen der AV unter dem Wert der Befragten aus Thüringen.\nUm das Ergebnis vollständig verschriftlichen zu können, benötigen wir noch die Mittelwerte und Standardabweichungen der beiden Gruppen. Das machen wir wie gewohnt mit Hilfe von summarise(). Damit die Werte für jede Gruppe erhalten, nutzen wir vorher noch group_by() und geben dort die Spalte Bula an.\n\n# berechnet Mittelwerte und Standardabweichungen für die beiden Gruppen\nMWsSDs &lt;- df_lokal |&gt;\n  group_by(Bula) |&gt;\n  summarise(MW = round(mean(lokaleBindung, na.rm = TRUE),2),\n            SD = round(sd(lokaleBindung, na.rm = TRUE),2))\n\n# zeigt die Werte an\nMWsSDs\n\n# A tibble: 2 × 3\n  Bula     MW    SD\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 RLP    3.87  1.02\n2 TH     4.02  0.97\n\n\nNun können wir das Ergebnis wie folgt aufschreiben: &gt; Durch einen t-Test wurde geprüft, ob sich die Bindung an den Wohnort von Menschen in Rheinland-Pfalz (M = 3,87; SD = 1,02) von der Bindung der Befragten in Thüringen (M = 4,02; SD = 0,97). Die beiden Gruppen unterscheiden sich signifikant voneinander (t(1767,9) = -3,28; p = 0,001). Die Thüringer fühlen sich signifikant stärker an ihren Ort gebunden, aber dieser Effekt ist schwach (Cohens d = -0,15).\n\n\n\n\n\n\nVarianzhomogenität beim t-Test\n\n\n\nAm Ende des letzten Kapitels haben wir die Voraussetzungen von Regressionen kennengelernt. Dort hieß es unter anderem, dass die Streuung der Schätzfehler gleichmäßig sein muss. Ist das nicht der Fall, sprechen wir von Heteroskedastizität. Ist die Voraussetzung dagegen erfüllt, von Homoskedastizität. Im Video in diesem Kapitel haben Sie dann erfahren, dass der t-Test eigentlich nur eine spezielle Form der Regression ist und daher dieselben Voraussetzungen teilt. Im Kontext von t-Tests sprechen wir aber in der Regel von Varianzhomogenität (statt Homo- oder Heteroskedastizität).\nDer t-Test wird in R standardmäßig in einer Variante durchgeführt, die keine gleichen Varianzen voraussetzt. Das ist einerseits sinnvoll, da es immer gut ist, einen Test zu haben, der nominell weniger Voraussetzungen hat. Andererseits liegt hierin auch der Grund, dass wir in unserem Aufruf von cohens_d() das Argument pooled_sd = FALSE angeben mussten. Denn die cohes_d()-Funktion geht davon aus, dass die Version des t-Tests gerechnet wurde, die von Varianzhomogenität ausgeht.\nAlternativ könnten Sie auch beim Aufruf der t.test()-Funktion das Argument var.equal = TRUE angeben und könnten im Gegenzug pooled_sd = FALSE beim Aufruf von cohens_d() weglassen.\nIn dieser Variante können wir übrigens schön sehen, dass der t-Test eigentlich eine Regression ist. Wenn Sie die Ergebnisse des Codes unten aufmerksam vergleichen, werden Sie feststellen, dass die t- und p-Werte des t-Tests und des entsprechenden Koeffizienten in der Regression quasi identisch sind. Gleiches gilt für die berechnete Effektstärke von standardize_parameters() und cohens_d().\n\n# berechnet einen t-Test mit angenommener Varianzhomogenität\ntTest &lt;- t.test(df_lokal$lokaleBindung ~ df_lokal$Bula, var.equal = TRUE)\n\n# zeigt das Ergebnis an\ntTest\n\n\n    Two Sample t-test\n\ndata:  df_lokal$lokaleBindung by df_lokal$Bula\nt = -3.2651, df = 1839, p-value = 0.001114\nalternative hypothesis: true difference in means between group RLP and group TH is not equal to 0\n95 percent confidence interval:\n -0.24443519 -0.06098132\nsample estimates:\nmean in group RLP  mean in group TH \n         3.868022          4.020730 \n\n# berechnet dasselbe Modell als Regression\nregression &lt;- lm(lokaleBindung ~ Bula, data = df_lokal)\n\n# zeigt die Ergebnisse an\nsummary(regression)\n\n\nCall:\nlm(formula = lokaleBindung ~ Bula, data = df_lokal)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0207 -0.6180  0.1320  0.9793  1.1320 \n\nCoefficients:\n            Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)  3.86802    0.03098 124.838 &lt; 0.0000000000000002 ***\nBulaTH       0.15271    0.04677   3.265              0.00111 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9958 on 1839 degrees of freedom\n  (5 Beobachtungen als fehlend gelöscht)\nMultiple R-squared:  0.005764,  Adjusted R-squared:  0.005223 \nF-statistic: 10.66 on 1 and 1839 DF,  p-value: 0.001114\n\n\n\n# berechnet Cohens d und zeigt es an\ncohens_d(tTest)\n\nCohen's d |         95% CI\n--------------------------\n-0.15     | [-0.25, -0.06]\n\n- Estimated using pooled SD.\n\n# berechnet standardisierte Effektstärken für die Regression und zeigt sie an\nstandardize_parameters(regression)\n\n# Standardization method: refit\n\nParameter   | Std. Coef. |         95% CI\n-----------------------------------------\n(Intercept) |      -0.07 | [-0.13, -0.01]\nBula [TH]   |       0.15 | [ 0.06,  0.24]",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>t-Test</span>"
    ]
  },
  {
    "objectID": "t-Test.html#ergebnis-visualisieren",
    "href": "t-Test.html#ergebnis-visualisieren",
    "title": "10  t-Test",
    "section": "10.3 Ergebnis visualisieren",
    "text": "10.3 Ergebnis visualisieren\nIm bisherigen Lauf der Veranstaltung haben wir schon einige Möglichkeiten kennengelernt, um Mittelwerte bzw. die dazugehörige Verteilung zu visualisieren. Für das Beispiel des t-Tests für unabhängige Stichproben, den wir oben berechnet haben, lernen Sie nun eine weitere Visualisierung kennen. Wir starten zunächst mit einem Histogramm, das die beiden Gruppen berücksichtigt. Wir starten mit einer sehr einfachen Variante und verfeinern sie nach und nach. Das Endresultat steht dann ganz unten.\nIm ersten Schritt filtern wir fehlende Werte in der Spalte lokaleBindung aus und übergeben unseren Datensatz an ggplot(). Dort legen wir fest, dass die Spalte lokaleBindung auf der x-Achse darstellen werden soll. Beim Histogramm wird auf der y-Achse automatisch die Häufigkeit dargestellt. Um die Gruppen abzubilden nutzen wir zusätzlich das Argument fill = Bula. Mit geom_histogram() erstellen wir dann das Histogramm. Dabei geben wir bins = 17 an. Unter bins verstehen wir, in wieviele Bereiche die Daten eingeteilt werden sollen. D.h., bei einem Histogramm werden nicht wie bei einem Balkendiagramm alle Werte einzeln abgebildet, sondern kleine Gruppen gebildet. Hier nehmen wir den Wert 17, weil er a) die tatsächlich beobachteten Werte gut abbildet und b) weil das Resultat besser aussieht als der Standardwert 30 oder andere Werte. Abschließend machen wir den Plot mit theme_minimal() direkt noch etwas schöner.\n\n# erstellt ein Histogramm der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\nhistBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_histogram(bins = 17)+\n  theme_minimal()\n\n# zeigt das Histogramm an\nhistBindung\n\n\n\n\n\n\n\n\nDas Resultat sieht nicht schrecklich aus, aber kann noch deutlich verbessert werden. Dass die Farben nicht sonderlich schön sind, ist das eine, aber vor allem handelt es sich hierbei um ein gestalpeltes Histogramm. D.h., die Anzahl, die auf der y-Achse dargestellt wird, ist die Gesamtanzahl der entsprechenden Werte in beiden Gruppen zusammen.\nDas können wir beheben, indem wir geom_histogram() das Argumet position = \"identity\" übergeben. So werden die Balken des Histogramms übereinandergelegt. Außerdem passen wir die Farben an. Dafür nutzen wir wie schon in anderen Beispielen die scale_fill_manual()-Funktion und übergeben ihr im Argument values zwei Farben (also eine pro Gruppe).\n\n# erstellt ein Histogramm der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\nhistBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_histogram(bins = 17, position = \"identity\")+\n  theme_minimal()+\n  scale_fill_manual(values=c(\"red\", \"orange\"))\n\n# zeigt das Histogramm an\nhistBindung\n\n\n\n\n\n\n\n\nDas sieht schon besser aus! Da die Balken nun hintereinander liegen und die Thüringer im Vordergrund dargestellt werden, wird der Balken für Rheinland-Pfalz an einigen Stellen verdeckt. Um das zu beheben können wir geom_histogram() das Argument alpha übergeben. Damit machen wir die Balken etwas transparent. Der Wert muss immer zwischen 0 und 1 liegen. Im Beispiel unten wurde 0,6 gewählt. Aber das ist eine Frage der Präferenz!\nEin etwas weniger offensichtliches Problem gibt es allerdings noch. Und zwar, dass die beiden Gruppen unterschiedlich groß sind. Oben im Test haben wir erfahren, dass die Thüringer einen etwas höheren Mittelwert haben als die Menschen aus Rheinland-Pfalz. Allerdings sehen wir in diesem Diagramm, dass in fast alle Wertebereichen mehr Menschen aus Rheinland-Pfalz als aus Thüringen fallen. In anderen Worten: die unterschiedlichen Fallzahlen machen es nahezu unmöglich, den höheren Mittelwert der Thüringer optisch zu erahnen. Wir können es beheben, indem wir die Darstellung auf der y-Achse von absooluten Häufigkeiten zur sogenannten Wahrscheinlichkeitsdichte ändern. Das machen wir, geom_histogram() die aes()-Funktion übergeben und dort y = after_stat(density) angeben. Dadurch werden die beiden Gruppen vergleichbar. Stark vereinfacht können wir sagen, dass die Wahrscheinlichkeitsdichte angibt, wie wahrscheinlich es ist, dass ein zufälliger Wert aus unserer Stichprobe in einem bestimmten Wertebereich liegt.\nDa wir nun die Bedeutung der Achse geändert haben, sollten wir auch die Beschriftung der Achsen anpassen. Dazu nutzen wir wieder die labs()-Funktion.\n\n# erstellt ein Histogramm der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\nhistBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_histogram(bins = 17, position = \"identity\", alpha = 0.6, aes(y = after_stat(density)))+\n  theme_minimal()+\n  scale_fill_manual(values=c(\"red\", \"orange\"))+\n  labs(x = \"Bindung an den Wohnort\", y = \"Wahrscheinlichkeitsdichte\")\n\n# zeigt das Histogramm an\nhistBindung\n\n\n\n\n\n\n\n\nEine besonderheit der Wahrscheinlichkeitsdichte ist, dass wir sie auch kontinuierlich darstellen können. Im Prinzip wird dazu auf Basis unserer Beobachtungen eine Funktion geschätzt, die die Verteilung einer kontinuierlichen, metrischne Variable abbildet. Dazu können wir geom_histogram() durch geom_density() ersetzen. Wir nutzen wieder das Argument alpha, um die Darstellung leicht transparent zu machen.\n\n# erstellt einen Densityplot der Spalte \"lokaleBindung\" nach Gruppe (RLP vs. TH)\ndensityBindung &lt;- df_lokal |&gt;\n  filter(!is.na(lokaleBindung)) |&gt;\n  ggplot(aes(x = lokaleBindung, fill = Bula))+\n  geom_density(alpha = .6)+\n  theme_minimal()+\n  scale_fill_manual(values=c(\"red\", \"orange\"))+\n  labs(x = \"Bindung an den Wohnort\", y = \"Wahrscheinlichkeitsdichte\")\n\n# zeigt den Densityplot an\ndensityBindung",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>t-Test</span>"
    ]
  }
]